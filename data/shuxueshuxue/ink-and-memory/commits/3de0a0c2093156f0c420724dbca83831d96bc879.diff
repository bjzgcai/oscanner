*** FILE: backend/.gitignore ***
@@ -0,0 +1 @@
+test_data/

*** FILE: backend/API.md ***
@@ -0,0 +1,668 @@
+# Ink & Memory API Documentation
+
+**Version:** 2.0.0
+**Base URL:** `http://localhost:8765` (dev) | `https://lexicalmathical.com/ink-and-memory` (prod)
+
+## Authentication
+
+All endpoints except `/api/register`, `/api/login`, and `/api/default-voices` require authentication.
+
+**Header:** `Authorization: Bearer <JWT_TOKEN>`
+
+JWT tokens expire after 7 days.
+
+---
+
+## Auth Endpoints
+
+### POST `/api/register`
+
+Register a new user.
+
+**Request:**
+```json
+{
+  "email": "user@example.com",
+  "password": "password123",
+  "display_name": "Optional Name"
+}
+```
+
+**Response:**
+```json
+{
+  "token": "eyJhbGciOiJIUzI1...",
+  "user": {
+    "id": 1,
+    "email": "user@example.com",
+    "display_name": "Optional Name"
+  }
+}
+```
+
+**Errors:**
+- `400` - Email/password missing or password < 6 chars
+- `400` - Email already exists
+
+---
+
+### POST `/api/login`
+
+Login with email and password.
+
+**Request:**
+```json
+{
+  "email": "user@example.com",
+  "password": "password123"
+}
+```
+
+**Response:**
+```json
+{
+  "token": "eyJhbGciOiJIUzI1...",
+  "user": {
+    "id": 1,
+    "email": "user@example.com",
+    "display_name": "Optional Name"
+  }
+}
+```
+
+**Errors:**
+- `401` - Invalid email or password
+
+---
+
+### GET `/api/me`
+
+Get current user info from token.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Response:**
+```json
+{
+  "id": 1,
+  "email": "user@example.com",
+  "display_name": "Optional Name",
+  "created_at": "2025-11-02 05:20:53"
+}
+```
+
+**Errors:**
+- `401` - Missing or invalid token
+- `404` - User not found
+
+---
+
+## Migration Endpoint
+
+### POST `/api/import-local-data`
+
+One-time import of localStorage data to database on first login.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Request:**
+```json
+{
+  "currentSession": "{\"cells\": [...]}",
+  "calendarEntries": "{\"2025-11-01\": [...]}",
+  "dailyPictures": "[{\"date\": \"2025-11-01\", \"base64\": \"...\"}]",
+  "voiceCustomizations": "{\"Logic\": {...}}",
+  "metaPrompt": "Be helpful",
+  "stateConfig": "{\"states\": {...}}",
+  "selectedState": "happy",
+  "analysisReports": "[{\"type\": \"echoes\", \"data\": {...}}]",
+  "oldDocument": "{\"document\": \"...\"}"
+}
+```
+
+All fields are optional. Strings should be JSON-stringified.
+
+**Response:**
+```json
+{
+  "success": true,
+  "imported": {
+    "sessions": 6,
+    "pictures": 2,
+    "preferences": 4,
+    "reports": 3
+  }
+}
+```
+
+**Errors:**
+- `401` - Missing or invalid token
+
+---
+
+## Session Storage
+
+### POST `/api/sessions`
+
+Save or update a session.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Request:**
+```json
+{
+  "session_id": "my-session-123",
+  "name": "My Session Name",
+  "editor_state": {
+    "cells": [
+      {"type": "text", "content": "Hello world"}
+    ],
+    "commentors": []
+  }
+}
+```
+
+**Response:**
+```json
+{
+  "success": true
+}
+```
+
+---
+
+### GET `/api/sessions`
+
+List all sessions for current user (metadata only, no editor_state).
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Response:**
+```json
+{
+  "sessions": [
+    {
+      "id": "session-123",
+      "name": "My Session",
+      "created_at": "2025-11-02 05:22:41",
+      "updated_at": "2025-11-02 05:22:41"
+    }
+  ]
+}
+```
+
+---
+
+### GET `/api/sessions/{session_id}`
+
+Get a specific session including full editor_state.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Response:**
+```json
+{
+  "id": "session-123",
+  "name": "My Session",
+  "created_at": "2025-11-02 05:22:41",
+  "updated_at": "2025-11-02 05:22:41",
+  "editor_state": {
+    "cells": [...],
+    "commentors": []
+  }
+}
+```
+
+**Errors:**
+- `404` - Session not found
+
+---
+
+### DELETE `/api/sessions/{session_id}`
+
+Delete a session.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Response:**
+```json
+{
+  "success": true
+}
+```
+
+---
+
+## Pictures
+
+### GET `/api/pictures`
+
+Get recent daily pictures.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Query params:**
+- `limit` (optional, default 30) - Max number of pictures
+
+**Response:**
+```json
+{
+  "pictures": [
+    {
+      "date": "2025-11-02",
+      "image_base64": "iVBORw0KGgoAAAANSUhEUg...",
+      "prompt": "A serene landscape...",
+      "created_at": "2025-11-02 05:22:41"
+    }
+  ]
+}
+```
+
+---
+
+### POST `/api/pictures`
+
+Save a daily picture.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Request:**
+```json
+{
+  "date": "2025-11-02",
+  "image_base64": "iVBORw0KGgoAAAANSUhEUg...",
+  "prompt": "A serene landscape..."
+}
+```
+
+**Response:**
+```json
+{
+  "success": true
+}
+```
+
+**Errors:**
+- `400` - date or image_base64 missing
+
+---
+
+## Preferences
+
+### GET `/api/preferences`
+
+Get user preferences.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Response:**
+```json
+{
+  "voice_configs": {
+    "Logic": {
+      "name": "Logic",
+      "tagline": "...",
+      "icon": "brain",
+      "color": "blue",
+      "enabled": true
+    }
+  },
+  "meta_prompt": "Be helpful",
+  "state_config": {
+    "states": {
+      "happy": {"name": "Happy", "prompt": "..."}
+    }
+  },
+  "selected_state": "happy",
+  "updated_at": "2025-11-02 05:22:41"
+}
+```
+
+Returns empty object `{}` if no preferences set.
+
+---
+
+### POST `/api/preferences`
+
+Save user preferences (partial updates supported).
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Request (any combination of fields):**
+```json
+{
+  "voice_configs": {...},
+  "meta_prompt": "Be creative",
+  "state_config": {...},
+  "selected_state": "happy"
+}
+```
+
+**Response:**
+```json
+{
+  "success": true
+}
+```
+
+---
+
+## Analysis Reports
+
+### GET `/api/reports`
+
+Get recent analysis reports.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Query params:**
+- `limit` (optional, default 10) - Max number of reports
+
+**Response:**
+```json
+{
+  "reports": [
+    {
+      "id": 1,
+      "report_type": "echoes",
+      "report_data": {
+        "echoes": [...]
+      },
+      "created_at": "2025-11-02 05:22:41"
+    }
+  ]
+}
+```
+
+---
+
+### POST `/api/reports`
+
+Save an analysis report.
+
+**Headers:** `Authorization: Bearer <token>`
+
+**Request:**
+```json
+{
+  "report_type": "echoes",
+  "report_data": {
+    "echoes": [
+      {"title": "...", "description": "...", "examples": [...]}
+    ]
+  },
+  "all_notes_text": "All the user's notes combined..."
+}
+```
+
+**Response:**
+```json
+{
+  "success": true
+}
+```
+
+**Errors:**
+- `400` - report_type or report_data missing
+
+---
+
+## Voice Analysis (PolyCLI)
+
+### POST `/api/analyze`
+
+Analyze text and return ONE new voice comment (sync API).
+
+**Request:**
+```json
+{
+  "text": "User's text to analyze",
+  "session_id": "session-123",
+  "voices": {...},
+  "applied_comments": [],
+  "meta_prompt": "",
+  "state_prompt": "",
+  "overlapped_phrases": []
+}
+```
+
+**Response:**
+```json
+{
+  "success": true,
+  "result": {
+    "voices": [
+      {
+        "phrase": "exact phrase",
+        "voice": "Logic",
+        "comment": "What the voice says",
+        "icon": "brain",
+        "color": "blue"
+      }
+    ],
+    "new_voices_added": 1
+  }
+}
+```
+
+---
+
+### POST `/api/chat`
+
+Chat with a voice persona (sync API).
+
+**Request:**
+```json
+{
+  "voice_name": "Logic",
+  "voice_config": {...},
+  "conversation_history": [
+    {"role": "user", "content": "Hi"},
+    {"role": "assistant", "content": "Hello"}
+  ],
+  "user_message": "What do you think?",
+  "original_text": "User's writing context",
+  "meta_prompt": "",
+  "state_prompt": ""
+}
+```
+
+**Response:**
+```json
+{
+  "success": true,
+  "result": {
+    "response": "Voice's response to the user"
+  }
+}
+```
+
+---
+
+### POST `/api/generate-image`
+
+Generate artistic image from notes (sync API, 60s timeout).
+
+**Request:**
+```json
+{
+  "all_notes": "All user's notes combined..."
+}
+```
+
+**Response:**
+```json
+{
+  "success": true,
+  "result": {
+    "image_base64": "iVBORw0KGgoAAAANSUhEUg...",
+    "prompt": "Creative image description"
+  }
+}
+```
+
+---
+
+### POST `/api/analyze-echoes`
+
+Find recurring themes in notes (sync API).
+
+**Request:**
+```json
+{
+  "all_notes": "All user's notes combined..."
+}
+```
+
+**Response:**
+```json
+{
+  "success": true,
+  "result": {
+    "echoes": [
+      {
+        "title": "Theme title",
+        "description": "Pattern description",
+        "examples": ["quote1", "quote2"]
+      }
+    ]
+  }
+}
+```
+
+---
+
+### POST `/api/analyze-traits`
+
+Identify personality traits from notes (sync API).
+
+**Request:**
+```json
+{
+  "all_notes": "All user's notes combined..."
+}
+```
+
+**Response:**
+```json
+{
+  "success": true,
+  "result": {
+    "traits": [
+      {
+        "trait": "Curious",
+        "strength": 4,
+        "evidence": "Examples from text..."
+      }
+    ]
+  }
+}
+```
+
+---
+
+### POST `/api/analyze-patterns`
+
+Identify behavioral patterns from notes (sync API).
+
+**Request:**
+```json
+{
+  "all_notes": "All user's notes combined..."
+}
+```
+
+**Response:**
+```json
+{
+  "success": true,
+  "result": {
+    "patterns": [
+      {
+        "pattern": "Pattern name",
+        "description": "Pattern description",
+        "frequency": "Often/Sometimes/Rarely"
+      }
+    ]
+  }
+}
+```
+
+---
+
+### GET `/api/default-voices`
+
+Get default voice configurations (no auth required).
+
+**Response:**
+```json
+{
+  "Logic": {
+    "tagline": "Wield raw intellectual power...",
+    "icon": "brain",
+    "color": "blue"
+  },
+  "Rhetoric": {...},
+  ...
+}
+```
+
+---
+
+## Error Responses
+
+All errors follow this format:
+
+```json
+{
+  "detail": "Error message"
+}
+```
+
+Common status codes:
+- `400` - Bad request (missing/invalid params)
+- `401` - Unauthorized (missing/invalid token)
+- `404` - Not found
+- `500` - Internal server error
+
+---
+
+## Development
+
+**Start server:**
+```bash
+cd backend
+source .venv/bin/activate
+python server.py
+```
+
+**Run tests:**
+```bash
+python test_migration.py           # Test migration logic
+python test_real_migration.py      # Test with real data
+```
+
+**API Docs:**
+- Interactive docs: http://localhost:8765/docs
+- PolyCLI control panel: http://localhost:8765/polycli
+
+---
+
+## Database
+
+SQLite database at `backend/data/ink-and-memory.db`
+
+**Initialize/reset:**
+```python
+from database import init_db
+init_db()
+```
+
+**Tables:**
+- `users` - User accounts
+- `user_sessions` - Editor sessions
+- `daily_pictures` - Generated images
+- `user_preferences` - User settings
+- `analysis_reports` - Analysis results
+- `auth_sessions` - Session tokens (optional)
+- `schema_version` - Migration tracking

*** FILE: backend/LOCALSTORAGE_AUDIT.md ***
@@ -0,0 +1,157 @@
+# localStorage Audit - Complete Data Inventory
+
+## All localStorage Keys Currently Used
+
+### 1. **Editor State** (CRITICAL)
+- **Key**: `ink_memory_state`
+- **Location**: `App.tsx`
+- **Content**: Full EditorState (cells, commentors, current session)
+- **Size**: ~50-200KB per session
+- **Migration**: ‚úÖ Save to `user_sessions` table
+
+### 2. **Calendar Entries** (CRITICAL)
+- **Key**: `calendar-entries`
+- **Location**: `calendarStorage.ts`
+- **Content**: `{ "YYYY-MM-DD": [{ id, timestamp, state, firstLine }] }`
+- **Size**: Can be LARGE (multiple full EditorStates)
+- **Migration**: ‚úÖ Extract each entry and save as separate session in `user_sessions`
+
+### 3. **Daily Pictures** (CRITICAL - QUOTA PROBLEM!)
+- **Key**: `daily-pictures`
+- **Location**: `CollectionsView.tsx`
+- **Content**: `[{ date, base64, prompt }]`
+- **Size**: **1.5MB per image** ‚Üê This is why we need database!
+- **Migration**: ‚úÖ Save to `daily_pictures` table
+
+### 4. **Voice Customizations**
+- **Key**: `voice-customizations`
+- **Location**: `voiceStorage.ts`
+- **Content**: `{ [voiceKey]: { name, tagline, icon, color, enabled } }`
+- **Size**: ~5-20KB
+- **Migration**: ‚úÖ Save to `user_preferences.voice_configs_json`
+
+### 5. **Meta Prompt**
+- **Key**: `meta-prompt`
+- **Location**: `voiceStorage.ts`
+- **Content**: String (global instructions for all voices)
+- **Size**: ~1-5KB
+- **Migration**: ‚úÖ Save to `user_preferences.meta_prompt`
+
+### 6. **State Config**
+- **Key**: `state-config`
+- **Location**: `voiceStorage.ts`
+- **Content**: `{ greeting, states: { happy: {name, prompt}, ... } }`
+- **Size**: ~2-10KB
+- **Migration**: ‚úÖ Save to `user_preferences.state_config_json`
+
+### 7. **Selected State**
+- **Key**: `selected-state`
+- **Location**: `App.tsx`
+- **Content**: String (e.g., "happy", "ok", "unhappy")
+- **Size**: ~10 bytes
+- **Migration**: ‚úÖ Save to `user_preferences.selected_state`
+
+### 8. **Analysis Reports History**
+- **Key**: `analysis-reports-history`
+- **Location**: `AnalysisView.tsx`
+- **Content**: `[{ timestamp, type, data, allNotes }]`
+- **Size**: ~10-50KB (limited to 10 reports)
+- **Migration**: ‚ö†Ô∏è **MISSING FROM DATABASE!** Need new table
+
+### 9. **Document Storage** (OLD SYSTEM - probably unused?)
+- **Key**: `ink_and_memory_document`
+- **Location**: `documentStorage.ts`
+- **Content**: `{ document, conversations, lastModified }`
+- **Size**: Unknown
+- **Migration**: ‚ö†Ô∏è **Check if this is still used** - might be deprecated
+
+## Database Schema Gaps Found
+
+### ‚ùå Missing Table: `analysis_reports`
+```sql
+CREATE TABLE analysis_reports (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  user_id INTEGER NOT NULL,
+  report_type TEXT NOT NULL,  -- 'echoes', 'traits', 'patterns'
+  report_data_json TEXT NOT NULL,
+  all_notes_text TEXT,  -- The text that was analyzed
+  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
+  FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE
+);
+```
+
+### ‚ùå Missing: Calendar Entry Handling
+- Calendar entries contain full EditorStates
+- Need to extract each calendar entry as a separate session
+- Need to preserve `date` and `timestamp` metadata
+
+## Migration Strategy
+
+### Phase 1: On First Login (Auto-Migration)
+```javascript
+async function migrateLocalStorageToServer() {
+  const migrationData = {
+    // Current session
+    currentSession: localStorage.getItem('ink_memory_state'),
+
+    // Calendar entries (extract as separate sessions)
+    calendarEntries: localStorage.getItem('calendar-entries'),
+
+    // Pictures (THE BIG ONE!)
+    dailyPictures: localStorage.getItem('daily-pictures'),
+
+    // Preferences
+    voiceCustomizations: localStorage.getItem('voice-customizations'),
+    metaPrompt: localStorage.getItem('meta-prompt'),
+    stateConfig: localStorage.getItem('state-config'),
+    selectedState: localStorage.getItem('selected-state'),
+
+    // Reports
+    analysisReports: localStorage.getItem('analysis-reports-history'),
+
+    // Old document storage (check if used)
+    oldDocument: localStorage.getItem('ink_and_memory_document')
+  };
+
+  // POST to /api/import-local-data
+  await fetch('/api/import-local-data', {
+    method: 'POST',
+    headers: { 'Authorization': `Bearer ${token}` },
+    body: JSON.stringify(migrationData)
+  });
+
+  // Clear localStorage (keep only auth token)
+  clearLocalStorage();
+}
+```
+
+### Phase 2: Server-First Operation
+After migration:
+- localStorage only stores: auth token
+- All data fetched from server on load
+- Auto-save to server every 30s
+
+## Size Estimates
+
+**Typical user localStorage usage:**
+- Current session: ~100KB
+- Calendar entries (30 days): ~3MB (30 sessions √ó 100KB)
+- Daily pictures (7 days): **10.5MB** ‚Üê EXCEEDS QUOTA!
+- Preferences: ~30KB
+- Reports: ~50KB
+- **TOTAL: ~13.7MB** ‚Üê Way over 5-10MB limit!
+
+**With database:**
+- localStorage: ~1KB (just token)
+- SQLite: Unlimited (file-based)
+
+## Action Items
+
+1. ‚úÖ Add `analysis_reports` table to database schema
+2. ‚úÖ Update `import_user_data()` to handle:
+   - Calendar entries extraction
+   - Analysis reports
+   - Old document storage check
+3. ‚úÖ Create comprehensive migration endpoint `/api/import-local-data`
+4. ‚ö†Ô∏è Test migration with real localStorage data
+5. ‚ö†Ô∏è Add data validation (check JSON parsing before import)

*** FILE: backend/MIGRATION_SUMMARY.md ***
@@ -0,0 +1,216 @@
+# localStorage Migration - Complete Picture
+
+## üö® Critical Discovery
+
+**Current localStorage usage: ~13.7MB per typical user**
+- localStorage limit: 5-10MB
+- **You've been living on borrowed time!**
+
+### The Quota Bomb:
+```
+Current session:      100 KB
+Calendar (30 days):  3000 KB  (30 sessions)
+Pictures (7 days):  10500 KB  ‚Üê THE PROBLEM!
+Preferences:           30 KB
+Reports:               50 KB
+‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
+TOTAL:             ~13680 KB  ‚Üê 13.7 MB!
+```
+
+**This explains the QuotaExceededError!**
+
+---
+
+## ‚úÖ Complete Data Inventory
+
+### 9 localStorage Keys Found:
+
+1. ‚úÖ `ink_memory_state` ‚Üí `user_sessions` table
+2. ‚úÖ `calendar-entries` ‚Üí Extract each entry as separate session
+3. ‚úÖ `daily-pictures` ‚Üí `daily_pictures` table
+4. ‚úÖ `voice-customizations` ‚Üí `user_preferences.voice_configs_json`
+5. ‚úÖ `meta-prompt` ‚Üí `user_preferences.meta_prompt`
+6. ‚úÖ `state-config` ‚Üí `user_preferences.state_config_json`
+7. ‚úÖ `selected-state` ‚Üí `user_preferences.selected_state`
+8. ‚úÖ `analysis-reports-history` ‚Üí `analysis_reports` table (NEW!)
+9. ‚ö†Ô∏è `ink_and_memory_document` ‚Üí Check if still used (might be old)
+
+---
+
+## üì¶ Database Schema (Complete)
+
+### Tables Created:
+```sql
+users                -- Email, password, display name
+user_sessions        -- Editor states (replaces localStorage sessions)
+daily_pictures       -- Images (solves quota problem!)
+user_preferences     -- Voice configs, meta prompt, state config
+analysis_reports     -- Echoes, traits, patterns (NEW!)
+auth_sessions        -- Session tokens
+schema_version       -- Migration tracking
+```
+
+### Key Features:
+- ‚úÖ WAL mode enabled (concurrent reads + 1 write)
+- ‚úÖ Foreign keys enforced (CASCADE DELETE)
+- ‚úÖ Indexes on user_id for fast queries
+- ‚úÖ JSON columns for flexibility (no schema migrations needed)
+
+---
+
+## üîÑ Migration Plan
+
+### On First Login:
+```javascript
+// 1. Detect localStorage data
+if (hasLocalStorageData()) {
+  // 2. Show banner
+  <Banner>
+    üíæ Migrating your local data to your account...
+  </Banner>
+
+  // 3. Extract all data
+  const migrationData = extractAllLocalStorageData();
+
+  // 4. POST to server
+  await fetch('/api/import-local-data', {
+    method: 'POST',
+    headers: { 'Authorization': `Bearer ${token}` },
+    body: JSON.stringify(migrationData)
+  });
+
+  // 5. Verify migration
+  const verify = await fetch('/api/verify-migration');
+
+  // 6. Clear localStorage (keep only token)
+  if (verify.ok) {
+    clearLocalStorage();
+    localStorage.setItem('auth-token', token);
+  }
+}
+```
+
+### Special Cases:
+
+**Calendar Entries (Complex!):**
+```javascript
+// calendar-entries: { "2025-11-01": [entry1, entry2], "2025-11-02": [...] }
+// Each entry contains full EditorState
+
+function extractCalendarEntries(calendarData) {
+  const sessions = [];
+
+  for (const [date, entries] of Object.entries(calendarData)) {
+    for (const entry of entries) {
+      sessions.push({
+        id: entry.id,
+        name: `${date} - ${entry.firstLine}`,
+        editor_state: entry.state,
+        // Preserve original timestamp
+        created_at: new Date(entry.timestamp).toISOString()
+      });
+    }
+  }
+
+  return sessions;
+}
+```
+
+**Pictures (The Big One!):**
+```javascript
+// pictures: [{ date, base64, prompt }]
+// Each base64 string is ~1.5MB!
+
+function extractPictures(picturesData) {
+  return picturesData.map(p => ({
+    date: p.date,
+    image_base64: p.base64,  // Goes straight to SQLite (unlimited)
+    prompt: p.prompt
+  }));
+}
+```
+
+---
+
+## üéØ Guest Mode Strategy
+
+### Before Login:
+```javascript
+// localStorage works normally
+localStorage.setItem('ink_memory_state', state);
+localStorage.setItem('daily-pictures', pictures);
+
+// ‚ùå But blocks image generation if >5MB used
+if (getLocalStorageSize() > 5 * 1024 * 1024) {
+  alert('‚ö†Ô∏è Storage full! Create account to generate images.');
+  return;
+}
+```
+
+### After Login:
+```javascript
+// Server becomes primary
+await fetch('/api/save-session', { body: state });
+
+// localStorage only stores token
+localStorage.clear();
+localStorage.setItem('auth-token', token);
+```
+
+### Image Generation Gate:
+```javascript
+async function generateImage() {
+  if (!isLoggedIn()) {
+    showLoginPrompt('üé® Create a free account to generate images');
+    return;
+  }
+
+  // Logged in users: unlimited images!
+  const image = await fetch('/api/generate-image', ...);
+}
+```
+
+---
+
+## üìä Storage Comparison
+
+### Before (localStorage):
+- Max: 10MB (hard limit)
+- Current usage: ~13.7MB (OVER LIMIT!)
+- Pictures: 7 max before quota error
+- Sync: None (single device only)
+- Backup: None (data lost if browser cache cleared)
+
+### After (SQLite):
+- Max: Unlimited (file-based)
+- Current usage: Irrelevant
+- Pictures: Unlimited
+- Sync: Across devices
+- Backup: Daily automated backups
+
+---
+
+## üöÄ Next Steps
+
+1. [x] Database schema complete
+2. [x] Migration functions ready
+3. [ ] Create auth module (JWT, bcrypt)
+4. [ ] Add auth endpoints to FastAPI
+5. [ ] Create frontend login/register UI
+6. [ ] Implement auto-migration on first login
+7. [ ] Add image generation gate
+8. [ ] Test with real localStorage data
+9. [ ] Deploy to production
+
+---
+
+## ‚ö†Ô∏è Important Notes
+
+1. **No data loss**: Migration keeps localStorage until verified
+2. **Rollback safe**: Can revert to localStorage if migration fails
+3. **Incremental**: Users can keep using app during migration
+4. **Guest mode works**: Anonymous users can still use app (limited)
+
+---
+
+**Ready to proceed with auth implementation!**

*** FILE: backend/auth.py ***
@@ -0,0 +1,96 @@
+#!/usr/bin/env python3
+"""
+Authentication module for Ink & Memory.
+
+Provides JWT token generation/verification and password hashing.
+"""
+
+import jwt
+import bcrypt
+from datetime import datetime, timedelta
+from typing import Optional
+import os
+
+# @@@ JWT Configuration
+SECRET_KEY = os.environ.get("JWT_SECRET_KEY", "dev-secret-change-in-production-123456789")
+ALGORITHM = "HS256"
+ACCESS_TOKEN_EXPIRE_MINUTES = 60 * 24 * 7  # 7 days
+
+def hash_password(password: str) -> str:
+    """Hash a password using bcrypt."""
+    return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
+
+def verify_password(password: str, password_hash: str) -> bool:
+    """Verify a password against its hash."""
+    return bcrypt.checkpw(password.encode('utf-8'), password_hash.encode('utf-8'))
+
+def create_access_token(user_id: int, email: str) -> str:
+    """
+    Create JWT access token.
+
+    Args:
+        user_id: User ID
+        email: User email
+
+    Returns:
+        JWT token string
+    """
+    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
+
+    payload = {
+        "sub": str(user_id),  # Subject: user ID
+        "email": email,
+        "exp": expire,  # Expiration time
+        "iat": datetime.utcnow()  # Issued at
+    }
+
+    token = jwt.encode(payload, SECRET_KEY, algorithm=ALGORITHM)
+    return token
+
+def verify_access_token(token: str) -> Optional[dict]:
+    """
+    Verify JWT token and extract payload.
+
+    Args:
+        token: JWT token string
+
+    Returns:
+        Payload dict with user_id and email, or None if invalid
+    """
+    try:
+        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
+        user_id = int(payload.get("sub"))
+        email = payload.get("email")
+
+        if user_id is None or email is None:
+            return None
+
+        return {
+            "user_id": user_id,
+            "email": email
+        }
+    except jwt.ExpiredSignatureError:
+        print("Token expired")
+        return None
+    except jwt.InvalidTokenError:
+        print("Invalid token")
+        return None
+
+def extract_token_from_header(authorization: Optional[str]) -> Optional[str]:
+    """
+    Extract JWT token from Authorization header.
+
+    Args:
+        authorization: Authorization header value (e.g., "Bearer <token>")
+
+    Returns:
+        Token string or None
+    """
+    if not authorization:
+        return None
+
+    parts = authorization.split()
+    if len(parts) != 2 or parts[0].lower() != "bearer":
+        return None
+
+    return parts[1]

*** FILE: backend/database.py ***
@@ -0,0 +1,446 @@
+#!/usr/bin/env python3
+"""
+SQLite database setup and migrations for Ink & Memory.
+
+Schema:
+- users: User accounts (email, password_hash)
+- user_sessions: Editor sessions (editor state JSON)
+- daily_pictures: Generated images (base64)
+- user_preferences: Voice configs, meta prompts, etc.
+"""
+
+import sqlite3
+import os
+from pathlib import Path
+from datetime import datetime, timedelta
+import json
+
+# Database location
+DB_DIR = Path(__file__).parent / "data"
+DB_PATH = DB_DIR / "ink-and-memory.db"
+
+# Ensure data directory exists
+DB_DIR.mkdir(exist_ok=True)
+
+def get_db():
+    """Get database connection with WAL mode enabled."""
+    db = sqlite3.connect(DB_PATH)
+    db.row_factory = sqlite3.Row  # Access columns by name
+
+    # @@@ Enable WAL mode for concurrent reads + 1 write
+    db.execute("PRAGMA journal_mode=WAL")
+    db.execute("PRAGMA foreign_keys=ON")
+
+    return db
+
+def init_db():
+    """Initialize database with schema and migrations."""
+    db = get_db()
+
+    # Check current schema version
+    try:
+        result = db.execute("SELECT MAX(version) FROM schema_version").fetchone()
+        current_version = result[0] if result[0] else 0
+    except sqlite3.OperationalError:
+        # schema_version table doesn't exist yet
+        current_version = 0
+
+    # Run migrations
+    if current_version < 1:
+        migrate_v1(db)
+
+    db.commit()
+    db.close()
+
+    print(f"‚úÖ Database initialized at {DB_PATH}")
+
+def migrate_v1(db):
+    """Initial schema - users, sessions, pictures, preferences."""
+    print("üì¶ Running migration v1: Initial schema")
+
+    # Schema version tracking
+    db.execute("""
+    CREATE TABLE IF NOT EXISTS schema_version (
+      version INTEGER PRIMARY KEY,
+      applied_at DATETIME DEFAULT CURRENT_TIMESTAMP
+    )
+    """)
+
+    # Users table
+    db.execute("""
+    CREATE TABLE IF NOT EXISTS users (
+      id INTEGER PRIMARY KEY AUTOINCREMENT,
+      email TEXT UNIQUE NOT NULL,
+      password_hash TEXT NOT NULL,
+      display_name TEXT,
+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP
+    )
+    """)
+
+    # User sessions (editor states)
+    db.execute("""
+    CREATE TABLE IF NOT EXISTS user_sessions (
+      id TEXT PRIMARY KEY,
+      user_id INTEGER NOT NULL,
+      name TEXT,
+      editor_state_json TEXT NOT NULL,
+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
+      updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE
+    )
+    """)
+    db.execute("CREATE INDEX IF NOT EXISTS idx_sessions_user ON user_sessions(user_id)")
+
+    # Daily pictures (generated images)
+    db.execute("""
+    CREATE TABLE IF NOT EXISTS daily_pictures (
+      id INTEGER PRIMARY KEY AUTOINCREMENT,
+      user_id INTEGER NOT NULL,
+      date TEXT NOT NULL,
+      image_base64 TEXT NOT NULL,
+      prompt TEXT,
+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,
+      UNIQUE(user_id, date)
+    )
+    """)
+    db.execute("CREATE INDEX IF NOT EXISTS idx_pictures_user_date ON daily_pictures(user_id, date)")
+
+    # User preferences (voice configs, meta prompts, etc.)
+    db.execute("""
+    CREATE TABLE IF NOT EXISTS user_preferences (
+      user_id INTEGER PRIMARY KEY,
+      voice_configs_json TEXT,
+      meta_prompt TEXT,
+      state_config_json TEXT,
+      selected_state TEXT,
+      updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE
+    )
+    """)
+
+    # Auth sessions (JWT alternative - optional, using JWT for now)
+    db.execute("""
+    CREATE TABLE IF NOT EXISTS auth_sessions (
+      token TEXT PRIMARY KEY,
+      user_id INTEGER NOT NULL,
+      expires_at DATETIME NOT NULL,
+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE
+    )
+    """)
+    db.execute("CREATE INDEX IF NOT EXISTS idx_auth_user ON auth_sessions(user_id)")
+
+    # @@@ Analysis reports (echoes, traits, patterns)
+    db.execute("""
+    CREATE TABLE IF NOT EXISTS analysis_reports (
+      id INTEGER PRIMARY KEY AUTOINCREMENT,
+      user_id INTEGER NOT NULL,
+      report_type TEXT NOT NULL,
+      report_data_json TEXT NOT NULL,
+      all_notes_text TEXT,
+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE
+    )
+    """)
+    db.execute("CREATE INDEX IF NOT EXISTS idx_reports_user ON analysis_reports(user_id, created_at)")
+
+    # Record migration
+    db.execute("INSERT INTO schema_version (version) VALUES (1)")
+
+    print("‚úÖ Migration v1 completed")
+
+# ========== User Management ==========
+
+def create_user(email: str, password_hash: str, display_name: str = None) -> int:
+    """Create a new user. Returns user_id."""
+    db = get_db()
+    try:
+        cursor = db.execute(
+            "INSERT INTO users (email, password_hash, display_name) VALUES (?, ?, ?)",
+            (email, password_hash, display_name)
+        )
+        user_id = cursor.lastrowid
+        db.commit()
+        return user_id
+    except sqlite3.IntegrityError:
+        raise ValueError("Email already exists")
+    finally:
+        db.close()
+
+def get_user_by_email(email: str):
+    """Get user by email. Returns dict or None."""
+    db = get_db()
+    try:
+        row = db.execute(
+            "SELECT id, email, password_hash, display_name, created_at FROM users WHERE email = ?",
+            (email,)
+        ).fetchone()
+        return dict(row) if row else None
+    finally:
+        db.close()
+
+def get_user_by_id(user_id: int):
+    """Get user by ID. Returns dict or None."""
+    db = get_db()
+    try:
+        row = db.execute(
+            "SELECT id, email, display_name, created_at FROM users WHERE id = ?",
+            (user_id,)
+        ).fetchone()
+        return dict(row) if row else None
+    finally:
+        db.close()
+
+# ========== Session Storage ==========
+
+def save_session(user_id: int, session_id: str, editor_state: dict, name: str = None):
+    """Save or update a user session."""
+    db = get_db()
+    try:
+        db.execute("""
+        INSERT INTO user_sessions (id, user_id, name, editor_state_json, updated_at)
+        VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
+        ON CONFLICT(id) DO UPDATE SET
+          editor_state_json = excluded.editor_state_json,
+          name = excluded.name,
+          updated_at = CURRENT_TIMESTAMP
+        """, (session_id, user_id, name, json.dumps(editor_state)))
+        db.commit()
+    finally:
+        db.close()
+
+def get_session(user_id: int, session_id: str):
+    """Get a specific session. Returns dict or None."""
+    db = get_db()
+    try:
+        row = db.execute("""
+        SELECT id, name, editor_state_json, created_at, updated_at
+        FROM user_sessions
+        WHERE user_id = ? AND id = ?
+        """, (user_id, session_id)).fetchone()
+
+        if row:
+            result = dict(row)
+            result['editor_state'] = json.loads(result['editor_state_json'])
+            del result['editor_state_json']
+            return result
+        return None
+    finally:
+        db.close()
+
+def list_sessions(user_id: int):
+    """List all sessions for a user."""
+    db = get_db()
+    try:
+        rows = db.execute("""
+        SELECT id, name, created_at, updated_at
+        FROM user_sessions
+        WHERE user_id = ?
+        ORDER BY updated_at DESC
+        """, (user_id,)).fetchall()
+        return [dict(row) for row in rows]
+    finally:
+        db.close()
+
+def delete_session(user_id: int, session_id: str):
+    """Delete a session."""
+    db = get_db()
+    try:
+        db.execute("DELETE FROM user_sessions WHERE user_id = ? AND id = ?", (user_id, session_id))
+        db.commit()
+    finally:
+        db.close()
+
+# ========== Daily Pictures ==========
+
+def save_daily_picture(user_id: int, date: str, image_base64: str, prompt: str = None):
+    """Save or update daily picture."""
+    db = get_db()
+    try:
+        db.execute("""
+        INSERT INTO daily_pictures (user_id, date, image_base64, prompt)
+        VALUES (?, ?, ?, ?)
+        ON CONFLICT(user_id, date) DO UPDATE SET
+          image_base64 = excluded.image_base64,
+          prompt = excluded.prompt
+        """, (user_id, date, image_base64, prompt))
+        db.commit()
+    finally:
+        db.close()
+
+def get_daily_pictures(user_id: int, limit: int = 30):
+    """Get recent daily pictures."""
+    db = get_db()
+    try:
+        rows = db.execute("""
+        SELECT date, image_base64, prompt, created_at
+        FROM daily_pictures
+        WHERE user_id = ?
+        ORDER BY date DESC
+        LIMIT ?
+        """, (user_id, limit)).fetchall()
+        return [dict(row) for row in rows]
+    finally:
+        db.close()
+
+# ========== User Preferences ==========
+
+def save_preferences(user_id: int, voice_configs: dict = None, meta_prompt: str = None,
+                    state_config: dict = None, selected_state: str = None):
+    """Save or update user preferences."""
+    db = get_db()
+    try:
+        # Check if preferences exist
+        existing = db.execute("SELECT user_id FROM user_preferences WHERE user_id = ?", (user_id,)).fetchone()
+
+        if existing:
+            # Update
+            updates = []
+            params = []
+            if voice_configs is not None:
+                updates.append("voice_configs_json = ?")
+                params.append(json.dumps(voice_configs))
+            if meta_prompt is not None:
+                updates.append("meta_prompt = ?")
+                params.append(meta_prompt)
+            if state_config is not None:
+                updates.append("state_config_json = ?")
+                params.append(json.dumps(state_config))
+            if selected_state is not None:
+                updates.append("selected_state = ?")
+                params.append(selected_state)
+
+            if updates:
+                updates.append("updated_at = CURRENT_TIMESTAMP")
+                params.append(user_id)
+                db.execute(f"UPDATE user_preferences SET {', '.join(updates)} WHERE user_id = ?", params)
+        else:
+            # Insert
+            db.execute("""
+            INSERT INTO user_preferences (user_id, voice_configs_json, meta_prompt, state_config_json, selected_state)
+            VALUES (?, ?, ?, ?, ?)
+            """, (user_id,
+                  json.dumps(voice_configs) if voice_configs else None,
+                  meta_prompt,
+                  json.dumps(state_config) if state_config else None,
+                  selected_state))
+
+        db.commit()
+    finally:
+        db.close()
+
+def get_preferences(user_id: int):
+    """Get user preferences. Returns dict or None."""
+    db = get_db()
+    try:
+        row = db.execute("""
+        SELECT voice_configs_json, meta_prompt, state_config_json, selected_state, updated_at
+        FROM user_preferences
+        WHERE user_id = ?
+        """, (user_id,)).fetchone()
+
+        if row:
+            result = dict(row)
+            result['voice_configs'] = json.loads(result['voice_configs_json']) if result['voice_configs_json'] else None
+            result['state_config'] = json.loads(result['state_config_json']) if result['state_config_json'] else None
+            del result['voice_configs_json']
+            del result['state_config_json']
+            return result
+        return None
+    finally:
+        db.close()
+
+# ========== Analysis Reports ==========
+
+def save_analysis_report(user_id: int, report_type: str, report_data: dict, all_notes_text: str = None):
+    """Save an analysis report."""
+    db = get_db()
+    try:
+        db.execute("""
+        INSERT INTO analysis_reports (user_id, report_type, report_data_json, all_notes_text)
+        VALUES (?, ?, ?, ?)
+        """, (user_id, report_type, json.dumps(report_data), all_notes_text))
+        db.commit()
+    finally:
+        db.close()
+
+def get_analysis_reports(user_id: int, limit: int = 10):
+    """Get recent analysis reports."""
+    db = get_db()
+    try:
+        rows = db.execute("""
+        SELECT id, report_type, report_data_json, created_at
+        FROM analysis_reports
+        WHERE user_id = ?
+        ORDER BY created_at DESC
+        LIMIT ?
+        """, (user_id, limit)).fetchall()
+
+        results = []
+        for row in rows:
+            result = dict(row)
+            result['report_data'] = json.loads(result['report_data_json'])
+            del result['report_data_json']
+            results.append(result)
+        return results
+    finally:
+        db.close()
+
+# ========== Bulk Import (for localStorage migration) ==========
+
+def import_user_data(user_id: int, sessions: list, pictures: list, preferences: dict, reports: list = None):
+    """
+    Bulk import user data from localStorage migration.
+
+    Args:
+        user_id: User ID
+        sessions: List of {id, name, editor_state}
+        pictures: List of {date, image_base64, prompt}
+        preferences: {voice_configs, meta_prompt, state_config, selected_state}
+        reports: Optional list of {type, data, allNotes, timestamp}
+    """
+    db = get_db()
+    try:
+        # Import sessions
+        for session in sessions:
+            db.execute("""
+            INSERT OR REPLACE INTO user_sessions (id, user_id, name, editor_state_json)
+            VALUES (?, ?, ?, ?)
+            """, (session['id'], user_id, session.get('name'), json.dumps(session['editor_state'])))
+
+        # Import pictures
+        for picture in pictures:
+            db.execute("""
+            INSERT OR REPLACE INTO daily_pictures (user_id, date, image_base64, prompt)
+            VALUES (?, ?, ?, ?)
+            """, (user_id, picture['date'], picture['image_base64'], picture.get('prompt')))
+
+        # Import preferences
+        if preferences:
+            db.execute("""
+            INSERT OR REPLACE INTO user_preferences
+            (user_id, voice_configs_json, meta_prompt, state_config_json, selected_state)
+            VALUES (?, ?, ?, ?, ?)
+            """, (user_id,
+                  json.dumps(preferences.get('voice_configs')) if preferences.get('voice_configs') else None,
+                  preferences.get('meta_prompt'),
+                  json.dumps(preferences.get('state_config')) if preferences.get('state_config') else None,
+                  preferences.get('selected_state')))
+
+        # Import analysis reports
+        if reports:
+            for report in reports:
+                db.execute("""
+                INSERT INTO analysis_reports (user_id, report_type, report_data_json, all_notes_text)
+                VALUES (?, ?, ?, ?)
+                """, (user_id, report.get('type', 'unknown'), json.dumps(report.get('data', {})), report.get('allNotes')))
+
+        db.commit()
+        print(f"‚úÖ Imported {len(sessions)} sessions, {len(pictures)} pictures, {len(reports or [])} reports for user {user_id}")
+    finally:
+        db.close()
+
+if __name__ == "__main__":
+    # Initialize database
+    init_db()

*** FILE: backend/server.py ***
@@ -1,12 +1,23 @@
 #!/usr/bin/env python3
-"""Stateless voice analysis server - no state tracking, just returns new comments."""
+"""FastAPI-based voice analysis server with sync API support."""
 
-import time
+import httpx
+from fastapi import FastAPI, HTTPException, Depends, Header
+from fastapi.middleware.cors import CORSMiddleware
 from polycli.orchestration.session_registry import session_def, get_registry
+from polycli.integrations.fastapi import mount_control_panel
 from polycli import PolyAgent
 from stateless_analyzer import analyze_stateless
 import config
 from proxy_config import get_image_api_proxies
+from typing import Optional
+from pydantic import BaseModel
+
+# Import database and auth modules
+import database
+import auth
+
+# ========== Session Definitions (PolyCLI) ==========
 
 @session_def(
     name="Chat with Voice",
@@ -23,20 +34,7 @@
     category="Chat"
 )
 def chat_with_voice(voice_name: str, voice_config: dict, conversation_history: list, user_message: str, original_text: str = "", meta_prompt: str = "", state_prompt: str = ""):
-    """
-    Chat with a specific voice persona.
-
-    Args:
-        voice_name: Name of the voice (e.g., "Logic", "Drama")
-        voice_config: Voice configuration with tagline, icon, color
-        conversation_history: Previous messages in the conversation
-        user_message: The user's new message
-        original_text: The user's original writing text
-        meta_prompt: Additional instructions that apply to all voices
-
-    Returns:
-        Dictionary with assistant's response
-    """
+    """Chat with a specific voice persona."""
     print(f"\n{'='*60}")
     print(f"üí¨ chat_with_voice() called")
     print(f"   Voice: {voice_name}")
@@ -79,7 +77,7 @@ def chat_with_voice(voice_name: str, voice_config: dict, conversation_history: l
 Additional instructions:
 {meta_prompt.strip()}"""
 
-    # @@@ Add state prompt if available (between meta and voice-specific)
+    # Add state prompt if available
     if state_prompt and state_prompt.strip():
         system_prompt += f"""
 
@@ -126,21 +124,7 @@ def chat_with_voice(voice_name: str, voice_config: dict, conversation_history: l
     category="Analysis"
 )
 def analyze_text(text: str, session_id: str, voices: dict = None, applied_comments: list = None, meta_prompt: str = "", state_prompt: str = "", overlapped_phrases: list = None):
-    """
-    Stateless analysis - returns ONE new comment based on text and applied comments.
-
-    Args:
-        text: Text to analyze (should be complete sentences only)
-        session_id: Session ID (for future use)
-        voices: Voice configuration
-        applied_comments: List of already applied comments (to avoid duplicates)
-        meta_prompt: Additional instructions that apply to all voices
-        state_prompt: User's current emotional state prompt
-        overlapped_phrases: Phrases that were rejected due to overlap (feedback loop)
-
-    Returns:
-        Dictionary with single new voice (or empty list)
-    """
+    """Stateless analysis - returns ONE new comment based on text and applied comments."""
     print(f"\n{'='*60}")
     print(f"üéØ Stateless analyze_text() called")
     print(f"   Text: {text[:100]}...")
@@ -319,21 +303,15 @@ def analyze_patterns(all_notes: str):
     category="Creative"
 )
 def generate_daily_picture(all_notes: str):
-    """Generate an image based on the essence of user's daily notes.
-
-    Uses a two-step process:
-    1. LLM analyzes notes and creates artistic image description
-    2. Image generation model creates the image
-    """
+    """Generate an image based on the essence of user's daily notes."""
     print(f"\n{'='*60}")
     print(f"üé® generate_daily_picture() called")
     print(f"   Notes length: {len(all_notes)} chars")
     print(f"{'='*60}\n")
 
     import requests
 
-    # @@@ Step 1: Convert notes to artistic image description using Claude Haiku
-
+    # Step 1: Convert notes to artistic image description using Claude Haiku
     description_prompt = f"""Read these personal notes and create a vivid, artistic image description that captures the essence, mood, and themes.
 
 Notes:
@@ -353,7 +331,7 @@ def generate_daily_picture(all_notes: str):
 
     print("üß† Creating image description from notes with Claude Haiku...")
 
-    # @@@ Use proxy for GFW bypass (if configured)
+    # Use proxy for GFW bypass (if configured)
     proxies = get_image_api_proxies()
 
     claude_response = requests.post(
@@ -382,7 +360,7 @@ def generate_daily_picture(all_notes: str):
 
     print(f"üìù Image description: {image_description}")
 
-    # @@@ Step 2: Generate image from description with retry logic
+    # Step 2: Generate image from description with retry logic
     url = f"{config.IMAGE_API_ENDPOINT}/chat/completions"
     headers = {
         "Authorization": f"Bearer {config.IMAGE_API_KEY}",
@@ -400,7 +378,7 @@ def generate_daily_picture(all_notes: str):
         "max_tokens": config.IMAGE_MAX_TOKENS
     }
 
-    # @@@ Retry logic with increasing timeouts
+    # Retry logic with increasing timeouts
     for attempt in range(1, config.IMAGE_RETRY_MAX_ATTEMPTS + 1):
         try:
             timeout_seconds = config.IMAGE_RETRY_BASE_TIMEOUT + (attempt - 1) * config.IMAGE_RETRY_TIMEOUT_INCREMENT
@@ -456,43 +434,590 @@ def generate_daily_picture(all_notes: str):
 
     return {"image_base64": None, "error": "All retry attempts failed"}
 
+# ========== FastAPI Application ==========
+
+app = FastAPI(
+    title="Ink & Memory API",
+    description="Voice analysis and creative generation API",
+    version="2.0.0"
+)
+
+# Add CORS middleware
+app.add_middleware(
+    CORSMiddleware,
+    allow_origins=["*"],  # In production, restrict to specific origins
+    allow_credentials=True,
+    allow_methods=["*"],
+    allow_headers=["*"],
+)
+
+# ========== Request/Response Models ==========
+
+class RegisterRequest(BaseModel):
+    email: str
+    password: str
+    display_name: Optional[str] = None
+
+class LoginRequest(BaseModel):
+    email: str
+    password: str
+
+class TokenResponse(BaseModel):
+    token: str
+    user: dict
+
+class ImportDataRequest(BaseModel):
+    currentSession: Optional[str] = None
+    calendarEntries: Optional[str] = None
+    dailyPictures: Optional[str] = None
+    voiceCustomizations: Optional[str] = None
+    metaPrompt: Optional[str] = None
+    stateConfig: Optional[str] = None
+    selectedState: Optional[str] = None
+    analysisReports: Optional[str] = None
+    oldDocument: Optional[str] = None
+
+# ========== Auth Dependency ==========
+
+def get_current_user(authorization: Optional[str] = Header(None)) -> dict:
+    """
+    Dependency to extract and verify JWT token from Authorization header.
+
+    Raises:
+        HTTPException 401 if token is missing or invalid
+    """
+    token = auth.extract_token_from_header(authorization)
+    if not token:
+        raise HTTPException(status_code=401, detail="Missing authorization token")
+
+    user_data = auth.verify_access_token(token)
+    if not user_data:
+        raise HTTPException(status_code=401, detail="Invalid or expired token")
+
+    return user_data
+
+# ========== Custom API Endpoints (Clean Interface) ==========
+
+@app.get("/")
+def root():
+    """Root endpoint"""
+    return {
+        "service": "Ink & Memory API",
+        "version": "2.0.0",
+        "docs": "/docs",
+        "control_panel": "/polycli"
+    }
+
+# ========== Auth Endpoints ==========
+
+@app.post("/api/register", response_model=TokenResponse)
+def register(request: RegisterRequest):
+    """
+    Register a new user.
+
+    Returns JWT token and user info.
+    """
+    # Validate input
+    if not request.email or not request.password:
+        raise HTTPException(status_code=400, detail="Email and password required")
+
+    if len(request.password) < 6:
+        raise HTTPException(status_code=400, detail="Password must be at least 6 characters")
+
+    # Hash password
+    password_hash = auth.hash_password(request.password)
+
+    # Create user
+    try:
+        user_id = database.create_user(request.email, password_hash, request.display_name)
+    except ValueError as e:
+        raise HTTPException(status_code=400, detail=str(e))
+
+    # Generate token
+    token = auth.create_access_token(user_id, request.email)
+
+    return {
+        "token": token,
+        "user": {
+            "id": user_id,
+            "email": request.email,
+            "display_name": request.display_name
+        }
+    }
+
+@app.post("/api/login", response_model=TokenResponse)
+def login(request: LoginRequest):
+    """
+    Login with email and password.
+
+    Returns JWT token and user info.
+    """
+    # Get user by email
+    user = database.get_user_by_email(request.email)
+    if not user:
+        raise HTTPException(status_code=401, detail="Invalid email or password")
+
+    # Verify password
+    if not auth.verify_password(request.password, user['password_hash']):
+        raise HTTPException(status_code=401, detail="Invalid email or password")
+
+    # Generate token
+    token = auth.create_access_token(user['id'], user['email'])
+
+    return {
+        "token": token,
+        "user": {
+            "id": user['id'],
+            "email": user['email'],
+            "display_name": user['display_name']
+        }
+    }
+
+@app.get("/api/me")
+def get_current_user_info(current_user: dict = Depends(get_current_user)):
+    """
+    Get current user info from token.
+
+    Requires Authorization header with Bearer token.
+    """
+    user = database.get_user_by_id(current_user['user_id'])
+    if not user:
+        raise HTTPException(status_code=404, detail="User not found")
+
+    return {
+        "id": user['id'],
+        "email": user['email'],
+        "display_name": user['display_name'],
+        "created_at": user['created_at']
+    }
+
+@app.post("/api/import-local-data")
+def import_local_data(request: ImportDataRequest, current_user: dict = Depends(get_current_user)):
+    """
+    Import localStorage data to database on first login.
+
+    Extracts sessions, pictures, preferences, and reports from localStorage export.
+    """
+    import json
+
+    user_id = current_user['user_id']
+
+    # Extract sessions
+    sessions = []
+
+    # 1. Current session
+    if request.currentSession:
+        try:
+            current = json.loads(request.currentSession)
+            sessions.append({
+                'id': 'current-session',
+                'name': 'Current Session',
+                'editor_state': current
+            })
+        except:
+            pass
+
+    # 2. Calendar entries
+    if request.calendarEntries:
+        try:
+            calendar = json.loads(request.calendarEntries)
+            for date, entries in calendar.items():
+                for entry in entries:
+                    sessions.append({
+                        'id': entry['id'],
+                        'name': f"{date} - {entry.get('firstLine', 'Untitled')}",
+                        'editor_state': entry['state']
+                    })
+        except:
+            pass
+
+    # 3. Old document (if exists)
+    if request.oldDocument:
+        try:
+            old_doc = json.loads(request.oldDocument)
+            if old_doc and old_doc.get('document'):
+                sessions.append({
+                    'id': 'old-document',
+                    'name': 'Old Document (migrated)',
+                    'editor_state': {'cells': [{'type': 'text', 'content': str(old_doc)}]}
+                })
+        except:
+            pass
+
+    # Extract pictures
+    pictures = []
+    if request.dailyPictures:
+        try:
+            pics = json.loads(request.dailyPictures)
+            for pic in pics:
+                pictures.append({
+                    'date': pic['date'],
+                    'image_base64': pic['base64'],
+                    'prompt': pic.get('prompt', '')
+                })
+        except:
+            pass
+
+    # Extract preferences
+    preferences = {}
+    if request.voiceCustomizations:
+        try:
+            preferences['voice_configs'] = json.loads(request.voiceCustomizations)
+        except:
+            pass
+
+    if request.metaPrompt:
+        preferences['meta_prompt'] = request.metaPrompt
+
+    if request.stateConfig:
+        try:
+            preferences['state_config'] = json.loads(request.stateConfig)
+        except:
+            pass
+
+    if request.selectedState:
+        preferences['selected_state'] = request.selectedState
+
+    # Extract reports
+    reports = []
+    if request.analysisReports:
+        try:
+            report_list = json.loads(request.analysisReports)
+            for report in report_list:
+                reports.append({
+                    'type': report.get('type', 'unknown'),
+                    'data': report.get('data', {}),
+                    'allNotes': report.get('allNotes', ''),
+                    'timestamp': report.get('timestamp', '')
+                })
+        except:
+            pass
+
+    # Import to database
+    database.import_user_data(user_id, sessions, pictures, preferences, reports)
+
+    return {
+        "success": True,
+        "imported": {
+            "sessions": len(sessions),
+            "pictures": len(pictures),
+            "preferences": len([k for k, v in preferences.items() if v]),
+            "reports": len(reports)
+        }
+    }
+
+# ========== Session Storage Endpoints ==========
+
+@app.post("/api/sessions")
+def save_session(
+    request: dict,
+    current_user: dict = Depends(get_current_user)
+):
+    """
+    Save or update a session.
+
+    Request body:
+    {
+        "session_id": "string",
+        "name": "optional string",
+        "editor_state": {...}
+    }
+    """
+    user_id = current_user['user_id']
+    session_id = request.get('session_id')
+    editor_state = request.get('editor_state')
+    name = request.get('name')
+
+    if not session_id or not editor_state:
+        raise HTTPException(status_code=400, detail="session_id and editor_state required")
+
+    database.save_session(user_id, session_id, editor_state, name)
+
+    return {"success": True}
+
+@app.get("/api/sessions")
+def list_sessions(current_user: dict = Depends(get_current_user)):
+    """
+    List all sessions for current user.
+
+    Returns: Array of session metadata (without full editor state)
+    """
+    user_id = current_user['user_id']
+    sessions = database.list_sessions(user_id)
+    return {"sessions": sessions}
+
+@app.get("/api/sessions/{session_id}")
+def get_session(session_id: str, current_user: dict = Depends(get_current_user)):
+    """
+    Get a specific session by ID.
+
+    Returns: Full session including editor_state
+    """
+    user_id = current_user['user_id']
+    session = database.get_session(user_id, session_id)
+
+    if not session:
+        raise HTTPException(status_code=404, detail="Session not found")
+
+    return session
+
+@app.delete("/api/sessions/{session_id}")
+def delete_session_endpoint(session_id: str, current_user: dict = Depends(get_current_user)):
+    """Delete a session."""
+    user_id = current_user['user_id']
+    database.delete_session(user_id, session_id)
+    return {"success": True}
+
+# ========== Pictures Endpoints ==========
+
+@app.get("/api/pictures")
+def get_pictures(
+    limit: int = 30,
+    current_user: dict = Depends(get_current_user)
+):
+    """
+    Get recent daily pictures for current user.
+
+    Query params:
+    - limit: Max number of pictures to return (default 30)
+    """
+    user_id = current_user['user_id']
+    pictures = database.get_daily_pictures(user_id, limit)
+    return {"pictures": pictures}
+
+@app.post("/api/pictures")
+def save_picture(
+    request: dict,
+    current_user: dict = Depends(get_current_user)
+):
+    """
+    Save a daily picture.
+
+    Request body:
+    {
+        "date": "YYYY-MM-DD",
+        "image_base64": "base64 string",
+        "prompt": "optional prompt"
+    }
+    """
+    user_id = current_user['user_id']
+    date = request.get('date')
+    image_base64 = request.get('image_base64')
+    prompt = request.get('prompt', '')
+
+    if not date or not image_base64:
+        raise HTTPException(status_code=400, detail="date and image_base64 required")
+
+    database.save_daily_picture(user_id, date, image_base64, prompt)
+    return {"success": True}
+
+# ========== Preferences Endpoints ==========
+
+@app.get("/api/preferences")
+def get_preferences(current_user: dict = Depends(get_current_user)):
+    """Get user preferences."""
+    user_id = current_user['user_id']
+    preferences = database.get_preferences(user_id)
+    return preferences or {}
+
+@app.post("/api/preferences")
+def save_preferences_endpoint(
+    request: dict,
+    current_user: dict = Depends(get_current_user)
+):
+    """
+    Save user preferences.
+
+    Request body can contain any of:
+    - voice_configs: dict
+    - meta_prompt: str
+    - state_config: dict
+    - selected_state: str
+    """
+    user_id = current_user['user_id']
+
+    database.save_preferences(
+        user_id,
+        voice_configs=request.get('voice_configs'),
+        meta_prompt=request.get('meta_prompt'),
+        state_config=request.get('state_config'),
+        selected_state=request.get('selected_state')
+    )
+
+    return {"success": True}
+
+# ========== Analysis Reports Endpoints ==========
+
+@app.get("/api/reports")
+def get_reports(
+    limit: int = 10,
+    current_user: dict = Depends(get_current_user)
+):
+    """Get recent analysis reports."""
+    user_id = current_user['user_id']
+    reports = database.get_analysis_reports(user_id, limit)
+    return {"reports": reports}
+
+@app.post("/api/reports")
+def save_report(
+    request: dict,
+    current_user: dict = Depends(get_current_user)
+):
+    """
+    Save an analysis report.
+
+    Request body:
+    {
+        "report_type": "echoes" | "traits" | "patterns",
+        "report_data": {...},
+        "all_notes_text": "optional text"
+    }
+    """
+    user_id = current_user['user_id']
+    report_type = request.get('report_type')
+    report_data = request.get('report_data')
+    all_notes_text = request.get('all_notes_text', '')
+
+    if not report_type or not report_data:
+        raise HTTPException(status_code=400, detail="report_type and report_data required")
+
+    database.save_analysis_report(user_id, report_type, report_data, all_notes_text)
+    return {"success": True}
+
+@app.get("/api/default-voices")
+def get_default_voices():
+    """Get default voice configurations"""
+    return config.VOICE_ARCHETYPES
+
+@app.post("/api/analyze")
+async def analyze_api(request_data: dict):
+    """
+    @@@ Analyze text and return ONE new voice comment (sync API).
+
+    Uses PolyCLI's sync API internally - no polling needed!
+    """
+    async with httpx.AsyncClient() as client:
+        response = await client.post(
+            "http://localhost:8765/polycli/api/trigger-sync",
+            json={
+                "session_id": "analyze_text",
+                "params": request_data,
+                "timeout": 30.0
+            },
+            timeout=35.0
+        )
+        return response.json()
+
+@app.post("/api/chat")
+async def chat_api(request_data: dict):
+    """
+    @@@ Chat with a voice persona (sync API).
+
+    Uses PolyCLI's sync API internally - no polling needed!
+    """
+    async with httpx.AsyncClient() as client:
+        response = await client.post(
+            "http://localhost:8765/polycli/api/trigger-sync",
+            json={
+                "session_id": "chat_with_voice",
+                "params": request_data,
+                "timeout": 30.0
+            },
+            timeout=35.0
+        )
+        return response.json()
+
+@app.post("/api/generate-image")
+async def generate_image_api(request_data: dict):
+    """
+    @@@ Generate artistic image from notes (sync API).
+
+    This may take longer (60s timeout) due to image generation.
+    """
+    async with httpx.AsyncClient() as client:
+        response = await client.post(
+            "http://localhost:8765/polycli/api/trigger-sync",
+            json={
+                "session_id": "generate_daily_picture",
+                "params": request_data,
+                "timeout": 60.0  # Image generation takes longer
+            },
+            timeout=65.0
+        )
+        return response.json()
+
+@app.post("/api/analyze-echoes")
+async def analyze_echoes_api(request_data: dict):
+    """Analyze recurring themes in notes (sync API)."""
+    async with httpx.AsyncClient() as client:
+        response = await client.post(
+            "http://localhost:8765/polycli/api/trigger-sync",
+            json={
+                "session_id": "analyze_echoes",
+                "params": request_data,
+                "timeout": 30.0
+            },
+            timeout=35.0
+        )
+        return response.json()
+
+@app.post("/api/analyze-traits")
+async def analyze_traits_api(request_data: dict):
+    """Analyze personality traits from notes (sync API)."""
+    async with httpx.AsyncClient() as client:
+        response = await client.post(
+            "http://localhost:8765/polycli/api/trigger-sync",
+            json={
+                "session_id": "analyze_traits",
+                "params": request_data,
+                "timeout": 30.0
+            },
+            timeout=35.0
+        )
+        return response.json()
+
+@app.post("/api/analyze-patterns")
+async def analyze_patterns_api(request_data: dict):
+    """Analyze behavioral patterns from notes (sync API)."""
+    async with httpx.AsyncClient() as client:
+        response = await client.post(
+            "http://localhost:8765/polycli/api/trigger-sync",
+            json={
+                "session_id": "analyze_patterns",
+                "params": request_data,
+                "timeout": 30.0
+            },
+            timeout=35.0
+        )
+        return response.json()
+
+# ========== Mount PolyCLI Control Panel ==========
+
+registry = get_registry()
+mount_control_panel(app, registry, prefix="/polycli")
+
+# ========== Main ==========
+
 if __name__ == "__main__":
-    # Get the global registry
-    registry = get_registry()
+    import uvicorn
 
-    # Start the control panel
     print("\n" + "="*60)
-    print("üé≠ Stateless Voice Analysis Server")
+    print("üé≠ Ink & Memory FastAPI Server")
     print("="*60)
-
-    # Monkey-patch to add /api/default-voices endpoint
-    server, thread = registry.serve_control_panel(port=8765)
-
-    original_do_get = server.RequestHandlerClass.do_GET
-    def patched_do_get(handler_self):
-        if handler_self.path == "/api/default-voices":
-            import json
-            body = json.dumps(config.VOICE_ARCHETYPES).encode("utf-8")
-            handler_self.send_response(200)
-            handler_self.send_header("Content-Type", "application/json")
-            handler_self.send_header("Access-Control-Allow-Origin", "*")
-            handler_self.end_headers()
-            handler_self.wfile.write(body)
-        else:
-            original_do_get(handler_self)
-
-    server.RequestHandlerClass.do_GET = patched_do_get
-
-    print("\nüìö Available endpoints:")
-    print("  - POST /api/trigger")
-    print("    Body: {\"session_id\": \"analyze_text\", \"params\": {\"text\": \"...\", \"applied_comments\": [...]}}")
-    print("    Body: {\"session_id\": \"chat_with_voice\", \"params\": {\"voice_name\": \"...\", \"user_message\": \"...\", ...}}")
-    print("  - GET /api/default-voices")
-    print("\n" + "="*60 + "\n")
-
-    # Keep server running
-    try:
-        while True:
-            time.sleep(1)
-    except KeyboardInterrupt:
-        print("\n\nüëã Shutting down...")
\ No newline at end of file
+    print("\nüìö API Endpoints:")
+    print("  Clean API:")
+    print("    POST /api/analyze         - Analyze text (sync)")
+    print("    POST /api/chat            - Chat with voice (sync)")
+    print("    POST /api/generate-image  - Generate image (sync)")
+    print("    POST /api/analyze-echoes  - Find themes (sync)")
+    print("    POST /api/analyze-traits  - Identify traits (sync)")
+    print("    POST /api/analyze-patterns - Find patterns (sync)")
+    print("    GET  /api/default-voices  - Get voice configs")
+    print("\n  PolyCLI Control Panel:")
+    print("    /polycli                  - Control panel UI")
+    print("    /polycli/api/trigger-sync - Direct sync API")
+    print("\n  Documentation:")
+    print("    /docs                     - Auto-generated API docs")
+    print("="*60 + "\n")
+
+    uvicorn.run(app, host="127.0.0.1", port=8765)

*** FILE: backend/server_old.py ***
@@ -0,0 +1,498 @@
+#!/usr/bin/env python3
+"""Stateless voice analysis server - no state tracking, just returns new comments."""
+
+import time
+from polycli.orchestration.session_registry import session_def, get_registry
+from polycli import PolyAgent
+from stateless_analyzer import analyze_stateless
+import config
+from proxy_config import get_image_api_proxies
+
+@session_def(
+    name="Chat with Voice",
+    description="Have a conversation with a specific inner voice persona",
+    params={
+        "voice_name": {"type": "str"},
+        "voice_config": {"type": "dict"},
+        "conversation_history": {"type": "list"},
+        "user_message": {"type": "str"},
+        "original_text": {"type": "str"},
+        "meta_prompt": {"type": "str"},
+        "state_prompt": {"type": "str"}
+    },
+    category="Chat"
+)
+def chat_with_voice(voice_name: str, voice_config: dict, conversation_history: list, user_message: str, original_text: str = "", meta_prompt: str = "", state_prompt: str = ""):
+    """
+    Chat with a specific voice persona.
+
+    Args:
+        voice_name: Name of the voice (e.g., "Logic", "Drama")
+        voice_config: Voice configuration with tagline, icon, color
+        conversation_history: Previous messages in the conversation
+        user_message: The user's new message
+        original_text: The user's original writing text
+        meta_prompt: Additional instructions that apply to all voices
+
+    Returns:
+        Dictionary with assistant's response
+    """
+    print(f"\n{'='*60}")
+    print(f"üí¨ chat_with_voice() called")
+    print(f"   Voice: {voice_name}")
+    print(f"   User message: {user_message}")
+    print(f"   History length: {len(conversation_history)}")
+    print(f"   Meta prompt: {repr(meta_prompt)[:100]}")
+    print(f"   State prompt: {repr(state_prompt)[:100]}")
+    print(f"{'='*60}\n")
+
+    agent = PolyAgent(id=f"voice-chat-{voice_name.lower()}")
+
+    # Ensure voice_config is a dict
+    if not isinstance(voice_config, dict):
+        print(f"‚ö†Ô∏è  voice_config is not a dict: {type(voice_config)}, using default")
+        voice_config = {"tagline": f"{voice_name} voice from Disco Elysium"}
+
+    # Build system prompt for this voice
+    system_prompt = f"""You are {voice_name}, an inner voice archetype from Disco Elysium.
+
+Your character: {voice_config.get('tagline', '')}
+
+Respond in character as {voice_name}. Be concise (1-3 sentences). Stay true to your archetype.
+Use the conversation context but focus on your unique perspective."""
+
+    # Add original writing area text if available
+    if original_text and original_text.strip():
+        system_prompt += f"""
+
+Context: The user is writing this text:
+---
+{original_text.strip()}
+---
+
+Your initial comment was about this text. Keep this context in mind when responding to the user's questions."""
+
+    # Add meta prompt if available
+    if meta_prompt and meta_prompt.strip():
+        system_prompt += f"""
+
+Additional instructions:
+{meta_prompt.strip()}"""
+
+    # @@@ Add state prompt if available (between meta and voice-specific)
+    if state_prompt and state_prompt.strip():
+        system_prompt += f"""
+
+User's current state:
+{state_prompt.strip()}"""
+
+    # Build full prompt with conversation history
+    prompt = system_prompt + "\n\nConversation history:\n"
+
+    # Add conversation history
+    for msg in conversation_history:
+        role_label = "User" if msg["role"] == "user" else voice_name
+        prompt += f"\n{role_label}: {msg['content']}"
+
+    # Add user's new message
+    prompt += f"\n\nUser: {user_message}\n\n{voice_name}:"
+
+    # Get response from LLM
+    result = agent.run(prompt, model="gpt-4o-dou", cli="no-tools", tracked=True)
+
+    if not result.is_success or not result.content:
+        response = "..."
+    else:
+        response = result.content
+
+    print(f"‚úÖ Got response: {response[:100]}...")
+
+    return {
+        "response": response,
+        "voice_name": voice_name
+    }
+
+@session_def(
+    name="Analyze Voices",
+    description="Get one new voice comment for text",
+    params={
+        "text": {"type": "str"},
+        "session_id": {"type": "str"},
+        "voices": {"type": "dict"},
+        "applied_comments": {"type": "list"},
+        "meta_prompt": {"type": "str"},
+        "state_prompt": {"type": "str"}
+    },
+    category="Analysis"
+)
+def analyze_text(text: str, session_id: str, voices: dict = None, applied_comments: list = None, meta_prompt: str = "", state_prompt: str = "", overlapped_phrases: list = None):
+    """
+    Stateless analysis - returns ONE new comment based on text and applied comments.
+
+    Args:
+        text: Text to analyze (should be complete sentences only)
+        session_id: Session ID (for future use)
+        voices: Voice configuration
+        applied_comments: List of already applied comments (to avoid duplicates)
+        meta_prompt: Additional instructions that apply to all voices
+        state_prompt: User's current emotional state prompt
+        overlapped_phrases: Phrases that were rejected due to overlap (feedback loop)
+
+    Returns:
+        Dictionary with single new voice (or empty list)
+    """
+    print(f"\n{'='*60}")
+    print(f"üéØ Stateless analyze_text() called")
+    print(f"   Text: {text[:100]}...")
+    print(f"   Applied comments: {len(applied_comments or [])}")
+    print(f"   Overlapped phrases: {len(overlapped_phrases or [])}")
+    print(f"   Meta prompt: {repr(meta_prompt)[:100]}")
+    print(f"   State prompt: {repr(state_prompt)[:100]}")
+    print(f"{'='*60}\n")
+
+    agent = PolyAgent(id="voice-analyzer")
+
+    # Get voices from stateless analyzer
+    result = analyze_stateless(agent, text, applied_comments or [], voices, meta_prompt, state_prompt, overlapped_phrases or [])
+
+    print(f"‚úÖ Returning {result['new_voices_added']} new voice(s)")
+
+    return {
+        "voices": result["voices"],
+        "new_voices_added": result["new_voices_added"],
+        "status": "completed"
+    }
+
+@session_def(
+    name="Analyze Echoes",
+    description="Find recurring themes and topics in all user notes",
+    params={
+        "all_notes": {"type": "str"}
+    },
+    category="Analysis"
+)
+def analyze_echoes(all_notes: str):
+    """Analyze recurring themes and topics across all notes."""
+    print(f"\n{'='*60}")
+    print(f"üîÑ analyze_echoes() called")
+    print(f"   Notes length: {len(all_notes)} chars")
+    print(f"{'='*60}\n")
+
+    agent = PolyAgent(id="echoes-analyzer")
+
+    prompt = f"""Analyze these personal notes and identify recurring themes, topics, or concerns that keep appearing.
+
+Notes:
+---
+{all_notes}
+---
+
+Find 3-5 echoes (recurring themes) that appear across different entries. For each echo:
+- Give it a short title (2-4 words)
+- Explain what pattern you see
+- Quote 2-3 specific examples from the notes
+
+Format as a JSON array:
+[
+  {{"title": "...", "description": "...", "examples": ["quote1", "quote2", "quote3"]}},
+  ...
+]
+
+Return ONLY the JSON array, no other text."""
+
+    result = agent.run(prompt, model="gpt-4o-dou", cli="no-tools", tracked=True)
+
+    if not result.is_success or not result.content:
+        return {"echoes": []}
+
+    try:
+        import json
+        echoes = json.loads(result.content.strip())
+        return {"echoes": echoes}
+    except:
+        return {"echoes": []}
+
+@session_def(
+    name="Analyze Traits",
+    description="Identify personality traits and characteristics from user notes",
+    params={
+        "all_notes": {"type": "str"}
+    },
+    category="Analysis"
+)
+def analyze_traits(all_notes: str):
+    """Analyze personality traits from all notes."""
+    print(f"\n{'='*60}")
+    print(f"üë§ analyze_traits() called")
+    print(f"   Notes length: {len(all_notes)} chars")
+    print(f"{'='*60}\n")
+
+    agent = PolyAgent(id="traits-analyzer")
+
+    prompt = f"""Analyze these personal notes and identify personality traits and characteristics.
+
+Notes:
+---
+{all_notes}
+---
+
+Identify 4-6 personality traits that are evident from the writing. For each trait:
+- Give it a name (1-2 words)
+- Rate the strength (1-5)
+- Explain why you see this trait with specific examples
+
+Format as a JSON array:
+[
+  {{"trait": "...", "strength": 4, "evidence": "..."}},
+  ...
+]
+
+Return ONLY the JSON array, no other text."""
+
+    result = agent.run(prompt, model="gpt-4o-dou", cli="no-tools", tracked=True)
+
+    if not result.is_success or not result.content:
+        return {"traits": []}
+
+    try:
+        import json
+        traits = json.loads(result.content.strip())
+        return {"traits": traits}
+    except:
+        return {"traits": []}
+
+@session_def(
+    name="Analyze Patterns",
+    description="Identify behavioral patterns and habits from user notes",
+    params={
+        "all_notes": {"type": "str"}
+    },
+    category="Analysis"
+)
+def analyze_patterns(all_notes: str):
+    """Analyze behavioral patterns from all notes."""
+    print(f"\n{'='*60}")
+    print(f"üîç analyze_patterns() called")
+    print(f"   Notes length: {len(all_notes)} chars")
+    print(f"{'='*60}\n")
+
+    agent = PolyAgent(id="patterns-analyzer")
+
+    prompt = f"""Analyze these personal notes and identify behavioral patterns or habits.
+
+Notes:
+---
+{all_notes}
+---
+
+Identify 3-5 behavioral patterns or habits. For each pattern:
+- Give it a descriptive name
+- Describe the pattern
+- Note the frequency/context when it appears
+
+Format as a JSON array:
+[
+  {{"pattern": "...", "description": "...", "frequency": "..."}},
+  ...
+]
+
+Return ONLY the JSON array, no other text."""
+
+    result = agent.run(prompt, model="gpt-4o-dou", cli="no-tools", tracked=True)
+
+    if not result.is_success or not result.content:
+        return {"patterns": []}
+
+    try:
+        import json
+        patterns = json.loads(result.content.strip())
+        return {"patterns": patterns}
+    except:
+        return {"patterns": []}
+
+@session_def(
+    name="Generate Daily Picture",
+    description="Generate an artistic image based on user's daily notes",
+    params={
+        "all_notes": {"type": "str"}
+    },
+    category="Creative"
+)
+def generate_daily_picture(all_notes: str):
+    """Generate an image based on the essence of user's daily notes.
+
+    Uses a two-step process:
+    1. LLM analyzes notes and creates artistic image description
+    2. Image generation model creates the image
+    """
+    print(f"\n{'='*60}")
+    print(f"üé® generate_daily_picture() called")
+    print(f"   Notes length: {len(all_notes)} chars")
+    print(f"{'='*60}\n")
+
+    import requests
+
+    # @@@ Step 1: Convert notes to artistic image description using Claude Haiku
+
+    description_prompt = f"""Read these personal notes and create a vivid, artistic image description that captures the essence, mood, and themes.
+
+Notes:
+---
+{all_notes}
+---
+
+Create a detailed image description (2-3 sentences) that:
+- Captures the emotional tone and atmosphere
+- Uses visual metaphors for abstract concepts
+- Specifies artistic style (e.g., watercolor, impressionist, minimalist)
+- Describes colors, lighting, composition
+
+Be creative and interpretive. Focus on mood and feeling, not literal representation.
+
+Return ONLY the image description, no other text."""
+
+    print("üß† Creating image description from notes with Claude Haiku...")
+
+    # @@@ Use proxy for GFW bypass (if configured)
+    proxies = get_image_api_proxies()
+
+    claude_response = requests.post(
+        f"{config.IMAGE_API_ENDPOINT}/chat/completions",
+        headers={
+            "Authorization": f"Bearer {config.IMAGE_API_KEY}",
+            "Content-Type": "application/json"
+        },
+        json={
+            "model": config.IMAGE_DESCRIPTION_MODEL,
+            "messages": [{"role": "user", "content": description_prompt}],
+            "max_tokens": config.IMAGE_DESCRIPTION_MAX_TOKENS
+        },
+        proxies=proxies,
+        timeout=config.IMAGE_DESCRIPTION_TIMEOUT
+    )
+
+    if claude_response.status_code != 200:
+        return {"image_base64": None, "error": "Failed to create image description"}
+
+    claude_data = claude_response.json()
+    image_description = claude_data.get('choices', [{}])[0].get('message', {}).get('content', '').strip()
+
+    if not image_description:
+        return {"image_base64": None, "error": "Failed to create image description"}
+
+    print(f"üìù Image description: {image_description}")
+
+    # @@@ Step 2: Generate image from description with retry logic
+    url = f"{config.IMAGE_API_ENDPOINT}/chat/completions"
+    headers = {
+        "Authorization": f"Bearer {config.IMAGE_API_KEY}",
+        "Content-Type": "application/json"
+    }
+
+    payload = {
+        "model": config.IMAGE_GENERATION_MODEL,
+        "messages": [
+            {
+                "role": "user",
+                "content": image_description
+            }
+        ],
+        "max_tokens": config.IMAGE_MAX_TOKENS
+    }
+
+    # @@@ Retry logic with increasing timeouts
+    for attempt in range(1, config.IMAGE_RETRY_MAX_ATTEMPTS + 1):
+        try:
+            timeout_seconds = config.IMAGE_RETRY_BASE_TIMEOUT + (attempt - 1) * config.IMAGE_RETRY_TIMEOUT_INCREMENT
+            print(f"üé® Generating image (attempt {attempt}/{config.IMAGE_RETRY_MAX_ATTEMPTS}, timeout={timeout_seconds}s)...")
+            response = requests.post(url, headers=headers, json=payload, proxies=proxies, timeout=timeout_seconds)
+
+            if response.status_code != 200:
+                print(f"‚ùå Error: {response.status_code}")
+                if attempt < config.IMAGE_RETRY_MAX_ATTEMPTS:
+                    print(f"‚è≥ Retrying in 2 seconds...")
+                    import time
+                    time.sleep(2)
+                    continue
+                return {"image_base64": None, "error": "Image generation failed"}
+
+            data = response.json()
+
+            # Extract image from response
+            if 'choices' in data and len(data['choices']) > 0:
+                message = data['choices'][0].get('message', {})
+                images = message.get('images', [])
+
+                if images:
+                    image_data = images[0].get('image_url', {}).get('url', '')
+
+                    if image_data.startswith('data:image/png;base64,'):
+                        # Extract base64 data (without the data URI prefix)
+                        base64_data = image_data.split(',', 1)[1]
+
+                        print(f"‚úÖ Image generated successfully")
+                        print(f"   Size: {len(base64_data)} chars")
+
+                        return {
+                            "image_base64": base64_data,
+                            "prompt": image_description  # Return the creative description
+                        }
+
+            if attempt < config.IMAGE_RETRY_MAX_ATTEMPTS:
+                print(f"‚ö†Ô∏è No image in response, retrying...")
+                import time
+                time.sleep(2)
+                continue
+            return {"image_base64": None, "error": "No image in response"}
+
+        except Exception as e:
+            print(f"‚ùå Exception on attempt {attempt}: {e}")
+            if attempt < config.IMAGE_RETRY_MAX_ATTEMPTS:
+                print(f"‚è≥ Retrying in 2 seconds...")
+                import time
+                time.sleep(2)
+                continue
+            return {"image_base64": None, "error": str(e)}
+
+    return {"image_base64": None, "error": "All retry attempts failed"}
+
+if __name__ == "__main__":
+    # Get the global registry
+    registry = get_registry()
+
+    # Start the control panel
+    print("\n" + "="*60)
+    print("üé≠ Stateless Voice Analysis Server")
+    print("="*60)
+
+    # Monkey-patch to add /api/default-voices endpoint
+    server, thread = registry.serve_control_panel(port=8765)
+
+    original_do_get = server.RequestHandlerClass.do_GET
+    def patched_do_get(handler_self):
+        if handler_self.path == "/api/default-voices":
+            import json
+            body = json.dumps(config.VOICE_ARCHETYPES).encode("utf-8")
+            handler_self.send_response(200)
+            handler_self.send_header("Content-Type", "application/json")
+            handler_self.send_header("Access-Control-Allow-Origin", "*")
+            handler_self.end_headers()
+            handler_self.wfile.write(body)
+        else:
+            original_do_get(handler_self)
+
+    server.RequestHandlerClass.do_GET = patched_do_get
+
+    print("\nüìö Available endpoints:")
+    print("  - POST /api/trigger")
+    print("    Body: {\"session_id\": \"analyze_text\", \"params\": {\"text\": \"...\", \"applied_comments\": [...]}}")
+    print("    Body: {\"session_id\": \"chat_with_voice\", \"params\": {\"voice_name\": \"...\", \"user_message\": \"...\", ...}}")
+    print("  - GET /api/default-voices")
+    print("\n" + "="*60 + "\n")
+
+    # Keep server running
+    try:
+        while True:
+            time.sleep(1)
+    except KeyboardInterrupt:
+        print("\n\nüëã Shutting down...")
\ No newline at end of file

*** FILE: backend/test_migration.py ***
@@ -0,0 +1,205 @@
+#!/usr/bin/env python3
+"""
+Test migration of real localStorage data to database.
+
+This script:
+1. Loads the real_user_data.json export
+2. Parses all localStorage data
+3. Creates a test user
+4. Migrates all data to database
+5. Verifies migration success
+"""
+
+import json
+import sys
+from datetime import datetime
+import bcrypt
+from database import (
+    init_db, create_user, import_user_data,
+    get_user_by_id, list_sessions, get_daily_pictures,
+    get_preferences, get_analysis_reports
+)
+
+def parse_localStorage_export(filepath):
+    """Parse the localStorage export JSON."""
+    print(f"üìÇ Loading {filepath}...")
+
+    with open(filepath, 'r') as f:
+        data = json.load(f)
+
+    print(f"‚úÖ Loaded {data.get('sizeEstimate', 'unknown')} of data")
+
+    return data
+
+def extract_sessions(data):
+    """Extract all sessions from current session + calendar entries."""
+    sessions = []
+
+    # 1. Current session
+    if data.get('currentSession'):
+        current = json.loads(data['currentSession'])
+        sessions.append({
+            'id': 'current-session',
+            'name': 'Current Session',
+            'editor_state': current
+        })
+        print(f"  ‚úÖ Current session: {len(current.get('cells', []))} cells")
+
+    # 2. Calendar entries (each entry is a separate session)
+    if data.get('calendarEntries'):
+        calendar = json.loads(data['calendarEntries'])
+
+        for date, entries in calendar.items():
+            for entry in entries:
+                sessions.append({
+                    'id': entry['id'],
+                    'name': f"{date} - {entry.get('firstLine', 'Untitled')}",
+                    'editor_state': entry['state']
+                })
+
+        total_entries = sum(len(entries) for entries in calendar.values())
+        print(f"  ‚úÖ Calendar: {len(calendar)} days, {total_entries} entries")
+
+    # 3. Old document system (if used)
+    if data.get('oldDocument'):
+        try:
+            old_doc = json.loads(data['oldDocument'])
+            if old_doc and old_doc.get('document'):
+                sessions.append({
+                    'id': 'old-document',
+                    'name': 'Old Document (migrated)',
+                    'editor_state': {'cells': [{'type': 'text', 'content': str(old_doc)}]}
+                })
+                print(f"  ‚ö†Ô∏è Old document system found (migrated as text)")
+        except:
+            pass
+
+    return sessions
+
+def extract_pictures(data):
+    """Extract daily pictures."""
+    pictures = []
+
+    if data.get('dailyPictures'):
+        pics = json.loads(data['dailyPictures'])
+        for pic in pics:
+            pictures.append({
+                'date': pic['date'],
+                'image_base64': pic['base64'],
+                'prompt': pic.get('prompt', '')
+            })
+
+        print(f"  ‚úÖ Pictures: {len(pictures)} images")
+
+    return pictures
+
+def extract_preferences(data):
+    """Extract user preferences."""
+    prefs = {}
+
+    if data.get('voiceCustomizations'):
+        prefs['voice_configs'] = json.loads(data['voiceCustomizations'])
+
+    if data.get('metaPrompt'):
+        prefs['meta_prompt'] = data['metaPrompt']
+
+    if data.get('stateConfig'):
+        prefs['state_config'] = json.loads(data['stateConfig'])
+
+    if data.get('selectedState'):
+        prefs['selected_state'] = data['selectedState']
+
+    print(f"  ‚úÖ Preferences: {len(prefs)} items")
+
+    return prefs
+
+def extract_reports(data):
+    """Extract analysis reports."""
+    reports = []
+
+    if data.get('analysisReports'):
+        report_list = json.loads(data['analysisReports'])
+        for report in report_list:
+            reports.append({
+                'type': report.get('type', 'unknown'),
+                'data': report.get('data', {}),
+                'allNotes': report.get('allNotes', ''),
+                'timestamp': report.get('timestamp', datetime.now().isoformat())
+            })
+
+        print(f"  ‚úÖ Reports: {len(reports)} analysis reports")
+
+    return reports
+
+def test_migration():
+    """Run the full migration test."""
+    print("\n" + "="*60)
+    print("üß™ Testing localStorage Migration")
+    print("="*60 + "\n")
+
+    # Step 1: Initialize database
+    print("1Ô∏è‚É£ Initializing database...")
+    init_db()
+
+    # Step 2: Load localStorage export
+    print("\n2Ô∏è‚É£ Loading localStorage export...")
+    data = parse_localStorage_export('test_data/real_user_data.json')
+
+    # Step 3: Extract all data
+    print("\n3Ô∏è‚É£ Extracting data...")
+    sessions = extract_sessions(data)
+    pictures = extract_pictures(data)
+    preferences = extract_preferences(data)
+    reports = extract_reports(data)
+
+    # Step 4: Create test user
+    print("\n4Ô∏è‚É£ Creating test user...")
+    password_hash = bcrypt.hashpw(b"test123", bcrypt.gensalt()).decode('utf-8')
+    user_id = create_user('test@example.com', password_hash, 'Test User')
+    print(f"  ‚úÖ User created: ID={user_id}")
+
+    # Step 5: Import all data
+    print("\n5Ô∏è‚É£ Importing data to database...")
+    import_user_data(user_id, sessions, pictures, preferences, reports)
+
+    # Step 6: Verify migration
+    print("\n6Ô∏è‚É£ Verifying migration...")
+
+    user = get_user_by_id(user_id)
+    print(f"  ‚úÖ User: {user['email']}")
+
+    db_sessions = list_sessions(user_id)
+    print(f"  ‚úÖ Sessions: {len(db_sessions)} (expected {len(sessions)})")
+
+    db_pictures = get_daily_pictures(user_id, limit=100)
+    print(f"  ‚úÖ Pictures: {len(db_pictures)} (expected {len(pictures)})")
+
+    db_prefs = get_preferences(user_id)
+    if db_prefs:
+        print(f"  ‚úÖ Preferences: {len([k for k, v in db_prefs.items() if v is not None])} items")
+
+    db_reports = get_analysis_reports(user_id, limit=100)
+    print(f"  ‚úÖ Reports: {len(db_reports)} (expected {len(reports)})")
+
+    # Success!
+    print("\n" + "="*60)
+    print("‚úÖ Migration test PASSED!")
+    print("="*60)
+    print(f"\nMigrated:")
+    print(f"  - {len(sessions)} sessions")
+    print(f"  - {len(pictures)} images (freed ~{len(pictures) * 2.5:.1f}MB from localStorage!)")
+    print(f"  - {len([k for k, v in preferences.items() if v])} preference items")
+    print(f"  - {len(reports)} analysis reports")
+
+    return True
+
+if __name__ == "__main__":
+    try:
+        test_migration()
+        sys.exit(0)
+    except Exception as e:
+        print(f"\n‚ùå Migration test FAILED!")
+        print(f"Error: {e}")
+        import traceback
+        traceback.print_exc()
+        sys.exit(1)

*** FILE: backend/test_real_migration.py ***
@@ -0,0 +1,210 @@
+#!/usr/bin/env python3
+"""
+Test full migration flow with real user data.
+
+Simulates:
+1. User registers
+2. User logs in
+3. Frontend sends localStorage data
+4. Backend imports to database
+5. Frontend fetches data back
+"""
+
+import requests
+import json
+
+API_BASE = "http://localhost:8765"
+
+def test_full_migration():
+    print("\n" + "="*60)
+    print("üß™ Testing Full Migration with Real Data")
+    print("="*60 + "\n")
+
+    # Load real localStorage export
+    print("üìÇ Loading real localStorage export...")
+    with open('test_data/real_user_data.json', 'r') as f:
+        real_data = json.load(f)
+
+    print(f"‚úÖ Loaded {real_data.get('sizeEstimate', 'unknown')}")
+    print()
+
+    # Step 1: Register
+    print("1Ô∏è‚É£ Registering new user...")
+    register_response = requests.post(
+        f"{API_BASE}/api/register",
+        json={
+            "email": "realuser@example.com",
+            "password": "password123",
+            "display_name": "Real User"
+        }
+    )
+
+    if register_response.status_code != 200:
+        print(f"‚ùå Registration failed: {register_response.text}")
+        return False
+
+    register_data = register_response.json()
+    token = register_data['token']
+    user_id = register_data['user']['id']
+    print(f"‚úÖ User registered: ID={user_id}")
+    print()
+
+    # Step 2: Import localStorage data
+    print("2Ô∏è‚É£ Importing localStorage data...")
+
+    # Prepare import request (match frontend localStorage keys)
+    import_request = {
+        "currentSession": real_data.get('currentSession'),
+        "calendarEntries": real_data.get('calendarEntries'),
+        "dailyPictures": real_data.get('dailyPictures'),
+        "voiceCustomizations": real_data.get('voiceCustomizations'),
+        "metaPrompt": real_data.get('metaPrompt'),
+        "stateConfig": real_data.get('stateConfig'),
+        "selectedState": real_data.get('selectedState'),
+        "analysisReports": real_data.get('analysisReports'),
+        "oldDocument": real_data.get('oldDocument')
+    }
+
+    import_response = requests.post(
+        f"{API_BASE}/api/import-local-data",
+        headers={"Authorization": f"Bearer {token}"},
+        json=import_request
+    )
+
+    if import_response.status_code != 200:
+        print(f"‚ùå Import failed: {import_response.text}")
+        return False
+
+    import_result = import_response.json()
+    print(f"‚úÖ Import successful!")
+    print(f"   Sessions: {import_result['imported']['sessions']}")
+    print(f"   Pictures: {import_result['imported']['pictures']}")
+    print(f"   Preferences: {import_result['imported']['preferences']}")
+    print(f"   Reports: {import_result['imported']['reports']}")
+    print()
+
+    # Step 3: Verify - List sessions
+    print("3Ô∏è‚É£ Verifying data - List sessions...")
+    sessions_response = requests.get(
+        f"{API_BASE}/api/sessions",
+        headers={"Authorization": f"Bearer {token}"}
+    )
+
+    if sessions_response.status_code != 200:
+        print(f"‚ùå Failed to list sessions: {sessions_response.text}")
+        return False
+
+    sessions = sessions_response.json()['sessions']
+    print(f"‚úÖ Found {len(sessions)} sessions:")
+    for session in sessions[:3]:  # Show first 3
+        print(f"   - {session['name']} (updated: {session['updated_at']})")
+    if len(sessions) > 3:
+        print(f"   ... and {len(sessions) - 3} more")
+    print()
+
+    # Step 4: Verify - Get a session's full state
+    if sessions:
+        print("4Ô∏è‚É£ Fetching full session state...")
+        session_id = sessions[0]['id']
+        session_response = requests.get(
+            f"{API_BASE}/api/sessions/{session_id}",
+            headers={"Authorization": f"Bearer {token}"}
+        )
+
+        if session_response.status_code != 200:
+            print(f"‚ùå Failed to get session: {session_response.text}")
+            return False
+
+        session_data = session_response.json()
+        editor_state = session_data['editor_state']
+        num_cells = len(editor_state.get('cells', []))
+        print(f"‚úÖ Session '{session_data['name']}' has {num_cells} cells")
+        print()
+
+    # Step 5: Verify - Get pictures
+    print("5Ô∏è‚É£ Verifying pictures...")
+    pictures_response = requests.get(
+        f"{API_BASE}/api/pictures?limit=10",
+        headers={"Authorization": f"Bearer {token}"}
+    )
+
+    if pictures_response.status_code != 200:
+        print(f"‚ùå Failed to get pictures: {pictures_response.text}")
+        return False
+
+    pictures = pictures_response.json()['pictures']
+    print(f"‚úÖ Found {len(pictures)} pictures:")
+    for pic in pictures:
+        size_kb = len(pic['image_base64']) / 1024
+        print(f"   - {pic['date']}: {size_kb:.1f} KB ({pic.get('prompt', 'no prompt')[:50]}...)")
+
+    total_size_mb = sum(len(p['image_base64']) for p in pictures) / 1024 / 1024
+    print(f"   Total: {total_size_mb:.2f} MB (was in localStorage!)")
+    print()
+
+    # Step 6: Verify - Get preferences
+    print("6Ô∏è‚É£ Verifying preferences...")
+    prefs_response = requests.get(
+        f"{API_BASE}/api/preferences",
+        headers={"Authorization": f"Bearer {token}"}
+    )
+
+    if prefs_response.status_code != 200:
+        print(f"‚ùå Failed to get preferences: {prefs_response.text}")
+        return False
+
+    prefs = prefs_response.json()
+    print(f"‚úÖ Preferences loaded:")
+    if prefs.get('meta_prompt'):
+        print(f"   - Meta prompt: {prefs['meta_prompt'][:50]}...")
+    if prefs.get('selected_state'):
+        print(f"   - Selected state: {prefs['selected_state']}")
+    if prefs.get('voice_configs'):
+        num_voices = len(prefs['voice_configs'])
+        print(f"   - Voice configs: {num_voices} voices")
+    print()
+
+    # Step 7: Verify - Get reports
+    print("7Ô∏è‚É£ Verifying analysis reports...")
+    reports_response = requests.get(
+        f"{API_BASE}/api/reports?limit=10",
+        headers={"Authorization": f"Bearer {token}"}
+    )
+
+    if reports_response.status_code != 200:
+        print(f"‚ùå Failed to get reports: {reports_response.text}")
+        return False
+
+    reports = reports_response.json()['reports']
+    print(f"‚úÖ Found {reports} reports:")
+    for report in reports:
+        print(f"   - {report['report_type']} (created: {report['created_at']})")
+    print()
+
+    # Success summary
+    print("="*60)
+    print("‚úÖ MIGRATION TEST PASSED!")
+    print("="*60)
+    print(f"\nMigrated from localStorage ‚Üí SQLite:")
+    print(f"  - {import_result['imported']['sessions']} sessions")
+    print(f"  - {import_result['imported']['pictures']} pictures ({total_size_mb:.2f} MB freed!)")
+    print(f"  - {import_result['imported']['preferences']} preference items")
+    print(f"  - {import_result['imported']['reports']} analysis reports")
+    print(f"\nAll data successfully retrieved via API!")
+    print("="*60 + "\n")
+
+    return True
+
+if __name__ == "__main__":
+    try:
+        success = test_full_migration()
+        if success:
+            print("üéâ Ready to build frontend!")
+        else:
+            print("‚ùå Migration test failed")
+            exit(1)
+    except Exception as e:
+        print(f"\n‚ùå Error: {e}")
+        import traceback
+        traceback.print_exc()
+        exit(1)

*** FILE: frontend/src/api/voiceApi.ts ***
@@ -1,5 +1,5 @@
 /**
- * API client for voice analysis backend
+ * API client for voice analysis backend - FastAPI sync API version
  */
 
 // nginx proxies /ink-and-memory/api/* to backend (8765)
@@ -13,14 +13,8 @@ export async function getDefaultVoices(): Promise<any> {
   return await response.json();
 }
 
-interface TriggerResponse {
+interface SyncResponse {
   success: boolean;
-  exec_id: string;
-}
-
-interface StatusResponse {
-  exec_id: string;
-  status: 'running' | 'completed' | 'failed';
   result?: {
     voices?: Array<{
       phrase: string;
@@ -29,7 +23,7 @@ interface StatusResponse {
       icon: string;
       color: string;
     }>;
-    new_voices_added?: number;  // @@@ Number of new voices from this LLM call
+    new_voices_added?: number;
     status?: string;
     response?: string;  // For chat responses
     voice_name?: string;  // For chat responses
@@ -40,82 +34,45 @@ interface StatusResponse {
     prompt?: string;  // Image generation prompt
   };
   error?: string;
+  exec_id?: string;  // Still included for debugging
 }
 
 /**
- * Trigger voice analysis session
+ * Analyze text and return voices with metadata (sync API - no polling!)
  */
-export async function triggerAnalysis(text: string, sessionId: string, voices?: any, appliedComments?: any[], metaPrompt?: string, statePrompt?: string, overlappedPhrases?: string[]): Promise<string> {
-  console.log('üì§ Sending trigger request...');
-  const response = await fetch(`${API_BASE}/api/trigger`, {
+export async function analyzeText(text: string, sessionId: string, voices?: any, appliedComments?: any[], metaPrompt?: string, statePrompt?: string, overlappedPhrases?: string[]) {
+  console.log('üì§ Sending analyze request (sync API)...');
+
+  const response = await fetch(`${API_BASE}/api/analyze`, {
     method: 'POST',
     headers: { 'Content-Type': 'application/json' },
     body: JSON.stringify({
-      session_id: 'analyze_text',
-      params: { text, session_id: sessionId, voices, applied_comments: appliedComments || [], meta_prompt: metaPrompt || '', state_prompt: statePrompt || '', overlapped_phrases: overlappedPhrases || [] }
+      text,
+      session_id: sessionId,
+      voices,
+      applied_comments: appliedComments || [],
+      meta_prompt: metaPrompt || '',
+      state_prompt: statePrompt || '',
+      overlapped_phrases: overlappedPhrases || []
     })
   });
 
-  console.log('üì• Got response, status:', response.status);
-  const data: TriggerResponse = await response.json();
-  console.log('üìã Parsed JSON:', data);
+  const data: SyncResponse = await response.json();
+  console.log('‚úÖ Got sync response:', data);
 
   if (!data.success) {
-    throw new Error('Failed to trigger analysis');
-  }
-
-  console.log('‚úÖ Exec ID:', data.exec_id);
-  return data.exec_id;
-}
-
-/**
- * Get analysis result (polls until completed)
- */
-export async function getAnalysisResult(exec_id: string): Promise<StatusResponse['result']> {
-  // Poll every 500ms, max 2 minutes (enough for image generation)
-  const maxAttempts = 240;
-  let attempts = 0;
-
-  console.log('üîÑ Starting to poll for exec_id:', exec_id);
-
-  while (attempts < maxAttempts) {
-    console.log(`üìä Polling attempt ${attempts + 1}/${maxAttempts}...`);
-    const response = await fetch(`${API_BASE}/api/status/${exec_id}`);
-    const data: StatusResponse = await response.json();
-    console.log('üìä Status:', data.status);
-
-    if (data.status === 'completed') {
-      console.log('‚úÖ Analysis completed!', data.result);
-      return data.result;
-    }
-
-    if (data.status === 'failed') {
-      throw new Error(data.error || 'Analysis failed');
-    }
-
-    // Still running, wait and retry
-    await new Promise(resolve => setTimeout(resolve, 500));
-    attempts++;
+    throw new Error(data.error || 'Analysis failed');
   }
 
-  throw new Error('Analysis timeout');
-}
-
-/**
- * Analyze text and return voices with metadata (all-in-one)
- */
-export async function analyzeText(text: string, sessionId: string, voices?: any, appliedComments?: any[], metaPrompt?: string, statePrompt?: string, overlappedPhrases?: string[]) {
-  const exec_id = await triggerAnalysis(text, sessionId, voices, appliedComments, metaPrompt, statePrompt, overlappedPhrases);
-  const result = await getAnalysisResult(exec_id);
-  // @@@ Return both voices and new_voices_added for energy refund mechanism
+  // Return both voices and new_voices_added for energy refund mechanism
   return {
-    voices: result?.voices || [],
-    new_voices_added: result?.new_voices_added ?? 0
+    voices: data.result?.voices || [],
+    new_voices_added: data.result?.new_voices_added ?? 0
   };
 }
 
 /**
- * Chat with a voice persona
+ * Chat with a voice persona (sync API - no polling!)
  */
 export async function chatWithVoice(
   voiceName: string,
@@ -126,140 +83,123 @@ export async function chatWithVoice(
   metaPrompt?: string,
   statePrompt?: string
 ): Promise<string> {
-  console.log('üí¨ Sending chat request to backend...');
+  console.log('üí¨ Sending chat request (sync API)...');
 
-  // Trigger chat session
-  const response = await fetch(`${API_BASE}/api/trigger`, {
+  const response = await fetch(`${API_BASE}/api/chat`, {
     method: 'POST',
     headers: { 'Content-Type': 'application/json' },
     body: JSON.stringify({
-      session_id: 'chat_with_voice',
-      params: {
-        voice_name: voiceName,
-        voice_config: voiceConfig,
-        conversation_history: conversationHistory,
-        user_message: userMessage,
-        original_text: originalText || '',
-        meta_prompt: metaPrompt || '',
-        state_prompt: statePrompt || ''
-      }
+      voice_name: voiceName,
+      voice_config: voiceConfig,
+      conversation_history: conversationHistory,
+      user_message: userMessage,
+      original_text: originalText || '',
+      meta_prompt: metaPrompt || '',
+      state_prompt: statePrompt || ''
     })
   });
 
-  const data: TriggerResponse = await response.json();
+  const data: SyncResponse = await response.json();
+  console.log('‚úÖ Got chat response:', data);
+
   if (!data.success) {
-    throw new Error('Failed to trigger chat');
+    throw new Error(data.error || 'Chat failed');
   }
 
-  console.log('‚úÖ Chat triggered, exec_id:', data.exec_id);
-
-  // Poll for result
-  const result = await getAnalysisResult(data.exec_id);
-  console.log('‚úÖ Got chat response:', result);
-
-  return result?.response || 'Sorry, I could not respond.';
+  return data.result?.response || 'Sorry, I could not respond.';
 }
 
 /**
- * Analyze echoes (recurring themes) from all notes
+ * Analyze echoes (recurring themes) from all notes (sync API - no polling!)
  */
 export async function analyzeEchoes(allNotes: string): Promise<any[]> {
-  console.log('üîÑ Sending echoes analysis request...');
+  console.log('üîÑ Sending echoes analysis request (sync API)...');
 
-  const response = await fetch(`${API_BASE}/api/trigger`, {
+  const response = await fetch(`${API_BASE}/api/analyze-echoes`, {
     method: 'POST',
     headers: { 'Content-Type': 'application/json' },
-    body: JSON.stringify({
-      session_id: 'analyze_echoes',
-      params: { all_notes: allNotes }
-    })
+    body: JSON.stringify({ all_notes: allNotes })
   });
 
-  const data: TriggerResponse = await response.json();
+  const data: SyncResponse = await response.json();
+  console.log('‚úÖ Got echoes response:', data);
+
   if (!data.success) {
-    throw new Error('Failed to trigger echoes analysis');
+    throw new Error(data.error || 'Echoes analysis failed');
   }
 
-  const result = await getAnalysisResult(data.exec_id);
-  return result?.echoes || [];
+  return data.result?.echoes || [];
 }
 
 /**
- * Analyze traits (personality characteristics) from all notes
+ * Analyze traits (personality characteristics) from all notes (sync API - no polling!)
  */
 export async function analyzeTraits(allNotes: string): Promise<any[]> {
-  console.log('üë§ Sending traits analysis request...');
+  console.log('üë§ Sending traits analysis request (sync API)...');
 
-  const response = await fetch(`${API_BASE}/api/trigger`, {
+  const response = await fetch(`${API_BASE}/api/analyze-traits`, {
     method: 'POST',
     headers: { 'Content-Type': 'application/json' },
-    body: JSON.stringify({
-      session_id: 'analyze_traits',
-      params: { all_notes: allNotes }
-    })
+    body: JSON.stringify({ all_notes: allNotes })
   });
 
-  const data: TriggerResponse = await response.json();
+  const data: SyncResponse = await response.json();
+  console.log('‚úÖ Got traits response:', data);
+
   if (!data.success) {
-    throw new Error('Failed to trigger traits analysis');
+    throw new Error(data.error || 'Traits analysis failed');
   }
 
-  const result = await getAnalysisResult(data.exec_id);
-  return result?.traits || [];
+  return data.result?.traits || [];
 }
 
 /**
- * Analyze patterns (behavioral patterns) from all notes
+ * Analyze patterns (behavioral patterns) from all notes (sync API - no polling!)
  */
 export async function analyzePatterns(allNotes: string): Promise<any[]> {
-  console.log('üîç Sending patterns analysis request...');
+  console.log('üîç Sending patterns analysis request (sync API)...');
 
-  const response = await fetch(`${API_BASE}/api/trigger`, {
+  const response = await fetch(`${API_BASE}/api/analyze-patterns`, {
     method: 'POST',
     headers: { 'Content-Type': 'application/json' },
-    body: JSON.stringify({
-      session_id: 'analyze_patterns',
-      params: { all_notes: allNotes }
-    })
+    body: JSON.stringify({ all_notes: allNotes })
   });
 
-  const data: TriggerResponse = await response.json();
+  const data: SyncResponse = await response.json();
+  console.log('‚úÖ Got patterns response:', data);
+
   if (!data.success) {
-    throw new Error('Failed to trigger patterns analysis');
+    throw new Error(data.error || 'Patterns analysis failed');
   }
 
-  const result = await getAnalysisResult(data.exec_id);
-  return result?.patterns || [];
+  return data.result?.patterns || [];
 }
 
 /**
- * Generate a daily picture based on user's notes
+ * Generate a daily picture based on user's notes (sync API - no polling!)
  */
 export async function generateDailyPicture(allNotes: string): Promise<{ image_base64: string; prompt: string }> {
-  console.log('üé® Sending image generation request...');
+  console.log('üé® Sending image generation request (sync API)...');
 
-  const response = await fetch(`${API_BASE}/api/trigger`, {
+  const response = await fetch(`${API_BASE}/api/generate-image`, {
     method: 'POST',
     headers: { 'Content-Type': 'application/json' },
-    body: JSON.stringify({
-      session_id: 'generate_daily_picture',
-      params: { all_notes: allNotes }
-    })
+    body: JSON.stringify({ all_notes: allNotes })
   });
 
-  const data: TriggerResponse = await response.json();
+  const data: SyncResponse = await response.json();
+  console.log('‚úÖ Got image response:', data);
+
   if (!data.success) {
-    throw new Error('Failed to trigger image generation');
+    throw new Error(data.error || 'Image generation failed');
   }
 
-  const result = await getAnalysisResult(data.exec_id);
-
-  if (result?.image_base64) {
+  if (data.result?.image_base64) {
     return {
-      image_base64: result.image_base64,
-      prompt: result.prompt || 'Generated from your notes'
+      image_base64: data.result.image_base64,
+      prompt: data.result.prompt || 'Generated from your notes'
     };
   }
 
-  throw new Error('Image generation failed');
+  throw new Error('Image generation failed - no image in response');
 }
