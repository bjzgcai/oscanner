*** FILE: backend/server.py ***
@@ -10,12 +10,13 @@
 
 import asyncio
 import httpx
-from fastapi import FastAPI, HTTPException, Depends, Header
+from fastapi import FastAPI, HTTPException, Depends, Header, WebSocket
 from fastapi.middleware.cors import CORSMiddleware
 from polycli.orchestration.session_registry import session_def, get_registry
 from polycli.integrations.fastapi import mount_control_panel
 from polycli import PolyAgent
 from stateless_analyzer import analyze_stateless
+from speech_recognition import init_speech_recognition
 import config
 from proxy_config import get_image_api_proxies
 from typing import Optional
@@ -1623,6 +1624,13 @@ def get_friend_timeline(friend_id: int, limit: int = 30, current_user: dict = De
         raise HTTPException(status_code=403, detail="Not friends or friend not found")
     return {"pictures": timeline}
 
+@app.websocket("/ws/speech-recognition")
+async def speech_recognition(websocket: WebSocket):
+    # TODO: find a way of authentication for websocket
+    await websocket.accept()
+    await init_speech_recognition(websocket)
+
+
 # @@@ Removed /api/analyze wrapper - frontend now calls /polycli/api/trigger-sync directly
 
 # @@@ Removed /api/chat wrapper - frontend now calls /polycli/api/trigger-sync directly

*** FILE: backend/speech_recognition.py ***
@@ -0,0 +1,72 @@
+from fastapi import FastAPI, WebSocket, WebSocketDisconnect
+from dashscope.audio.asr import Recognition, RecognitionCallback, RecognitionResult
+import asyncio
+import json
+from typing import cast
+
+import dashscope
+# TODO: move api key to config
+dashscope.api_key = "sk-c4063b5a8e094b1691875f05b700a036"
+
+SAMPLE_RATE = 16000
+MODEL_NAME = "paraformer-realtime-v2"
+
+app = FastAPI()
+
+async def init_speech_recognition(websocket: WebSocket):
+    callback = Callback(websocket)
+    recognition = Recognition(
+        model=MODEL_NAME,
+        format="pcm",
+        sample_rate=SAMPLE_RATE,
+        callback=callback,
+    )
+    recognition.start()
+    print("Recognition started (model=%s, sample_rate=%d)" % (MODEL_NAME, SAMPLE_RATE))
+    try:
+        while True:
+            try:
+                data = await websocket.receive_bytes()
+                recognition.send_audio_frame(data)
+            except Exception as e:
+                print("Error during speech streaming: ", e)
+                break
+    except WebSocketDisconnect:
+        recognition.stop()
+    except Exception as e:
+        print("WebSocket handler error:", e)
+
+class Callback(RecognitionCallback):
+    def __init__(self, websocket: WebSocket) -> None:
+        self.websocket = websocket
+
+    def on_event(self, result: RecognitionResult) -> None:
+        """
+        Called by the recognition library when there's an update.
+        Compute incremental new_word and schedule broadcast to connected clients.
+
+        Example response from model:
+        {
+            'sentence_id': 1,
+            'begin_time': 0,
+            'end_time': None,
+            'text': '你好世界',
+            'channel_id': 0,
+            'speaker_id': None,
+            'sentence_end': False,
+            'words': [
+                {'begin_time': 0, 'end_time': 940, 'text': '你好', 'punctuation': '', 'fixed': False, 'speaker_id': None},
+                {'begin_time': 940, 'end_time': 1880, 'text': '世界', 'punctuation': '', 'fixed': False, 'speaker_id': None},
+            ]
+        }
+        """
+        sentence = result.get_sentence()
+        sentence = cast(dict, sentence)
+
+        sentence_id = sentence.get("sentence_id") or -1
+        text = sentence.get("text")
+        res = json.dumps({"id": sentence_id, "sentence": text})
+
+        async def send_text():
+            await self.websocket.send_text(res)
+        asyncio.run(send_text())

*** FILE: frontend/src/App.css ***
@@ -263,3 +263,47 @@
 .comments-panel::-webkit-scrollbar-thumb:hover {
   background: #999;
 }
+
+.voice-input-modal {
+  background-color: #25252588;
+  display: flex;
+  align-items: center;
+  justify-content: center;
+  height: 100vh;
+  width: 100vw;
+  position: fixed;
+  top: 0;
+  left: 0;
+  z-index: 99999;
+}
+
+.voice-input-container {
+  font-family: 'Excalifont', 'Xiaolai', 'Georgia', serif;
+  background-color: #ddd;
+  border-radius: 10px;
+  width: 50%;
+  height: 50%;
+}
+
+.voice-input-result {
+  font-size: 1.25rem;
+  box-sizing: border-box;
+  width: 100%;
+  height: 80%;
+  padding: 20px;
+  overflow: auto;
+}
+
+.voice-input-button-group {
+  display: flex;
+  align-items: center;
+  justify-content: space-around;
+  width: 100%;
+  height: 18%;
+}
+
+.voice-input-button-group button {
+  font-family: 'Excalifont', 'Xiaolai', 'Georgia', serif;
+  padding: 5px 10px;
+  font-size: 1.25rem;
+}

*** FILE: frontend/src/App.tsx ***
@@ -9,7 +9,7 @@ import {
   FaSync,
   FaBrain, FaHeart, FaQuestion, FaCloud, FaTheaterMasks, FaEye,
   FaFistRaised, FaLightbulb, FaShieldAlt, FaWind, FaFire, FaCompass,
-  FaAlignRight
+  FaAlignRight, FaMicrophone
 } from 'react-icons/fa';
 import TopNavBar from './components/TopNavBar';
 import DeckManager from './components/DeckManager';
@@ -47,12 +47,14 @@ function LeftToolbar({
   onToggleAlign,
   onShowCalendar,
   onSaveToday,
+  onStartTalking,
   isAligned
 }: {
   onInsertAgent: () => void;
   onToggleAlign: () => void;
   onShowCalendar: () => void;
   onSaveToday: () => void;
+  onStartTalking: () => void;
   isAligned: boolean;
 }) {
   return (
@@ -162,7 +164,7 @@ function LeftToolbar({
         @
       </button>
 
-      {/* Align button - last */}
+      {/* Align button - fourth */}
       <button
         onClick={onToggleAlign}
         title={isAligned ? "Unalign Comments" : "Align Comments Right"}
@@ -187,6 +189,32 @@ function LeftToolbar({
       >
         <FaAlignRight size={18} color={isAligned ? '#1976d2' : '#333'} />
       </button>
+
+      {/* Align button - last */}
+      <button
+        onClick={onStartTalking}
+        title="Voice Input"
+        style={{
+          width: '36px',
+          height: '36px',
+          border: 'none',
+          borderRadius: '4px',
+          backgroundColor: isAligned ? '#e3f2fd' : '#fff',
+          cursor: 'pointer',
+          display: 'flex',
+          alignItems: 'center',
+          justifyContent: 'center',
+          transition: 'all 0.2s ease'
+        }}
+        onMouseEnter={(e) => {
+          e.currentTarget.style.backgroundColor = isAligned ? '#bbdefb' : '#f0f0f0';
+        }}
+        onMouseLeave={(e) => {
+          e.currentTarget.style.backgroundColor = isAligned ? '#e3f2fd' : '#fff';
+        }}
+      >
+        <FaMicrophone size={18} color={isAligned ? '#1976d2' : '#333'} />
+      </button>
     </div>
   );
 }
@@ -1412,6 +1440,218 @@ export default function App() {
     }
   }, [ensureStateForPersistence, getFirstLineFromState, isAuthenticated, saveSessionToDatabase]);
 
+  const handleStartTalking = useCallback(async () => {
+    if (!textareaRefs.current) return;
+    if (!isAuthenticated) {
+      const toast = document.createElement('div');
+      toast.textContent = 'Please sign in to enable voice input';
+      toast.style.cssText = `
+        position: fixed;
+        top: 70px;
+        right: 20px;
+        background: #f44336;
+        color: white;
+        padding: 12px 20px;
+        borderRadius: 6px;
+        fontSize: 14px;
+        fontFamily: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto;
+        zIndex: 10000;
+        boxShadow: 0 4px 12px rgba(0,0,0,0.15);
+      `;
+      document.body.appendChild(toast);
+      setTimeout(() => {
+        toast.style.opacity = '0';
+        toast.style.transition = 'opacity 0.3s';
+        setTimeout(() => document.body.removeChild(toast), 300);
+      }, 2000);
+      return;
+    }
+
+    let voiceInputModal: HTMLDivElement = document.createElement('div');
+    voiceInputModal.className = 'voice-input-modal';
+    document.body.append(voiceInputModal);
+
+    let voiceInputContainer: HTMLDivElement = document.createElement('div');
+    voiceInputContainer.className = 'voice-input-container';
+    voiceInputModal.append(voiceInputContainer);
+
+    let voiceInputResult: HTMLParagraphElement = document.createElement('div');
+    voiceInputResult.className = 'voice-input-result';
+    voiceInputContainer.append(voiceInputResult);
+
+    let btnGroup: HTMLDivElement = document.createElement('div');
+    btnGroup.className = 'voice-input-button-group';
+    voiceInputContainer.append(btnGroup);
+
+    let startBtn: HTMLButtonElement = document.createElement('button');
+    startBtn.innerText = 'Start';
+
+    let stopBtn: HTMLButtonElement = document.createElement('button');
+    stopBtn.innerText = 'Pause';
+    stopBtn.disabled = true;
+
+    let applyBtn: HTMLButtonElement = document.createElement('button');
+    applyBtn.innerText = 'Apply';
+    applyBtn.disabled = true;
+
+    let cancelBtn: HTMLButtonElement = document.createElement('button');
+    cancelBtn.innerText = 'Cancel';
+
+    btnGroup.append(startBtn);
+    btnGroup.append(stopBtn);
+    btnGroup.append(applyBtn);
+    btnGroup.append(cancelBtn);
+
+    try {
+      let audioCtx: AudioContext;
+      let stream: MediaStream;
+      let processor: ScriptProcessorNode;
+      let source: MediaStreamAudioSourceNode;
+      let ws: WebSocket;
+      const targetSampleRate = 16000;
+
+      let sentences: Array<string> = [];
+      let sentenceId: number = -1;
+
+      function floatTo16BitPCM(float32Array: Float32Array): ArrayBuffer {
+        const buffer = new ArrayBuffer(float32Array.length * 2);
+        const view = new DataView(buffer);
+        let offset = 0;
+        for (let i = 0; i < float32Array.length; i++, offset += 2) {
+          let s = Math.max(-1, Math.min(1, float32Array[i]));
+          view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
+        }
+        return buffer;
+      }
+
+      function downsampleBuffer(buffer: Float32Array, inSampleRate: number, outSampleRate: number): Float32Array {
+        if (outSampleRate === inSampleRate) {
+          return buffer;
+        }
+        if (outSampleRate > inSampleRate) {
+          console.warn("downsampleBuffer: target sample rate is higher than input, returning original");
+          return buffer;
+        }
+        const sampleRateRatio = inSampleRate / outSampleRate;
+        const newLength = Math.round(buffer.length / sampleRateRatio);
+        const result = new Float32Array(newLength);
+        let offsetResult = 0;
+        let offsetBuffer = 0;
+        while (offsetResult < result.length) {
+          const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
+          let accum = 0, count = 0;
+          for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
+            accum += buffer[i];
+            count++;
+          }
+          result[offsetResult] = count ? accum / count : 0;
+          offsetResult++;
+          offsetBuffer = nextOffsetBuffer;
+        }
+        return result;
+      }
+
+      async function start() {
+        startBtn.disabled = true;
+        stopBtn.disabled = false;
+        applyBtn.disabled = false;
+
+        ws = new WebSocket('ws://127.0.0.1:8765/ws/speech-recognition');
+        ws.binaryType = 'arraybuffer';
+        ws.onerror = (e) => {
+          console.error('WS err', e);
+        };
+        ws.onmessage = (evt) => {
+          try {
+            const data = JSON.parse(evt.data);
+            let id = data.id;
+            if (id != sentenceId) {
+              sentenceId = id;
+              sentences.push('');
+            }
+            sentences[sentences.length - 1] = data.sentence;
+            voiceInputResult.innerHTML = sentences.map(v => `<p>${v}</p>`).join('');
+          } catch (e) {
+            console.log('Non-JSON message from server:', evt.data);
+          }
+        };
+
+        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
+        audioCtx = new window.AudioContext();
+        source = audioCtx.createMediaStreamSource(stream);
+
+        const inputSampleRate = audioCtx.sampleRate;
+        console.log('input sample rate', inputSampleRate);
+
+        const bufferSize = 4096;
+        processor = audioCtx.createScriptProcessor(bufferSize, 1, 1);
+
+        processor.onaudioprocess = (event) => {
+          const inputBuffer = event.inputBuffer.getChannelData(0);
+          const downsampled = downsampleBuffer(inputBuffer, inputSampleRate, targetSampleRate);
+          const pcm16ab = floatTo16BitPCM(downsampled);
+          if (ws && ws.readyState === WebSocket.OPEN) {
+            ws.send(pcm16ab);
+          }
+        };
+
+        source.connect(processor);
+        processor.connect(audioCtx.destination);
+
+        startBtn.disabled = true;
+        stopBtn.disabled = false;
+      }
+
+      function stop() {
+        startBtn.disabled = false;
+        stopBtn.disabled = true;
+
+        processor?.disconnect();
+        source?.disconnect();
+        audioCtx?.close();
+        stream?.getTracks().forEach(t => t.stop());
+        ws?.close();
+        startBtn.disabled = false;
+        stopBtn.disabled = true;
+        sentenceId = -1;
+      }
+
+      function apply() {
+        stop();
+        voiceInputModal.remove();
+
+        if (!engineRef.current) return;
+        const lastTextCell = [...engineRef.current.getState().cells].reverse().find(c => c.type === 'text');
+        if (!lastTextCell) return;
+        const textarea = textareaRefs.current.get(lastTextCell.id);
+        if (!textarea) return;
+
+        const currentContent = (lastTextCell as TextCell).content;
+        const newContent = currentContent + sentences.join('');
+        engineRef.current.updateTextCell(lastTextCell.id, newContent);
+
+        // Postpone setting of textarea height
+        setTimeout(() => {
+          textarea.style.height = `${textarea.scrollHeight}px`;
+        }, 100);
+      }
+
+      function cancel() {
+        stop();
+        voiceInputModal.remove();
+      }
+
+      startBtn.addEventListener('click', start);
+      stopBtn.addEventListener('click', stop);
+      applyBtn.addEventListener('click', apply);
+      cancelBtn.addEventListener('click', cancel);
+    
+    } catch (error) {
+      console.error('Voice input encountered an unexpected error:', error);
+      voiceInputModal.remove();
+    }
+  }, [isAuthenticated]);
+
   const handleLoadEntry = useCallback((entry: CalendarEntry) => {
     if (!engineRef.current) return;
 
@@ -2108,6 +2348,7 @@ export default function App() {
                 onToggleAlign={handleToggleAlign}
                 onShowCalendar={() => setShowCalendarPopup(true)}
                 onSaveToday={handleSaveToday}
+                onStartTalking={handleStartTalking}
                 isAligned={commentsAligned}
               />
             </div>
