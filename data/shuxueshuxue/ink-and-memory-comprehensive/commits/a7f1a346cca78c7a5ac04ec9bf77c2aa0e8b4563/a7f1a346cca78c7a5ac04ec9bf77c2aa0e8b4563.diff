commit a7f1a346cca78c7a5ac04ec9bf77c2aa0e8b4563
Author: lexicalmathical <lexicalmathical@gmail.com>
Date:   Thu Oct 30 09:22:46 2025 +0800

    Code cleanup: remove temporary test files
    
    Remove files that were accidentally committed:
    - frontend/src/App.old.tsx (old backup file)
    - backend/proxy_config.py (test proxy configuration)
    - backend/test_image_gen.py (debugging script)
    
    ðŸ¤– Generated with Claude Code
    
    Co-Authored-By: Claude <noreply@anthropic.com>

diff --git a/backend/proxy_config.py b/backend/proxy_config.py
deleted file mode 100644
index 2456524..0000000
--- a/backend/proxy_config.py
+++ /dev/null
@@ -1,28 +0,0 @@
-"""Proxy configuration for API calls that need GFW bypass."""
-import os
-
-def get_image_api_proxies():
-    """
-    Get proxy configuration for image generation API calls.
-    
-    Returns dict for requests.post(proxies=...) or None if no proxy configured.
-    
-    Configuration priority:
-    1. Environment variable IMAGE_API_PROXY (e.g., "socks5://localhost:7890")
-    2. Return None (no proxy)
-    
-    Usage in server.py:
-        proxies = get_image_api_proxies()
-        response = requests.post(url, proxies=proxies, ...)  # None is valid
-    """
-    proxy_url = os.getenv('IMAGE_API_PROXY')
-    
-    if proxy_url:
-        print(f"[Proxy Config] Using proxy for image API: {proxy_url}")
-        return {
-            'http': proxy_url,
-            'https': proxy_url
-        }
-    else:
-        print("[Proxy Config] No proxy configured for image API")
-        return None
diff --git a/backend/test_image_gen.py b/backend/test_image_gen.py
deleted file mode 100644
index cb81104..0000000
--- a/backend/test_image_gen.py
+++ /dev/null
@@ -1,91 +0,0 @@
-#!/usr/bin/env python3
-"""Test Gemini image generation via dou.chat endpoint"""
-
-import requests
-import json
-import base64
-from pathlib import Path
-
-API_KEY = "sk-yz0JLc7sGbCHnwam70Bc9e29Dc684bAe904102C95dF32fB1"
-ENDPOINT = "https://api.dou.chat/v1"
-MODEL = "google/gemini-2.5-flash-image-preview"
-
-def test_image_generation():
-    """Test if image generation works with the given model"""
-
-    print(f"\n{'='*60}")
-    print(f"ðŸŽ¨ Testing Image Generation")
-    print(f"   Endpoint: {ENDPOINT}")
-    print(f"   Model: {MODEL}")
-    print(f"{'='*60}\n")
-
-    # Try a simple prompt
-    prompt = "A serene morning scene with a cup of coffee on a wooden table, sunlight streaming through a window, peaceful and contemplative mood"
-
-    print(f"Prompt: {prompt}\n")
-
-    # Make request
-    url = f"{ENDPOINT}/chat/completions"
-    headers = {
-        "Authorization": f"Bearer {API_KEY}",
-        "Content-Type": "application/json"
-    }
-
-    payload = {
-        "model": MODEL,
-        "messages": [
-            {
-                "role": "user",
-                "content": prompt
-            }
-        ],
-        "max_tokens": 1000
-    }
-
-    print("Sending request...")
-    try:
-        response = requests.post(url, headers=headers, json=payload, timeout=60)
-        print(f"Status: {response.status_code}")
-
-        if response.status_code == 200:
-            data = response.json()
-            print("\nâœ… Success!")
-            print(json.dumps(data, indent=2))
-
-            # Check if there's image data
-            if 'choices' in data and len(data['choices']) > 0:
-                message = data['choices'][0].get('message', {})
-                images = message.get('images', [])
-
-                if images:
-                    print(f"\nðŸ–¼ï¸  Found {len(images)} image(s)!")
-
-                    # Extract first image
-                    image_data = images[0].get('image_url', {}).get('url', '')
-
-                    if image_data.startswith('data:image/png;base64,'):
-                        # Extract base64 data
-                        base64_data = image_data.split(',', 1)[1]
-
-                        # Decode and save
-                        image_bytes = base64.b64decode(base64_data)
-                        output_path = Path("/tmp/test_gemini_image.png")
-                        output_path.write_bytes(image_bytes)
-
-                        print(f"âœ… Image saved to: {output_path}")
-                        print(f"   Size: {len(image_bytes)} bytes")
-                        print(f"\nðŸ’¡ Open with: open {output_path}")
-                    else:
-                        print(f"âš ï¸  Unexpected image format: {image_data[:100]}...")
-                else:
-                    print("\nâŒ No images found in response")
-
-        else:
-            print(f"\nâŒ Error: {response.status_code}")
-            print(response.text)
-
-    except Exception as e:
-        print(f"\nâŒ Exception: {e}")
-
-if __name__ == "__main__":
-    test_image_generation()
diff --git a/frontend/src/App.old.tsx b/frontend/src/App.old.tsx
deleted file mode 100644
index e6d859f..0000000
--- a/frontend/src/App.old.tsx
+++ /dev/null
@@ -1,415 +0,0 @@
-import { useState, useEffect, useRef } from 'react'
-import './App.css'
-import WritingArea from './components/WritingArea'
-import type { EditableTextAreaRef } from './components/EditableTextArea'
-import VoicesPanel from './components/VoicesPanel'
-import VoiceComment from './components/VoiceComment'
-import BinderRings from './components/BinderRings'
-import VoiceSettings from './components/VoiceSettings'
-import CalendarView from './components/CalendarView'
-import AnalysisView from './components/AnalysisView'
-import AboutView from './components/AboutView'
-import LeftSidebar from './components/LeftSidebar'
-import type { VoiceTrigger } from './extensions/VoiceHighlight'
-import type { VoiceConfig } from './types/voice'
-import { analyzeText, getDefaultVoices } from './api/voiceApi'
-import { getVoices } from './utils/voiceStorage'
-
-interface Voice {
-  name: string;
-  text: string;
-  icon: string;
-  color: string;
-  position: number;
-}
-
-// @@@ UUID fallback for non-secure contexts
-function generateUUID() {
-  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
-    const r = Math.random() * 16 | 0;
-    const v = c === 'x' ? r : (r & 0x3 | 0x8);
-    return v.toString(16);
-  });
-}
-
-function App() {
-  // @@@ Multi-user support - Generate unique session ID on mount
-  const sessionId = useRef(
-    typeof crypto !== 'undefined' && crypto.randomUUID
-      ? crypto.randomUUID()
-      : generateUUID()
-  ).current;
-
-  // @@@ Version logging and initialize default voices from backend
-  useEffect(() => {
-    console.log('ðŸŽ­ Ink & Memory - Version: v1.2.1-energy-refund');
-    console.log('âš¡ Energy pool trigger: accumulate weight changes, trigger at 40 energy');
-    console.log('â™»ï¸  Energy refund: if LLM returns no voices, refund 20 energy');
-    console.log('ðŸ“ Weights: CJK=2, punctuation(.!?ã€‚ï¼ï¼Ÿï¼Œ\\n)=4, other=1');
-    console.log('ðŸ”’ Single-threaded: max 1 backend request at a time');
-
-    // Fetch default voices from backend
-    getDefaultVoices().then(backendVoices => {
-      // Convert backend format to frontend VoiceConfig format (keep text names)
-      const converted: Record<string, VoiceConfig> = {};
-      for (const [name, data] of Object.entries(backendVoices)) {
-        const v = data as any;
-        converted[name] = {
-          name,
-          systemPrompt: v.tagline,
-          enabled: true,
-          icon: v.icon,    // Keep text name: "brain"
-          color: v.color   // Keep text name: "blue"
-        };
-      }
-      // Store the original defaults separately (never modified)
-      setDefaultVoiceConfigs(converted);
-      // Use localStorage if exists, otherwise use backend defaults
-      setVoiceConfigs(getVoices() || converted);
-    });
-  }, [sessionId]);
-
-  const [currentView, setCurrentView] = useState<'writing' | 'settings' | 'calendar' | 'analysis' | 'about'>('writing');
-  const [voices, setVoices] = useState<Voice[]>([]);
-  const [voiceTriggers, setVoiceTriggers] = useState<VoiceTrigger[]>([]);
-  const [voiceConfigs, setVoiceConfigs] = useState<Record<string, VoiceConfig>>({});
-  const [defaultVoiceConfigs, setDefaultVoiceConfigs] = useState<Record<string, VoiceConfig>>({});
-  const [currentText, setCurrentText] = useState<string>('');
-  const [currentHTML, setCurrentHTML] = useState<string>('');
-  const [cursorPosition, setCursorPosition] = useState<number>(0);
-  const [focusedVoiceIndex, setFocusedVoiceIndex] = useState<number | undefined>(undefined);
-  const [hoveredPhrase, setHoveredPhrase] = useState<string | null>(null);
-  const [quotedComments, setQuotedComments] = useState<Array<{ voiceName: string; comment: string }>>([]);
-  const currentTextRef = useRef<string>('');
-  const isAnalyzingRef = useRef<boolean>(false);
-  const editorRef = useRef<EditableTextAreaRef>(null);
-
-  // @@@ Energy pool trigger system
-  const energyRef = useRef<number>(0);
-  const lastPollWeightRef = useRef<number>(0);
-
-  const detectVoices = (text: string, triggers: VoiceTrigger[]) => {
-    const newVoices: Voice[] = [];
-    const lowerText = text.toLowerCase();
-
-    triggers.forEach(({ phrase, voice, comment, icon, color }) => {
-      const index = lowerText.indexOf(phrase.toLowerCase());
-      if (index !== -1) {
-        newVoices.push({ name: voice, text: comment, icon, color, position: index });
-      }
-    });
-
-    // Sort by position in text
-    newVoices.sort((a, b) => a.position - b.position);
-
-    setVoices(newVoices);
-  };
-
-  // @@@ Track which voice comment to focus based on cursor position
-  useEffect(() => {
-    if (voices.length === 0) {
-      setFocusedVoiceIndex(undefined);
-      return;
-    }
-
-    // Find the comment whose trigger phrase is closest to cursor
-    let closestIndex = 0;
-    let closestDistance = Math.abs(voices[0].position - cursorPosition);
-
-    for (let i = 1; i < voices.length; i++) {
-      const distance = Math.abs(voices[i].position - cursorPosition);
-      if (distance < closestDistance) {
-        closestDistance = distance;
-        closestIndex = i;
-      }
-    }
-
-    setFocusedVoiceIndex(closestIndex);
-  }, [cursorPosition, voices]);
-
-  // @@@ weighted-character-counting with punctuation bonus
-  // Sentence separators get high weight to encourage natural boundaries
-  const getWeightedLength = (text: string): number => {
-    let weight = 0;
-
-    for (const char of text) {
-      // Sentence separators (English + Chinese) and newlines = 4 weight
-      if (/[.!?ã€‚ï¼ï¼Ÿ\n]/.test(char)) {
-        weight += 4;
-      }
-      // Chinese comma = 0 weight (ignored)
-      else if (char === 'ï¼Œ') {
-        weight += 0;
-      }
-      // CJK characters (Chinese, Japanese, Korean) = 2 weight
-      else if (/[\u4e00-\u9fa5\u3040-\u309f\u30a0-\u30ff]/.test(char)) {
-        weight += 2;
-      }
-      // English/other = 1 weight
-      else {
-        weight += 1;
-      }
-    }
-
-    return weight;
-  };
-
-  const analyzeIfNeeded = async () => {
-    // Skip if already analyzing (single-threaded)
-    if (isAnalyzingRef.current) {
-      return;
-    }
-
-    // @@@ Use text without quotes for weight calculation
-    // Atomic quote widgets are automatically excluded
-    const textForWeighting = editorRef.current?.getTextWithoutQuotes() || currentTextRef.current;
-    const currentWeight = getWeightedLength(textForWeighting);
-
-    // Still use full text for backend analysis
-    const currentTextValue = currentTextRef.current;
-
-    // Calculate weight difference since last poll
-    const weightDiff = currentWeight - lastPollWeightRef.current;
-
-    // Accumulate energy (only positive changes, ignore deletions)
-    if (weightDiff > 0) {
-      energyRef.current += weightDiff;
-      console.log(`âš¡ Energy accumulated: +${weightDiff} â†’ ${energyRef.current} total`);
-    }
-
-    // @@@ Update last poll weight ALWAYS (every cycle, even if negative)
-    lastPollWeightRef.current = currentWeight;
-
-    // Check if we have enough energy to trigger
-    if (energyRef.current < 40) {
-      return;
-    }
-
-    // Trigger backend request and consume energy
-    isAnalyzingRef.current = true;
-    energyRef.current -= 40;
-    const remainingEnergy = energyRef.current;
-
-    try {
-      console.log(`ðŸ” Calling backend analysis (consumed 40 energy, ${remainingEnergy} remaining)...`);
-      console.log(`ðŸ“ Current voiceConfigs:`, voiceConfigs);
-      // Convert frontend VoiceConfig to backend format
-      const backendFormat: Record<string, any> = {};
-      for (const [name, cfg] of Object.entries(voiceConfigs)) {
-        if (cfg.enabled) {
-          backendFormat[name] = {
-            name: cfg.name,
-            tagline: cfg.systemPrompt,
-            icon: cfg.icon,
-            color: cfg.color
-          };
-        }
-      }
-      console.log(`ðŸ“¤ Sending to backend:`, backendFormat);
-      const result = await analyzeText(currentTextValue, sessionId, backendFormat);
-      console.log(`âœ… Got ${result.voices.length} total voices (${result.new_voices_added} new from this LLM call)`);
-
-      // @@@ Energy refund mechanism - if LLM returns no NEW comments, refund 20 energy
-      // This prevents wasting energy when nothing interesting is detected
-      if (result.new_voices_added === 0) {
-        energyRef.current += 20;
-        console.log(`â™»ï¸  No new voices detected, refunded 20 energy â†’ ${energyRef.current} total`);
-      }
-
-      setVoiceTriggers(result.voices);
-      detectVoices(currentTextValue, result.voices);
-    } catch (error) {
-      console.error('âŒ Voice analysis failed:', error);
-    } finally {
-      isAnalyzingRef.current = false;
-    }
-  };
-
-  // @@@ Reset weight baseline when switching back to writing view
-  // Prevents energy accumulation from "seeing" the full text again
-  useEffect(() => {
-    if (currentView === 'writing' && editorRef.current) {
-      const textForWeighting = editorRef.current.getTextWithoutQuotes() || currentTextRef.current;
-      lastPollWeightRef.current = getWeightedLength(textForWeighting);
-      console.log(`ðŸ”„ Switched to writing view, reset baseline weight to ${lastPollWeightRef.current}`);
-    }
-  }, [currentView]);
-
-  // @@@ Polling strategy - Check every 5 seconds (stable interval)
-  // Must include voiceConfigs in deps so interval uses latest config
-  // Only run when in writing view to prevent energy accumulation when switched away
-  useEffect(() => {
-    if (currentView !== 'writing') {
-      return;
-    }
-
-    const interval = setInterval(analyzeIfNeeded, 5000);
-    return () => clearInterval(interval);
-  }, [voiceConfigs, currentView]);
-
-  const handleTextChange = (newText: string) => {
-    setCurrentText(newText);
-    currentTextRef.current = newText;
-
-    // Instantly update display with current triggers
-    detectVoices(newText, voiceTriggers);
-  };
-
-  const handleContentChange = (newHTML: string) => {
-    setCurrentHTML(newHTML);
-
-    // @@@ Update quoted comments list whenever content changes
-    if (editorRef.current?.getQuotedComments) {
-      setQuotedComments(editorRef.current.getQuotedComments());
-    }
-  };
-
-  const handleQuote = (voiceName: string, comment: string) => {
-    // @@@ Insert atomic voice quote widget
-    // Quotes are now special nodes that are automatically excluded from weight calculation
-    if (editorRef.current?.insertVoiceQuote) {
-      // Get voice config for this voice (for chat context)
-      const voiceConfig = voiceConfigs[voiceName] || {
-        tagline: `${voiceName} voice`
-      };
-
-      editorRef.current.insertVoiceQuote(voiceName, comment, {
-        tagline: voiceConfig.systemPrompt,
-        icon: voiceConfig.icon,
-        color: voiceConfig.color
-      });
-    } else {
-      console.error('insertVoiceQuote method not available on editorRef');
-    }
-  };
-
-  // @@@ Re-detect voices when triggers change
-  useEffect(() => {
-    detectVoices(currentText, voiceTriggers);
-  }, [voiceTriggers]);
-
-  // @@@ Clear old triggers when voice config changes (e.g., Use Default)
-  // This forces immediate re-analysis with new config
-  useEffect(() => {
-    // Skip on initial mount (voiceConfigs is empty)
-    if (Object.keys(voiceConfigs).length === 0) return;
-
-    console.log('ðŸ”„ Voice config changed, clearing old triggers and triggering immediate analysis');
-    setVoiceTriggers([]);
-    setVoices([]);
-
-    // Force immediate re-analysis (session ID ensures backend returns cached results)
-    energyRef.current = 40;
-    analyzeIfNeeded();
-  }, [voiceConfigs]);
-
-  return (
-    <>
-      <LeftSidebar currentView={currentView} onViewChange={setCurrentView} />
-      {currentView === 'writing' && (
-        <div className="book-interface">
-          <WritingArea
-            ref={editorRef}
-            onChange={handleTextChange}
-            onContentChange={handleContentChange}
-            triggers={voiceTriggers}
-            onCursorChange={setCursorPosition}
-            onPhraseHover={setHoveredPhrase}
-            content={currentHTML}
-          />
-          <VoicesPanel focusedVoiceIndex={focusedVoiceIndex}>
-            {voices
-              .filter(voice => {
-                // @@@ Hide comments that are already quoted as widgets
-                return !quotedComments.some(
-                  quoted => quoted.voiceName === voice.name && quoted.comment === voice.text
-                );
-              })
-              .map((voice, index) => {
-                // @@@ Find the trigger phrase for this voice
-                const trigger = voiceTriggers.find(t =>
-                  t.voice === voice.name && t.comment === voice.text
-                );
-                const isHovered = hoveredPhrase !== null && trigger !== undefined &&
-                  hoveredPhrase.toLowerCase() === trigger.phrase.toLowerCase();
-
-                return (
-                  <VoiceComment
-                    key={index}
-                    voice={voice.name}
-                    text={voice.text}
-                    icon={voice.icon}
-                    color={voice.color}
-                    onQuote={() => handleQuote(voice.name, voice.text)}
-                    isHovered={isHovered}
-                  />
-                );
-              })}
-          </VoicesPanel>
-          <BinderRings />
-        </div>
-      )}
-      {currentView === 'settings' && (
-        <div style={{
-          position: 'fixed',
-          top: 48,
-          left: 0,
-          right: 0,
-          bottom: 0,
-          background: '#f8f0e6',
-          display: 'flex',
-          overflow: 'hidden'
-        }}>
-          <VoiceSettings
-            defaultVoices={defaultVoiceConfigs}
-            onSave={setVoiceConfigs}
-          />
-        </div>
-      )}
-      {currentView === 'calendar' && (
-        <div style={{
-          position: 'fixed',
-          top: 48,
-          left: 0,
-          right: 0,
-          bottom: 0,
-          background: '#f8f0e6',
-          display: 'flex',
-          overflow: 'hidden'
-        }}>
-          <CalendarView />
-        </div>
-      )}
-      {currentView === 'analysis' && (
-        <div style={{
-          position: 'fixed',
-          top: 48,
-          left: 0,
-          right: 0,
-          bottom: 0,
-          background: '#f8f0e6',
-          display: 'flex',
-          overflow: 'hidden'
-        }}>
-          <AnalysisView />
-        </div>
-      )}
-      {currentView === 'about' && (
-        <div style={{
-          position: 'fixed',
-          top: 48,
-          left: 0,
-          right: 0,
-          bottom: 0,
-          background: '#f8f0e6',
-          display: 'flex',
-          overflow: 'hidden'
-        }}>
-          <AboutView />
-        </div>
-      )}
-    </>
-  );
-}
-
-export default App
\ No newline at end of file
