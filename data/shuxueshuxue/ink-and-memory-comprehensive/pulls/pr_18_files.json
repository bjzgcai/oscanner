[
  {
    "sha": "3b2aed97cbf84d4fc705b5f7e566f41fceecf806",
    "filename": "backend/server.py",
    "status": "modified",
    "additions": 9,
    "deletions": 1,
    "changes": 10,
    "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/bc06173f92d704ef74ef5839123ea519d448d160/backend%2Fserver.py",
    "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/bc06173f92d704ef74ef5839123ea519d448d160/backend%2Fserver.py",
    "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fserver.py?ref=bc06173f92d704ef74ef5839123ea519d448d160",
    "patch": "@@ -10,12 +10,13 @@\n \n import asyncio\n import httpx\n-from fastapi import FastAPI, HTTPException, Depends, Header\n+from fastapi import FastAPI, HTTPException, Depends, Header, WebSocket\n from fastapi.middleware.cors import CORSMiddleware\n from polycli.orchestration.session_registry import session_def, get_registry\n from polycli.integrations.fastapi import mount_control_panel\n from polycli import PolyAgent\n from stateless_analyzer import analyze_stateless\n+from speech_recognition import init_speech_recognition\n import config\n from proxy_config import get_image_api_proxies\n from typing import Optional\n@@ -1623,6 +1624,13 @@ def get_friend_timeline(friend_id: int, limit: int = 30, current_user: dict = De\n         raise HTTPException(status_code=403, detail=\"Not friends or friend not found\")\n     return {\"pictures\": timeline}\n \n+@app.websocket(\"/ws/speech-recognition\")\n+async def speech_recognition(websocket: WebSocket):\n+    # TODO: find a way of authentication for websocket\n+    await websocket.accept()\n+    await init_speech_recognition(websocket)\n+\n+\n # @@@ Removed /api/analyze wrapper - frontend now calls /polycli/api/trigger-sync directly\n \n # @@@ Removed /api/chat wrapper - frontend now calls /polycli/api/trigger-sync directly"
  },
  {
    "sha": "72758a2060f1f71a2d10d4980f29d075eb79e8d8",
    "filename": "backend/speech_recognition.py",
    "status": "added",
    "additions": 72,
    "deletions": 0,
    "changes": 72,
    "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/bc06173f92d704ef74ef5839123ea519d448d160/backend%2Fspeech_recognition.py",
    "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/bc06173f92d704ef74ef5839123ea519d448d160/backend%2Fspeech_recognition.py",
    "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fspeech_recognition.py?ref=bc06173f92d704ef74ef5839123ea519d448d160",
    "patch": "@@ -0,0 +1,72 @@\n+from fastapi import FastAPI, WebSocket, WebSocketDisconnect\n+from dashscope.audio.asr import Recognition, RecognitionCallback, RecognitionResult\n+import asyncio\n+import json\n+from typing import cast\n+\n+import dashscope\n+# TODO: move api key to config\n+dashscope.api_key = \"sk-c4063b5a8e094b1691875f05b700a036\"\n+\n+SAMPLE_RATE = 16000\n+MODEL_NAME = \"paraformer-realtime-v2\"\n+\n+app = FastAPI()\n+\n+async def init_speech_recognition(websocket: WebSocket):\n+    callback = Callback(websocket)\n+    recognition = Recognition(\n+        model=MODEL_NAME,\n+        format=\"pcm\",\n+        sample_rate=SAMPLE_RATE,\n+        callback=callback,\n+    )\n+    recognition.start()\n+    print(\"Recognition started (model=%s, sample_rate=%d)\" % (MODEL_NAME, SAMPLE_RATE))\n+    try:\n+        while True:\n+            try:\n+                data = await websocket.receive_bytes()\n+                recognition.send_audio_frame(data)\n+            except Exception as e:\n+                print(\"Error during speech streaming: \", e)\n+                break\n+    except WebSocketDisconnect:\n+        recognition.stop()\n+    except Exception as e:\n+        print(\"WebSocket handler error:\", e)\n+\n+class Callback(RecognitionCallback):\n+    def __init__(self, websocket: WebSocket) -> None:\n+        self.websocket = websocket\n+\n+    def on_event(self, result: RecognitionResult) -> None:\n+        \"\"\"\n+        Called by the recognition library when there's an update.\n+        Compute incremental new_word and schedule broadcast to connected clients.\n+\n+        Example response from model:\n+        {\n+            'sentence_id': 1,\n+            'begin_time': 0,\n+            'end_time': None,\n+            'text': '\u4f60\u597d\u4e16\u754c',\n+            'channel_id': 0,\n+            'speaker_id': None,\n+            'sentence_end': False,\n+            'words': [\n+                {'begin_time': 0, 'end_time': 940, 'text': '\u4f60\u597d', 'punctuation': '', 'fixed': False, 'speaker_id': None},\n+                {'begin_time': 940, 'end_time': 1880, 'text': '\u4e16\u754c', 'punctuation': '', 'fixed': False, 'speaker_id': None},\n+            ]\n+        }\n+        \"\"\"\n+        sentence = result.get_sentence()\n+        sentence = cast(dict, sentence)\n+\n+        sentence_id = sentence.get(\"sentence_id\") or -1\n+        text = sentence.get(\"text\")\n+        res = json.dumps({\"id\": sentence_id, \"sentence\": text})\n+\n+        async def send_text():\n+            await self.websocket.send_text(res)\n+        asyncio.run(send_text())"
  },
  {
    "sha": "4f0f8d98bd52d1d5ba921ac81f7a13ca065ce41d",
    "filename": "frontend/src/App.css",
    "status": "modified",
    "additions": 44,
    "deletions": 0,
    "changes": 44,
    "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/bc06173f92d704ef74ef5839123ea519d448d160/frontend%2Fsrc%2FApp.css",
    "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/bc06173f92d704ef74ef5839123ea519d448d160/frontend%2Fsrc%2FApp.css",
    "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/frontend%2Fsrc%2FApp.css?ref=bc06173f92d704ef74ef5839123ea519d448d160",
    "patch": "@@ -263,3 +263,47 @@\n .comments-panel::-webkit-scrollbar-thumb:hover {\n   background: #999;\n }\n+\n+.voice-input-modal {\n+  background-color: #25252588;\n+  display: flex;\n+  align-items: center;\n+  justify-content: center;\n+  height: 100vh;\n+  width: 100vw;\n+  position: fixed;\n+  top: 0;\n+  left: 0;\n+  z-index: 99999;\n+}\n+\n+.voice-input-container {\n+  font-family: 'Excalifont', 'Xiaolai', 'Georgia', serif;\n+  background-color: #ddd;\n+  border-radius: 10px;\n+  width: 50%;\n+  height: 50%;\n+}\n+\n+.voice-input-result {\n+  font-size: 1.25rem;\n+  box-sizing: border-box;\n+  width: 100%;\n+  height: 80%;\n+  padding: 20px;\n+  overflow: auto;\n+}\n+\n+.voice-input-button-group {\n+  display: flex;\n+  align-items: center;\n+  justify-content: space-around;\n+  width: 100%;\n+  height: 18%;\n+}\n+\n+.voice-input-button-group button {\n+  font-family: 'Excalifont', 'Xiaolai', 'Georgia', serif;\n+  padding: 5px 10px;\n+  font-size: 1.25rem;\n+}"
  },
  {
    "sha": "1c9409845899f4b73955faec76e6680b3a078eb1",
    "filename": "frontend/src/App.tsx",
    "status": "modified",
    "additions": 243,
    "deletions": 2,
    "changes": 245,
    "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/bc06173f92d704ef74ef5839123ea519d448d160/frontend%2Fsrc%2FApp.tsx",
    "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/bc06173f92d704ef74ef5839123ea519d448d160/frontend%2Fsrc%2FApp.tsx",
    "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/frontend%2Fsrc%2FApp.tsx?ref=bc06173f92d704ef74ef5839123ea519d448d160",
    "patch": "@@ -9,7 +9,7 @@ import {\n   FaSync,\n   FaBrain, FaHeart, FaQuestion, FaCloud, FaTheaterMasks, FaEye,\n   FaFistRaised, FaLightbulb, FaShieldAlt, FaWind, FaFire, FaCompass,\n-  FaAlignRight\n+  FaAlignRight, FaMicrophone\n } from 'react-icons/fa';\n import TopNavBar from './components/TopNavBar';\n import DeckManager from './components/DeckManager';\n@@ -47,12 +47,14 @@ function LeftToolbar({\n   onToggleAlign,\n   onShowCalendar,\n   onSaveToday,\n+  onStartTalking,\n   isAligned\n }: {\n   onInsertAgent: () => void;\n   onToggleAlign: () => void;\n   onShowCalendar: () => void;\n   onSaveToday: () => void;\n+  onStartTalking: () => void;\n   isAligned: boolean;\n }) {\n   return (\n@@ -162,7 +164,7 @@ function LeftToolbar({\n         @\n       </button>\n \n-      {/* Align button - last */}\n+      {/* Align button - fourth */}\n       <button\n         onClick={onToggleAlign}\n         title={isAligned ? \"Unalign Comments\" : \"Align Comments Right\"}\n@@ -187,6 +189,32 @@ function LeftToolbar({\n       >\n         <FaAlignRight size={18} color={isAligned ? '#1976d2' : '#333'} />\n       </button>\n+\n+      {/* Align button - last */}\n+      <button\n+        onClick={onStartTalking}\n+        title=\"Voice Input\"\n+        style={{\n+          width: '36px',\n+          height: '36px',\n+          border: 'none',\n+          borderRadius: '4px',\n+          backgroundColor: isAligned ? '#e3f2fd' : '#fff',\n+          cursor: 'pointer',\n+          display: 'flex',\n+          alignItems: 'center',\n+          justifyContent: 'center',\n+          transition: 'all 0.2s ease'\n+        }}\n+        onMouseEnter={(e) => {\n+          e.currentTarget.style.backgroundColor = isAligned ? '#bbdefb' : '#f0f0f0';\n+        }}\n+        onMouseLeave={(e) => {\n+          e.currentTarget.style.backgroundColor = isAligned ? '#e3f2fd' : '#fff';\n+        }}\n+      >\n+        <FaMicrophone size={18} color={isAligned ? '#1976d2' : '#333'} />\n+      </button>\n     </div>\n   );\n }\n@@ -1412,6 +1440,218 @@ export default function App() {\n     }\n   }, [ensureStateForPersistence, getFirstLineFromState, isAuthenticated, saveSessionToDatabase]);\n \n+  const handleStartTalking = useCallback(async () => {\n+    if (!textareaRefs.current) return;\n+    if (!isAuthenticated) {\n+      const toast = document.createElement('div');\n+      toast.textContent = 'Please sign in to enable voice input';\n+      toast.style.cssText = `\n+        position: fixed;\n+        top: 70px;\n+        right: 20px;\n+        background: #f44336;\n+        color: white;\n+        padding: 12px 20px;\n+        borderRadius: 6px;\n+        fontSize: 14px;\n+        fontFamily: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto;\n+        zIndex: 10000;\n+        boxShadow: 0 4px 12px rgba(0,0,0,0.15);\n+      `;\n+      document.body.appendChild(toast);\n+      setTimeout(() => {\n+        toast.style.opacity = '0';\n+        toast.style.transition = 'opacity 0.3s';\n+        setTimeout(() => document.body.removeChild(toast), 300);\n+      }, 2000);\n+      return;\n+    }\n+\n+    let voiceInputModal: HTMLDivElement = document.createElement('div');\n+    voiceInputModal.className = 'voice-input-modal';\n+    document.body.append(voiceInputModal);\n+\n+    let voiceInputContainer: HTMLDivElement = document.createElement('div');\n+    voiceInputContainer.className = 'voice-input-container';\n+    voiceInputModal.append(voiceInputContainer);\n+\n+    let voiceInputResult: HTMLParagraphElement = document.createElement('div');\n+    voiceInputResult.className = 'voice-input-result';\n+    voiceInputContainer.append(voiceInputResult);\n+\n+    let btnGroup: HTMLDivElement = document.createElement('div');\n+    btnGroup.className = 'voice-input-button-group';\n+    voiceInputContainer.append(btnGroup);\n+\n+    let startBtn: HTMLButtonElement = document.createElement('button');\n+    startBtn.innerText = 'Start';\n+\n+    let stopBtn: HTMLButtonElement = document.createElement('button');\n+    stopBtn.innerText = 'Pause';\n+    stopBtn.disabled = true;\n+\n+    let applyBtn: HTMLButtonElement = document.createElement('button');\n+    applyBtn.innerText = 'Apply';\n+    applyBtn.disabled = true;\n+\n+    let cancelBtn: HTMLButtonElement = document.createElement('button');\n+    cancelBtn.innerText = 'Cancel';\n+\n+    btnGroup.append(startBtn);\n+    btnGroup.append(stopBtn);\n+    btnGroup.append(applyBtn);\n+    btnGroup.append(cancelBtn);\n+\n+    try {\n+      let audioCtx: AudioContext;\n+      let stream: MediaStream;\n+      let processor: ScriptProcessorNode;\n+      let source: MediaStreamAudioSourceNode;\n+      let ws: WebSocket;\n+      const targetSampleRate = 16000;\n+\n+      let sentences: Array<string> = [];\n+      let sentenceId: number = -1;\n+\n+      function floatTo16BitPCM(float32Array: Float32Array): ArrayBuffer {\n+        const buffer = new ArrayBuffer(float32Array.length * 2);\n+        const view = new DataView(buffer);\n+        let offset = 0;\n+        for (let i = 0; i < float32Array.length; i++, offset += 2) {\n+          let s = Math.max(-1, Math.min(1, float32Array[i]));\n+          view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);\n+        }\n+        return buffer;\n+      }\n+\n+      function downsampleBuffer(buffer: Float32Array, inSampleRate: number, outSampleRate: number): Float32Array {\n+        if (outSampleRate === inSampleRate) {\n+          return buffer;\n+        }\n+        if (outSampleRate > inSampleRate) {\n+          console.warn(\"downsampleBuffer: target sample rate is higher than input, returning original\");\n+          return buffer;\n+        }\n+        const sampleRateRatio = inSampleRate / outSampleRate;\n+        const newLength = Math.round(buffer.length / sampleRateRatio);\n+        const result = new Float32Array(newLength);\n+        let offsetResult = 0;\n+        let offsetBuffer = 0;\n+        while (offsetResult < result.length) {\n+          const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);\n+          let accum = 0, count = 0;\n+          for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {\n+            accum += buffer[i];\n+            count++;\n+          }\n+          result[offsetResult] = count ? accum / count : 0;\n+          offsetResult++;\n+          offsetBuffer = nextOffsetBuffer;\n+        }\n+        return result;\n+      }\n+\n+      async function start() {\n+        startBtn.disabled = true;\n+        stopBtn.disabled = false;\n+        applyBtn.disabled = false;\n+\n+        ws = new WebSocket('ws://127.0.0.1:8765/ws/speech-recognition');\n+        ws.binaryType = 'arraybuffer';\n+        ws.onerror = (e) => {\n+          console.error('WS err', e);\n+        };\n+        ws.onmessage = (evt) => {\n+          try {\n+            const data = JSON.parse(evt.data);\n+            let id = data.id;\n+            if (id != sentenceId) {\n+              sentenceId = id;\n+              sentences.push('');\n+            }\n+            sentences[sentences.length - 1] = data.sentence;\n+            voiceInputResult.innerHTML = sentences.map(v => `<p>${v}</p>`).join('');\n+          } catch (e) {\n+            console.log('Non-JSON message from server:', evt.data);\n+          }\n+        };\n+\n+        stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n+        audioCtx = new window.AudioContext();\n+        source = audioCtx.createMediaStreamSource(stream);\n+\n+        const inputSampleRate = audioCtx.sampleRate;\n+        console.log('input sample rate', inputSampleRate);\n+\n+        const bufferSize = 4096;\n+        processor = audioCtx.createScriptProcessor(bufferSize, 1, 1);\n+\n+        processor.onaudioprocess = (event) => {\n+          const inputBuffer = event.inputBuffer.getChannelData(0);\n+          const downsampled = downsampleBuffer(inputBuffer, inputSampleRate, targetSampleRate);\n+          const pcm16ab = floatTo16BitPCM(downsampled);\n+          if (ws && ws.readyState === WebSocket.OPEN) {\n+            ws.send(pcm16ab);\n+          }\n+        };\n+\n+        source.connect(processor);\n+        processor.connect(audioCtx.destination);\n+\n+        startBtn.disabled = true;\n+        stopBtn.disabled = false;\n+      }\n+\n+      function stop() {\n+        startBtn.disabled = false;\n+        stopBtn.disabled = true;\n+\n+        processor?.disconnect();\n+        source?.disconnect();\n+        audioCtx?.close();\n+        stream?.getTracks().forEach(t => t.stop());\n+        ws?.close();\n+        startBtn.disabled = false;\n+        stopBtn.disabled = true;\n+        sentenceId = -1;\n+      }\n+\n+      function apply() {\n+        stop();\n+        voiceInputModal.remove();\n+\n+        if (!engineRef.current) return;\n+        const lastTextCell = [...engineRef.current.getState().cells].reverse().find(c => c.type === 'text');\n+        if (!lastTextCell) return;\n+        const textarea = textareaRefs.current.get(lastTextCell.id);\n+        if (!textarea) return;\n+\n+        const currentContent = (lastTextCell as TextCell).content;\n+        const newContent = currentContent + sentences.join('');\n+        engineRef.current.updateTextCell(lastTextCell.id, newContent);\n+\n+        // Postpone setting of textarea height\n+        setTimeout(() => {\n+          textarea.style.height = `${textarea.scrollHeight}px`;\n+        }, 100);\n+      }\n+\n+      function cancel() {\n+        stop();\n+        voiceInputModal.remove();\n+      }\n+\n+      startBtn.addEventListener('click', start);\n+      stopBtn.addEventListener('click', stop);\n+      applyBtn.addEventListener('click', apply);\n+      cancelBtn.addEventListener('click', cancel);\n+    \n+    } catch (error) {\n+      console.error('Voice input encountered an unexpected error:', error);\n+      voiceInputModal.remove();\n+    }\n+  }, [isAuthenticated]);\n+\n   const handleLoadEntry = useCallback((entry: CalendarEntry) => {\n     if (!engineRef.current) return;\n \n@@ -2108,6 +2348,7 @@ export default function App() {\n                 onToggleAlign={handleToggleAlign}\n                 onShowCalendar={() => setShowCalendarPopup(true)}\n                 onSaveToday={handleSaveToday}\n+                onStartTalking={handleStartTalking}\n                 isAligned={commentsAligned}\n               />\n             </div>"
  }
]