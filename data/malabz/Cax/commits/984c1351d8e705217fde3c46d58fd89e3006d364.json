{
  "cached_at": "2025-12-20T14:33:28.243687",
  "commit_sha": "984c1351d8e705217fde3c46d58fd89e3006d364",
  "repo": "malabz/Cax",
  "data": {
    "sha": "984c1351d8e705217fde3c46d58fd89e3006d364",
    "node_id": "C_kwDOPt61otoAKDk4NGMxMzUxZDhlNzA1MjE3ZmRlM2M0NmQ1OGZkODllMzAwNmQzNjQ",
    "commit": {
      "author": {
        "name": "LoadStar822",
        "email": "992247533@qq.com",
        "date": "2025-12-14T06:09:36Z"
      },
      "committer": {
        "name": "LoadStar822",
        "email": "992247533@qq.com",
        "date": "2025-12-14T06:09:36Z"
      },
      "message": "0.4.0",
      "tree": {
        "sha": "7cefeda409cd93266215a9513710839d52875a73",
        "url": "https://api.github.com/repos/malabz/Cax/git/trees/7cefeda409cd93266215a9513710839d52875a73"
      },
      "url": "https://api.github.com/repos/malabz/Cax/git/commits/984c1351d8e705217fde3c46d58fd89e3006d364",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null,
        "verified_at": null
      }
    },
    "url": "https://api.github.com/repos/malabz/Cax/commits/984c1351d8e705217fde3c46d58fd89e3006d364",
    "html_url": "https://github.com/malabz/Cax/commit/984c1351d8e705217fde3c46d58fd89e3006d364",
    "comments_url": "https://api.github.com/repos/malabz/Cax/commits/984c1351d8e705217fde3c46d58fd89e3006d364/comments",
    "author": {
      "login": "LoadStar822",
      "id": 56856603,
      "node_id": "MDQ6VXNlcjU2ODU2NjAz",
      "avatar_url": "https://avatars.githubusercontent.com/u/56856603?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/LoadStar822",
      "html_url": "https://github.com/LoadStar822",
      "followers_url": "https://api.github.com/users/LoadStar822/followers",
      "following_url": "https://api.github.com/users/LoadStar822/following{/other_user}",
      "gists_url": "https://api.github.com/users/LoadStar822/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/LoadStar822/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/LoadStar822/subscriptions",
      "organizations_url": "https://api.github.com/users/LoadStar822/orgs",
      "repos_url": "https://api.github.com/users/LoadStar822/repos",
      "events_url": "https://api.github.com/users/LoadStar822/events{/privacy}",
      "received_events_url": "https://api.github.com/users/LoadStar822/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "committer": {
      "login": "LoadStar822",
      "id": 56856603,
      "node_id": "MDQ6VXNlcjU2ODU2NjAz",
      "avatar_url": "https://avatars.githubusercontent.com/u/56856603?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/LoadStar822",
      "html_url": "https://github.com/LoadStar822",
      "followers_url": "https://api.github.com/users/LoadStar822/followers",
      "following_url": "https://api.github.com/users/LoadStar822/following{/other_user}",
      "gists_url": "https://api.github.com/users/LoadStar822/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/LoadStar822/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/LoadStar822/subscriptions",
      "organizations_url": "https://api.github.com/users/LoadStar822/orgs",
      "repos_url": "https://api.github.com/users/LoadStar822/repos",
      "events_url": "https://api.github.com/users/LoadStar822/events{/privacy}",
      "received_events_url": "https://api.github.com/users/LoadStar822/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "044e2806686d7c7acc8b2cd5bef18bd73c05c198",
        "url": "https://api.github.com/repos/malabz/Cax/commits/044e2806686d7c7acc8b2cd5bef18bd73c05c198",
        "html_url": "https://github.com/malabz/Cax/commit/044e2806686d7c7acc8b2cd5bef18bd73c05c198"
      }
    ],
    "stats": {
      "total": 2018,
      "additions": 1950,
      "deletions": 68
    },
    "files": [
      {
        "sha": "e8b4eec1fe72e2fab0b37be88ca94b2e135d4fe9",
        "filename": "CHANGELOG.md",
        "status": "modified",
        "additions": 3,
        "deletions": 2,
        "changes": 5,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/CHANGELOG.md",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/CHANGELOG.md",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/CHANGELOG.md?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -2,11 +2,12 @@\n \n All notable changes to this project will be documented in this file.\n \n-## [0.4.0-dev] - Unreleased\n+## [0.4.0] - 2025-12-14\n \n ### UI\n - Run Settings now has a dual-view toggle (`F6`): switch between the classic plan overview and a new flow view that renders the execution dependency tree as ASCII, so you can see round ordering and ancestry while editing thread/verbose options.\n-- Added an explicit Subtree Mode (`--subtree-mode` flag) toggle: enabling it on a node forces RaMAx for that subtree and automatically disables RaMAx on descendants; switching back to node mode removes the flag. Child-level edits now auto-cancel an ancestor’s subtree mode to avoid conflicts (with safe handling when no Textual app is active).\n+- When an existing `logs/run_state.json` is detected and you keep the output directories, PlanUI opens directly into a dedicated resume view (inside Run Settings) that shows completed/pending steps and the next command to run.\n+- Added an explicit Subtree Mode toggle (CAX-only sentinel, not passed to ramax): enabling it on a node forces RaMAx for that subtree and automatically disables RaMAx on descendants; switching back to node mode removes the sentinel. Child-level edits now auto-cancel an ancestor’s subtree mode to avoid conflicts (with safe handling when no Textual app is active).\n \n ### Fixes\n - Safeguard subtree-mode reversion when no Textual app context exists (tests/CLI), preventing NoActiveAppError during node-level toggles."
      },
      {
        "sha": "9bf10d6831bafafca2d46f4b7420e6f9ebf8dd98",
        "filename": "README.md",
        "status": "modified",
        "additions": 2,
        "deletions": 1,
        "changes": 3,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/README.md",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/README.md",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/README.md?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -1,6 +1,6 @@\n # Cactus-RaMAx\n \n-Cactus-RaMAx helps you remix alignment plans emitted by `cactus-prepare`. You can inspect every round, toggle RaMAx for any subtree, and then run or export the resulting command list. The current development version (`0.4.0-dev`) keeps the ASCII phylogenetic canvas with subtree/single-node toggle scopes, search, proportional branch spacing, and a bottom HUD that summarizes the current node, coverage, and live system metrics. Subtree Mode now adds a `--subtree-mode` flag, disables descendant RaMAx automatically, and gracefully reverts if you later edit a child node.\n+Cactus-RaMAx helps you remix alignment plans emitted by `cactus-prepare`. You can inspect every round, toggle RaMAx for any subtree, and then run or export the resulting command list. The current version (`0.4.0`) keeps the ASCII phylogenetic canvas with subtree/single-node toggle scopes, search, proportional branch spacing, and a bottom HUD that summarizes the current node, coverage, and live system metrics. Subtree Mode is a CAX-only toggle that disables descendant RaMAx automatically and gracefully reverts if you later edit a child node.\n \n ## Environment setup\n \n@@ -35,6 +35,7 @@ cax\n   - Press **F3** (or type `:template`) to choose from Evolver examples bundled with the package or from your own `~/.cax/templates.json`.\n   - Press **F4** or type `!N` (for example `!1`) to recall the Nth entry from `~/.cax/history.json`. The prompt keeps the 20 most recent commands and lets you delete entries from the history window.\n - Before running `cactus-prepare`, CAX infers the effective output directory (from `--outDir` or the parent directory of `--outSeqFile`) and offers to delete existing `--outDir`/`--jobStore` paths so the run starts cleanly.\n+- If `logs/run_state.json` is present and you choose to keep existing outputs, the UI opens directly into a resume view (inside Run Settings) showing which steps can be skipped, which will rerun, and where execution resumes.\n - After execution completes, the UI displays the parsed plan and lets you toggle RaMAx replacements before running or exporting.\n - Scripted usage is still supported:\n   ```bash"
      },
      {
        "sha": "1d0ba9ea182b0f7354f3daf12120744ec5e0c2f8",
        "filename": "VERSION",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/VERSION",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/VERSION",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/VERSION?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -1 +1 @@\n-0.4.0-dev\n+0.4.0"
      },
      {
        "sha": "08abceb737b495f707212acdc941f1bdb22386a3",
        "filename": "cax/cli.py",
        "status": "modified",
        "additions": 48,
        "deletions": 23,
        "changes": 71,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fcli.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fcli.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Fcli.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -11,7 +11,7 @@\n import shutil\n \n from . import command_prompt, history, parser, ui as ui_module\n-from .models import RunSettings\n+from .models import Plan, RunSettings\n from .runner import PlanRunner\n \n app = typer.Typer(help=\"Cactus-RaMAx interactive tools (ui only)\")\n@@ -68,16 +68,18 @@ def ui(\n         executable = prompt_result.executable or executable\n \n     out_dir_preview, job_store_preview = _prepare_plan_preview(executable, prepare_args, from_file)\n-    _ensure_clean_environment(out_dir_preview, job_store_preview)\n+    resume_preselected = _ensure_clean_environment(out_dir_preview, job_store_preview)\n     text = _load_prepare_text(prepare_args, from_file, executable=executable)\n     plan = parser.parse_prepare_script(text)\n-    run_settings = RunSettings(verbose=False, thread_count=threads)\n+    run_settings = RunSettings(verbose=False, thread_count=threads, resume=resume_preselected)\n+\n+    # 若用户在启动时选择保留 run_state，UI 会自动进入续跑专属界面（可查看已完成/待执行并微调后续命令）。\n     result = ui_module.launch(plan, run_settings=run_settings)\n     plan = result.plan\n     run_settings = result.run_settings or run_settings\n     if result.action == \"run\" or run_after:\n         if result.action != \"run\":\n-            run_settings = _prompt_run_settings(run_settings)\n+            run_settings = _prompt_run_settings(run_settings, plan)\n         runner = PlanRunner(plan, run_settings=run_settings)\n         runner.run()\n     else:\n@@ -88,7 +90,7 @@ def ui(\n     app()\n \n \n-def _prompt_run_settings(defaults: RunSettings) -> RunSettings:\n+def _prompt_run_settings(defaults: RunSettings, plan: Plan | None = None) -> RunSettings:\n     \"\"\"Collect run-time settings from the user just before execution.\"\"\"\n \n     typer.echo(\"[cax] Configure run settings before execution:\")\n@@ -97,6 +99,11 @@ def _prompt_run_settings(defaults: RunSettings) -> RunSettings:\n         default=defaults.verbose,\n     )\n \n+    resume = typer.confirm(\n+        \"Enable resume mode (record run state and skip successful steps next time)?\",\n+        default=defaults.resume,\n+    )\n+\n     thread_count = defaults.thread_count\n     while True:\n         default_display = \"\" if thread_count is None else str(thread_count)\n@@ -120,7 +127,9 @@ def _prompt_run_settings(defaults: RunSettings) -> RunSettings:\n         thread_count = value\n         break\n \n-    return RunSettings(verbose=verbose, thread_count=thread_count)\n+    settings = RunSettings(verbose=verbose, thread_count=thread_count, resume=resume)\n+\n+    return settings\n \n \n def _prepare_plan_preview(\n@@ -173,12 +182,17 @@ def _discover_out_dir(tokens: list[str]) -> Optional[Path]:\n     return None\n \n \n-def _ensure_clean_environment(out_dir: Optional[str], job_store: Optional[str]) -> None:\n-    \"\"\"Before running cactus-prepare, optionally clean existing output directories.\"\"\"\n+def _ensure_clean_environment(out_dir: Optional[str], job_store: Optional[str]) -> bool:\n+    \"\"\"Before running cactus-prepare, optionally clean existing output directories.\n+\n+    返回值：True 表示用户选择保留现有目录以便断点续跑；False 表示已清理或无需保留。\n+    \"\"\"\n \n     candidates: list[Path] = []\n+    run_state_path: Optional[Path] = None\n     if out_dir:\n         out_path = _resolve_path(out_dir)\n+        run_state_path = out_path / \"logs\" / \"run_state.json\"\n         candidates.append(out_path)\n     if job_store:\n         job_path = _resolve_path(job_store)\n@@ -195,30 +209,41 @@ def _ensure_clean_environment(out_dir: Optional[str], job_store: Optional[str])\n             existing.append(resolved)\n \n     if not existing:\n-        return\n+        return False\n \n-    typer.echo(\"[cax] Warning: existing directories detected:\")\n+    resume_available = run_state_path is not None and run_state_path.exists()\n+\n+    typer.echo(\"[cax] Detected existing paths:\")\n     for path in existing:\n         try:\n             relative = path.relative_to(Path.cwd())\n             typer.echo(f\"  - {relative}\")\n         except ValueError:\n             typer.echo(f\"  - {path}\")\n \n-    if typer.confirm(\"Delete these directories before running cactus-prepare?\", default=False):\n-        for path in existing:\n-            if not path.exists():\n-                continue\n-            try:\n-                if path.is_dir():\n-                    shutil.rmtree(path)\n-                else:\n-                    path.unlink()\n-            except OSError as exc:\n-                typer.echo(f\"[cax] Failed to remove {path}: {exc}\")\n-        typer.echo(\"[cax] Existing directories removed.\")\n+    if resume_available:\n+        if typer.confirm(\n+            \"Found logs/run_state.json. Keep existing outputs to resume?\",\n+            default=True,\n+        ):\n+            typer.echo(\"[cax] Keeping existing outputs; continuing.\")\n+            return True\n+        typer.echo(\"[cax] Cleaning outputs and restarting.\")\n     else:\n-        typer.echo(\"[cax] Keeping existing directories (may reuse previous outputs).\")\n+        typer.echo(\"[cax] No run_state.json found; cleaning old outputs and jobStore before starting.\")\n+\n+    for path in existing:\n+        if not path.exists():\n+            continue\n+        try:\n+            if path.is_dir():\n+                shutil.rmtree(path)\n+            else:\n+                path.unlink()\n+        except OSError as exc:\n+            typer.echo(f\"[cax] Failed to remove {path}: {exc}\")\n+    typer.echo(\"[cax] Cleanup complete.\")\n+    return False\n \n \n def _resolve_path(path_like: str) -> Path:"
      },
      {
        "sha": "83b68b7bbfc42ec0ec8691549797b29d8ea9bcf6",
        "filename": "cax/detectors.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fdetectors.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fdetectors.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Fdetectors.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -86,7 +86,7 @@ def system_resources() -> dict[str, str]:\n def environment_summary() -> dict[str, Optional[str]]:\n     \"\"\"Return a dictionary summarising key binaries and hardware.\"\"\"\n \n-    ramax = executable_info(\"RaMAx\", [\"--version\"])\n+    ramax = executable_info(\"ramax\", [\"--version\"])\n     cactus_exec = executable_info(\"cactus\", [\"--version\"])\n     # Prefer user-specified commands when deriving the cactus version\n     cactus_version = detect_cactus_version() or (cactus_exec.version)"
      },
      {
        "sha": "9ba30d3190a26035905c6007553210d2fd66727d",
        "filename": "cax/models.py",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fmodels.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fmodels.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Fmodels.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -106,3 +106,4 @@ class RunSettings:\n \n     verbose: bool = False\n     thread_count: Optional[int] = None\n+    resume: bool = False"
      },
      {
        "sha": "e68cac4c0b6b1aad6844143027b2ebfb80dca631",
        "filename": "cax/parser.py",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fparser.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fparser.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Fparser.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -261,6 +261,7 @@ def _classify_kind(first_token: str, default_kind: Optional[str]) -> str:\n         \"cactus-align\": \"align\",\n         \"hal2fasta\": \"hal2fasta\",\n         \"halAppendSubtree\": \"halmerge\",\n+        \"ramax\": \"ramax\",\n         \"RaMAx\": \"ramax\",\n     }\n     kind = mapping.get(first_token)"
      },
      {
        "sha": "44229aa90600a106c9e78d79acb034bc41ba1735",
        "filename": "cax/planner.py",
        "status": "modified",
        "additions": 50,
        "deletions": 5,
        "changes": 55,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fplanner.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fplanner.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Fplanner.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -51,6 +51,9 @@ def build_execution_plan(\n         )\n \n     for round_entry in plan.rounds:\n+        if _is_absorbed_by_subtree_ramax(round_entry, tree):\n+            # Ancestor subtree-mode RaMAx already covers this round; skip all steps here.\n+            continue\n         if _is_descendant_ramax(round_entry, tree):\n             # An ancestor already uses RaMAx; running it again here would be redundant.\n             continue\n@@ -141,6 +144,9 @@ def _from_step(\n     )\n \n \n+SUBTREE_FLAG = \"--subtree-mode\"\n+\n+\n def _ramax_command(\n     plan: Plan,\n     round_entry: Round,\n@@ -155,7 +161,7 @@ def _ramax_command(\n         command = _split_command(round_entry.manual_ramax_command)\n     else:\n         command = [\n-            \"RaMAx\",\n+            \"ramax\",\n             \"-i\",\n             plan.out_seq_file,\n             \"-o\",\n@@ -165,22 +171,31 @@ def _ramax_command(\n         ]\n         if workdir:\n             command.extend([\"-w\", workdir])\n-        command.extend(plan.global_ramax_opts)\n-        command.extend(round_entry.ramax_opts)\n+        command.extend(_filtered_ramax_opts(plan.global_ramax_opts))\n+        command.extend(_filtered_ramax_opts(round_entry.ramax_opts))\n         command = _ensure_ramax_threads(command, thread_count)\n \n     log_path = _guess_ramax_log_path(plan, round_entry, base_dir)\n \n     workdir_path = Path(workdir).expanduser() if workdir else None\n     if workdir_path and not workdir_path.is_absolute():\n         workdir_path = (base_dir / workdir_path).resolve()\n+\n+    # 为 RaMAx 命令补齐 out_files，使断点续跑能检查 HAL 产物是否存在。\n+    ramax_step = Step(\n+        raw=shlex.join(command),\n+        kind=\"ramax\",\n+        out_files=[round_entry.target_hal],\n+        root=round_entry.root,\n+        log_file=str(log_path) if log_path else None,\n+    )\n     return PlannedCommand(\n         command=command,\n         category=\"ramax\",\n-        display_name=f\"RaMAx-{round_entry.root}\",\n+        display_name=f\"ramax-{round_entry.root}\",\n         log_path=log_path,\n         round_name=round_entry.name,\n-        step=None,\n+        step=ramax_step,\n         is_ramax=True,\n         workdir=workdir_path,\n     )\n@@ -265,6 +280,12 @@ def _ensure_cactus_threads(command: List[str], thread_count: Optional[int]) -> L\n     return adjusted\n \n \n+def _filtered_ramax_opts(options: List[str]) -> List[str]:\n+    \"\"\"Drop CAX-only sentinel flags before invoking ramax.\"\"\"\n+\n+    return [opt for opt in options if opt != SUBTREE_FLAG]\n+\n+\n def _ensure_ramax_threads(command: List[str], thread_count: Optional[int]) -> List[str]:\n     if thread_count is None or not command:\n         return command\n@@ -303,6 +324,30 @@ def _is_descendant_ramax(round_entry: Round, tree: Optional[tree_utils.Alignment\n     return False\n \n \n+def _is_absorbed_by_subtree_ramax(\n+    round_entry: Round, tree: Optional[tree_utils.AlignmentTree]\n+) -> bool:\n+    \"\"\"Return True when an ancestor round is in subtree-mode RaMAx, so this round should be skipped entirely.\n+\n+    Subtree Mode represents \"run RaMAx at this ancestor and absorb descendants\". Descendants may have\n+    ``replace_with_ramax`` cleared to avoid mixed modes, but they should not execute their cactus steps\n+    either once the ancestor covers the subtree.\n+    \"\"\"\n+\n+    if tree is None:\n+        return False\n+    node = tree.find(round_entry.root)\n+    if node is None:\n+        return False\n+    ancestor = node.parent\n+    while ancestor:\n+        if ancestor.round and ancestor.round.replace_with_ramax:\n+            if SUBTREE_FLAG in ancestor.round.ramax_opts:\n+                return True\n+        ancestor = ancestor.parent\n+    return False\n+\n+\n def _skip_halmerge_for_ramax_parent(step: Step, tree: Optional[tree_utils.AlignmentTree]) -> bool:\n     \"\"\"Skip halAppendSubtree when its parent round was produced by RaMAx to avoid writing HAL twice.\"\"\"\n "
      },
      {
        "sha": "afc436654c7668099db184be7de7468ca3897f3c",
        "filename": "cax/resume.py",
        "status": "added",
        "additions": 490,
        "deletions": 0,
        "changes": 490,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fresume.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fresume.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Fresume.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -0,0 +1,490 @@\n+\"\"\"断点续跑（resume）相关的共享工具函数。\n+\n+该模块只做“状态解析/预览/匹配”，不直接执行命令，供 runner/CLI/UI 复用。\n+\"\"\"\n+from __future__ import annotations\n+\n+import hashlib\n+import json\n+import gzip\n+import shlex\n+from dataclasses import dataclass\n+from pathlib import Path\n+from typing import Any, Optional\n+\n+from rich.panel import Panel\n+from rich.table import Table\n+\n+from . import planner\n+from .models import Plan\n+\n+\n+STATUS_PENDING = \"Pending\"\n+STATUS_COMPLETED = \"Completed\"\n+STATUS_RERUN = \"Rerun\"\n+\n+\n+@dataclass\n+class ResumePreview:\n+    \"\"\"断点续跑的预览信息，供 CLI/UI 展示。\"\"\"\n+\n+    plan_matches: bool\n+    skipped_indices: set[int]\n+    completed: list[str]\n+    pending: list[str]\n+    failed: list[str]\n+    missing_outputs: list[str]\n+    total: int\n+    state_path: Path\n+\n+\n+@dataclass\n+class CommandRow:\n+    index: int\n+    name: str\n+    status: str\n+    note: str\n+\n+\n+def command_canonical_preview(command: planner.PlannedCommand) -> str:\n+    \"\"\"返回用于断点续跑匹配的“规范化命令”字符串。\n+\n+    目标：允许用户调整线程数或仅修改后续步骤时，已完成步骤仍能被匹配并跳过。\n+    - cactus*: 忽略 `--maxCores`（线程覆盖由 RunSettings 注入，改动不应导致续跑失效）\n+    - ramax: 忽略 `--threads`\n+    \"\"\"\n+\n+    return _canonical_shell_preview(command.command)\n+\n+\n+def command_stable_key(command: planner.PlannedCommand) -> str:\n+    \"\"\"基于 display_name + canonical_preview 的稳定键，用于跨运行匹配。\"\"\"\n+\n+    display = command.display_name or \"\"\n+    canonical = command_canonical_preview(command)\n+    return _stable_key(display, canonical)\n+\n+\n+def index_state_commands(entries: dict[str, Any]) -> dict[str, dict[str, Any]]:\n+    \"\"\"把 run_state.json 中的 commands 索引为 stable_key -> entry。兼容旧格式键名。\"\"\"\n+\n+    indexed: dict[str, dict[str, Any]] = {}\n+    for _key, entry in entries.items():\n+        if not isinstance(entry, dict):\n+            continue\n+        stable = entry.get(\"stable_key\")\n+        if not stable:\n+            display = str(entry.get(\"display_name\") or \"\")\n+            preview = str(entry.get(\"preview\") or \"\")\n+            canonical = str(entry.get(\"canonical_preview\") or _canonical_shell_preview_from_shell(preview))\n+            stable = _stable_key(display, canonical)\n+        indexed[stable] = entry\n+    return indexed\n+\n+\n+def preview_resume(\n+    plan: Plan,\n+    *,\n+    base_dir: Optional[Path] = None,\n+    thread_count: Optional[int] = None,\n+) -> ResumePreview | None:\n+    \"\"\"读取 run_state.json，返回续跑预览；文件缺失或无法解析时返回 None。\"\"\"\n+\n+    base = Path(base_dir) if base_dir else Path.cwd()\n+    commands = planner.build_execution_plan(plan, base, thread_count=thread_count)\n+    log_root = _log_root_for_plan(plan, base)\n+    state_path = log_root / \"run_state.json\"\n+    data = load_run_state_file(state_path)\n+    if not data:\n+        return None\n+\n+    current_sig = plan_signature(commands, base, thread_count)\n+    plan_matches = data.get(\"plan_signature\") == current_sig\n+    entries = index_state_commands(data.get(\"commands\", {}))\n+\n+    skipped_indices = _prefix_skipped_indices(commands, entries, base)\n+    completed: list[str] = []\n+    failed: list[str] = []\n+    missing_outputs: list[str] = []\n+\n+    for idx, cmd in enumerate(commands):\n+        entry = entries.get(command_stable_key(cmd))\n+        outputs_ok = outputs_exist(cmd, base)\n+        if idx in skipped_indices:\n+            completed.append(cmd.display_name)\n+            continue\n+        if not entry:\n+            continue\n+        status = entry.get(\"status\")\n+        if status == \"success\" and not outputs_ok:\n+            missing_outputs.append(cmd.display_name)\n+        elif status == \"failed\":\n+            failed.append(cmd.display_name)\n+\n+    pending = [cmd.display_name for i, cmd in enumerate(commands) if i not in skipped_indices]\n+\n+    return ResumePreview(\n+        plan_matches=plan_matches,\n+        skipped_indices=skipped_indices,\n+        completed=completed,\n+        pending=pending,\n+        failed=failed,\n+        missing_outputs=missing_outputs,\n+        total=len(commands),\n+        state_path=state_path,\n+    )\n+\n+\n+def command_rows(\n+    plan: Plan,\n+    *,\n+    base_dir: Optional[Path] = None,\n+    thread_count: Optional[int] = None,\n+) -> list[CommandRow]:\n+    \"\"\"返回每条命令的状态行，用于 UI 展示。\"\"\"\n+\n+    base = Path(base_dir) if base_dir else Path.cwd()\n+    commands = planner.build_execution_plan(plan, base, thread_count=thread_count)\n+    log_root = _log_root_for_plan(plan, base)\n+    state_path = log_root / \"run_state.json\"\n+    data = load_run_state_file(state_path)\n+    entries = index_state_commands(data.get(\"commands\", {}) if data else {})\n+    skipped_indices = _prefix_skipped_indices(commands, entries, base)\n+\n+    rows: list[CommandRow] = []\n+    for idx, cmd in enumerate(commands):\n+        entry = entries.get(command_stable_key(cmd))\n+        outputs_ok = outputs_exist(cmd, base)\n+        status = STATUS_PENDING\n+        note = \"\"\n+\n+        if idx in skipped_indices:\n+            status = STATUS_COMPLETED\n+            note = \"Will be skipped (succeeded and outputs exist)\"\n+        elif entry:\n+            s = entry.get(\"status\")\n+            status = STATUS_RERUN\n+            if s == \"success\" and outputs_ok:\n+                note = \"Previously succeeded, but an earlier step will rerun\"\n+            elif s == \"success\" and not outputs_ok:\n+                note = \"Outputs missing or inconsistent; will rerun\"\n+            elif s == \"failed\":\n+                note = f\"Failed last run (exit {entry.get('exit_code')}); will rerun\"\n+            elif s == \"running\":\n+                note = \"Interrupted/terminated last run; will rerun\"\n+            else:\n+                note = \"Will rerun\"\n+        elif outputs_ok:\n+            note = \"Outputs exist (no recorded success)\"\n+        rows.append(CommandRow(index=idx, name=cmd.display_name, status=status, note=note))\n+    return rows\n+\n+\n+def render_summary(preview: ResumePreview, sample_limit: int = 3) -> tuple[Table, Panel]:\n+    \"\"\"生成续跑摘要的 Rich 渲染对象。\"\"\"\n+\n+    table = Table(title=\"Resume Summary\", show_header=True, header_style=\"bold magenta\")\n+    table.add_column(\"Category\", style=\"cyan\", no_wrap=True)\n+    table.add_column(\"Count\", justify=\"right\")\n+    table.add_column(\"Examples\", overflow=\"fold\")\n+\n+    table.add_row(\"Skippable (completed)\", str(len(preview.completed)), _sample_items(preview.completed, sample_limit))\n+    table.add_row(STATUS_PENDING, str(len(preview.pending)), _sample_items(preview.pending, sample_limit))\n+    table.add_row(\"Needs rerun (outputs)\", str(len(preview.missing_outputs)), _sample_items(preview.missing_outputs, sample_limit))\n+    table.add_row(\"Failed last run\", str(len(preview.failed)), _sample_items(preview.failed, sample_limit))\n+\n+    panel = Panel(f\"State file: {preview.state_path}\", border_style=\"yellow\")\n+    return table, panel\n+\n+\n+def render_command_table(rows: list[CommandRow], *, limit: int = 200) -> Table:\n+    \"\"\"渲染每条命令的状态表。默认最多展示 200 行，超出会在末尾提示。\"\"\"\n+\n+    table = Table(title=\"Resume Commands (in order)\", show_header=True, header_style=\"bold cyan\")\n+    table.add_column(\"#\", justify=\"right\", no_wrap=True)\n+    table.add_column(\"Status\", style=\"magenta\", no_wrap=True)\n+    table.add_column(\"Command\", overflow=\"fold\")\n+    table.add_column(\"Note\", overflow=\"fold\")\n+\n+    shown = 0\n+    for row in rows:\n+        if shown >= limit:\n+            break\n+        table.add_row(str(row.index), row.status, row.name, row.note)\n+        shown += 1\n+\n+    if len(rows) > shown:\n+        table.caption = f\"... {len(rows) - shown} more not shown\"\n+    return table\n+\n+\n+# ---- shared helpers -----------------------------------------------------\n+\n+def outputs_exist(command: planner.PlannedCommand, base_dir: Path) -> bool:\n+    step = command.step\n+    if step is None or not step.out_files:\n+        return True\n+    resolved: list[Path] = []\n+    for out_file in step.out_files:\n+        path = Path(out_file).expanduser()\n+        if not path.is_absolute():\n+            path = (base_dir / path).resolve()\n+        resolved.append(path)\n+        if not path.exists():\n+            return False\n+    if step.kind == \"blast\":\n+        paf_paths = [p for p in resolved if p.name.endswith(\".paf\")]\n+        if paf_paths and not _blast_paf_matches_seqfile(command, base_dir, paf_paths):\n+            return False\n+    return True\n+\n+\n+def load_run_state_file(path: Path) -> dict[str, Any]:\n+    if not path.exists():\n+        return {}\n+    try:\n+        text = path.read_text(encoding=\"utf-8\")\n+        return json.loads(text)\n+    except (OSError, json.JSONDecodeError):\n+        return {}\n+\n+def plan_signature(\n+    commands: list[planner.PlannedCommand],\n+    base_dir: Path,\n+    thread_count: Optional[int],\n+) -> str:\n+    hasher = hashlib.sha1()\n+    hasher.update(str(base_dir).encode())\n+    hasher.update(str(thread_count or \"\").encode())\n+    for cmd in commands:\n+        hasher.update(cmd.shell_preview().encode())\n+        if cmd.workdir:\n+            hasher.update(str(cmd.workdir).encode())\n+    return hasher.hexdigest()\n+\n+\n+def _stable_key(display_name: str, canonical_preview: str) -> str:\n+    hasher = hashlib.sha1()\n+    hasher.update(display_name.encode())\n+    hasher.update(b\"\\0\")\n+    hasher.update(canonical_preview.encode())\n+    return hasher.hexdigest()\n+\n+\n+def _strip_flag(tokens: list[str], flag: str) -> list[str]:\n+    stripped: list[str] = []\n+    skip_next = False\n+    prefix = flag + \"=\"\n+    for token in tokens:\n+        if skip_next:\n+            skip_next = False\n+            continue\n+        if token == flag:\n+            skip_next = True\n+            continue\n+        if token.startswith(prefix):\n+            continue\n+        stripped.append(token)\n+    return stripped\n+\n+\n+def _strip_switch(tokens: list[str], flag: str) -> list[str]:\n+    \"\"\"移除不带参数的布尔开关（如 `--restart`）。\"\"\"\n+\n+    stripped: list[str] = []\n+    prefix = flag + \"=\"\n+    for token in tokens:\n+        if token == flag:\n+            continue\n+        if token.startswith(prefix):\n+            continue\n+        stripped.append(token)\n+    return stripped\n+\n+\n+def _canonical_shell_preview(tokens: list[str]) -> str:\n+    if not tokens:\n+        return \"\"\n+    name = Path(tokens[0]).name.lower()\n+    canonical_tokens = list(tokens)\n+    if name.startswith(\"cactus\"):\n+        canonical_tokens = _strip_flag(canonical_tokens, \"--maxCores\")\n+        # Toil 的 `--restart` 属于“运行方式”而非产物语义，不应影响续跑匹配。\n+        canonical_tokens = _strip_switch(canonical_tokens, \"--restart\")\n+    if name == \"ramax\":\n+        canonical_tokens = _strip_flag(canonical_tokens, \"--threads\")\n+    return shlex.join(canonical_tokens)\n+\n+\n+def _canonical_shell_preview_from_shell(preview: str) -> str:\n+    if not preview:\n+        return \"\"\n+    try:\n+        tokens = shlex.split(preview)\n+    except ValueError:\n+        return preview\n+    return _canonical_shell_preview(tokens)\n+\n+\n+def _log_root_for_plan(plan: Plan, base_dir: Path) -> Path:\n+    if plan.out_dir:\n+        return _to_path(plan.out_dir, base_dir) / \"logs\"\n+    return (base_dir / \"logs\").resolve()\n+\n+\n+def _to_path(path_like: str, base_dir: Path) -> Path:\n+    path = Path(path_like).expanduser()\n+    if path.is_absolute():\n+        return path\n+    return (base_dir / path).resolve()\n+\n+\n+def _sample_items(items: list[str], limit: int) -> str:\n+    if not items:\n+        return \"(none)\"\n+    head = items[:limit]\n+    remaining = len(items) - len(head)\n+    suffix = f\" (+{remaining} more)\" if remaining > 0 else \"\"\n+    return \", \".join(head) + suffix\n+\n+\n+def _prefix_skipped_indices(\n+    commands: list[planner.PlannedCommand],\n+    entries: dict[str, dict[str, Any]],\n+    base_dir: Path,\n+) -> set[int]:\n+    \"\"\"只跳过“前缀连续已完成步骤”。\n+\n+    计划是顺序执行的，后续步骤往往依赖前置产物；一旦某一步需要重跑，\n+    其后的步骤也必须重新执行，避免出现“上游变更但下游仍被跳过”的不一致。\n+    \"\"\"\n+\n+    skipped: set[int] = set()\n+    for idx, cmd in enumerate(commands):\n+        entry = entries.get(command_stable_key(cmd))\n+        if entry and entry.get(\"status\") == \"success\" and outputs_exist(cmd, base_dir):\n+            skipped.add(idx)\n+            continue\n+        break\n+    return skipped\n+\n+\n+def _blast_paf_matches_seqfile(\n+    command: planner.PlannedCommand,\n+    base_dir: Path,\n+    paf_paths: list[Path],\n+) -> bool:\n+    \"\"\"快速校验 blast 产物 PAF 与当前 seqfile/FASTA 是否一致。\n+\n+    经验问题：Toil jobStore 续跑（--restart）可能复用旧的中间结果，导致生成的 PAF 仍引用旧 FASTA 的 contig 名。\n+    若随后 internal FASTA 已被重跑并改名，align 步骤会出现 “Could not match contig name …”。\n+\n+    这里做一个轻量校验：抽样读取 PAF 前若干行的 qname/tname，检查其 contig 名是否存在于 seqfile 指定的 FASTA 头部。\n+    \"\"\"\n+\n+    cmd_name = Path(command.command[0]).name.lower() if command.command else \"\"\n+    if cmd_name != \"cactus-blast\":\n+        return True\n+    seqfile_path = _seqfile_from_cactus_blast(command, base_dir)\n+    if seqfile_path is None or not seqfile_path.exists():\n+        return True\n+    mapping = _parse_seqfile_mapping(seqfile_path, base_dir)\n+    if not mapping:\n+        return True\n+\n+    for paf_path in paf_paths:\n+        needed = _collect_needed_contigs_from_paf(paf_path, sample_limit=200)\n+        if not needed:\n+            continue\n+        for event, contigs in needed.items():\n+            fasta_path = mapping.get(event)\n+            if fasta_path is None:\n+                return False\n+            if not _fasta_contains_all_contigs(fasta_path, contigs):\n+                return False\n+    return True\n+\n+\n+def _seqfile_from_cactus_blast(command: planner.PlannedCommand, base_dir: Path) -> Path | None:\n+    # cactus-blast <jobstore> <seqfile> <out.paf> ...\n+    if len(command.command) < 3:\n+        return None\n+    token = command.command[2]\n+    path = Path(token).expanduser()\n+    if not path.is_absolute():\n+        path = (base_dir / path).resolve()\n+    return path\n+\n+\n+def _parse_seqfile_mapping(seqfile_path: Path, base_dir: Path) -> dict[str, Path]:\n+    mapping: dict[str, Path] = {}\n+    try:\n+        with seqfile_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as handle:\n+            _ = handle.readline()  # newick line\n+            for line in handle:\n+                stripped = line.strip()\n+                if not stripped or stripped.startswith(\"#\"):\n+                    continue\n+                parts = stripped.split()\n+                if len(parts) < 2:\n+                    continue\n+                name, path_like = parts[0], parts[1]\n+                mapping[name] = _to_path(path_like, base_dir)\n+    except OSError:\n+        return {}\n+    return mapping\n+\n+\n+def _collect_needed_contigs_from_paf(paf_path: Path, *, sample_limit: int) -> dict[str, set[str]]:\n+    needed: dict[str, set[str]] = {}\n+    try:\n+        with paf_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as handle:\n+            seen = 0\n+            for line in handle:\n+                stripped = line.strip()\n+                if not stripped or stripped.startswith(\"#\"):\n+                    continue\n+                fields = stripped.split(\"\\t\")\n+                if len(fields) < 6:\n+                    continue\n+                for name in (fields[0], fields[5]):\n+                    event, contig = _parse_paf_name(name)\n+                    if not event or not contig:\n+                        continue\n+                    needed.setdefault(event, set()).add(contig)\n+                seen += 1\n+                if seen >= sample_limit:\n+                    break\n+    except OSError:\n+        return {}\n+    return needed\n+\n+\n+def _parse_paf_name(name: str) -> tuple[str | None, str | None]:\n+    value = name.strip()\n+    if value.startswith(\"id=\"):\n+        value = value[len(\"id=\") :]\n+    if \"|\" not in value:\n+        return None, None\n+    event, contig = value.split(\"|\", 1)\n+    return (event or None), (contig or None)\n+\n+\n+def _fasta_contains_all_contigs(path: Path, contigs: set[str]) -> bool:\n+    remaining = set(contigs)\n+    if not remaining:\n+        return True\n+    try:\n+        opener = gzip.open if path.name.endswith(\".gz\") else open\n+        with opener(path, \"rt\", encoding=\"utf-8\", errors=\"replace\") as handle:\n+            for line in handle:\n+                if not line.startswith(\">\"):\n+                    continue\n+                header = line[1:].strip().split()[0]\n+                if header in remaining:\n+                    remaining.remove(header)\n+                    if not remaining:\n+                        return True\n+    except OSError:\n+        return False\n+    return False"
      },
      {
        "sha": "0731847d8a9ae00b9566746c09ebb20675a341f8",
        "filename": "cax/runner.py",
        "status": "modified",
        "additions": 275,
        "deletions": 10,
        "changes": 285,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Frunner.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Frunner.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Frunner.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -1,13 +1,16 @@\n \"\"\"Execution engine for running CAX plans.\"\"\"\n from __future__ import annotations\n \n+import errno\n+import json\n import os\n+import shutil\n from contextlib import nullcontext\n from pathlib import Path\n import subprocess\n import threading\n import time\n-from typing import Optional\n+from typing import Any, Optional\n \n import psutil\n from rich.console import Console\n@@ -16,6 +19,14 @@\n \n from . import planner\n from .models import Plan, RunSettings\n+from .resume import (\n+    command_canonical_preview,\n+    command_stable_key,\n+    index_state_commands,\n+    load_run_state_file,\n+    outputs_exist,\n+    plan_signature,\n+)\n \n \n IMPORTANT_KEYWORDS = (\"error\", \"failed\", \"exception\", \"critical\")\n@@ -44,6 +55,7 @@ def __init__(\n         self.run_settings = run_settings or RunSettings()\n         self.verbose = self.run_settings.verbose\n         self.thread_count = self.run_settings.thread_count\n+        self.run_state_path = self.log_root / \"run_state.json\"\n \n     def run(self, dry_run: Optional[bool] = None) -> None:\n         \"\"\"Execute the plan. When ``dry_run`` is True, commands are only logged.\"\"\"\n@@ -55,10 +67,29 @@ def run(self, dry_run: Optional[bool] = None) -> None:\n             thread_count=self.thread_count,\n         )\n         self.log_root.mkdir(parents=True, exist_ok=True)\n+        state = _RunState(self.run_state_path, planned_commands, self.base_dir, self.thread_count)\n         total_commands = len(planned_commands)\n         completed_commands = 0\n         failure_command: planner.PlannedCommand | None = None\n \n+        skip_enabled = self.run_settings.resume\n+        skipped_indices: set[int] = set()\n+        resume_start_index: int | None = None\n+        if skip_enabled:\n+            if state.mismatched and self.mirror_stdout:\n+                self.console.print(\n+                    \"[yellow][resume][/yellow] Found run_state.json, but the plan signature differs; will attempt command-matching resume.\"\n+                )\n+            skipped_indices = state.compute_skips(planned_commands, self.base_dir)\n+            if skipped_indices and self.mirror_stdout:\n+                self.console.print(\n+                    f\"[yellow][resume][/yellow] Skipping {len(skipped_indices)} successful steps (run_state.json detected).\"\n+                )\n+            for idx in range(len(planned_commands)):\n+                if idx not in skipped_indices:\n+                    resume_start_index = idx\n+                    break\n+\n         progress_cm = (\n             Progress(\n                 SpinnerColumn(),\n@@ -91,7 +122,28 @@ def run(self, dry_run: Optional[bool] = None) -> None:\n                         mem=\"--\",\n                         mem_peak=\"--\",\n                     )\n-                for command in planned_commands:\n+                for command_index, command in enumerate(planned_commands):\n+                    cmd_id = state.command_key(command, command_index)\n+                    if command_index in skipped_indices:\n+                        state.mark_skipped(cmd_id, command, command_index)\n+                        master_log.write(f\"[resume] skip {command.display_name}: {command.shell_preview()}\\n\")\n+                        master_log.flush()\n+                        if progress is not None and overall_task is not None:\n+                            remaining -= 1\n+                            progress.advance(overall_task)\n+                            progress.update(\n+                                overall_task,\n+                                description=f\"[yellow]⏭ {command.display_name} (resume)[/yellow]\",\n+                                remaining=remaining,\n+                            )\n+                        elif self.mirror_stdout:\n+                            self.console.print(f\"[yellow][resume][/yellow] Skipping {command.display_name}\")\n+                        completed_commands += 1\n+                        continue\n+                    entry = state.state[\"commands\"].get(cmd_id)\n+                    if skip_enabled:\n+                        allow_restart = resume_start_index is not None and command_index == resume_start_index\n+                        self._prepare_toil_jobstore(command, entry, allow_restart=allow_restart)\n                     preview = command.shell_preview()\n                     task_id: TaskID | None = None\n                     if isinstance(progress, Progress):\n@@ -105,14 +157,16 @@ def run(self, dry_run: Optional[bool] = None) -> None:\n                         )\n                         self._announce_command(preview, progress)\n                         task_id = overall_task\n-                    success = self._run_single(\n+                    state.mark_running(cmd_id, command, command_index)\n+                    success, exit_code = self._run_single(\n                         command,\n                         master_log,\n                         effective_dry,\n                         progress if isinstance(progress, Progress) else None,\n                         task_id,\n                         preview,\n                     )\n+                    state.mark_result(cmd_id, command, command_index, success, exit_code)\n                     if not success:\n                         if isinstance(progress, Progress):\n                             progress.update(\n@@ -156,7 +210,7 @@ def _run_single(\n         progress: Optional[Progress],\n         task_id,\n         preview: Optional[str] = None,\n-    ) -> bool:\n+    ) -> tuple[bool, int]:\n         start_time = time.time()\n         preview = preview or command.shell_preview()\n         master_log.write(f\"[start] {command.display_name}: {preview}\\n\")\n@@ -177,7 +231,7 @@ def _run_single(\n                 )\n             elif self.mirror_stdout:\n                 self.console.print(f\"[yellow][skip][/yellow] {command.display_name} (dry-run {elapsed:.1f}s)\")\n-            return True\n+            return True, 0\n \n         if command.workdir:\n             command.workdir.mkdir(parents=True, exist_ok=True)\n@@ -242,7 +296,7 @@ def _run_single(\n                     )\n                 elif self.mirror_stdout:\n                     self.console.print(f\"[red][end][/red] {command.display_name} -> {return_code} ({duration:.1f}s)\")\n-                return False\n+                return False, return_code\n \n             if progress is not None and task_id is not None:\n                 progress.update(\n@@ -252,7 +306,7 @@ def _run_single(\n                 )\n             elif self.mirror_stdout:\n                 self.console.print(f\"[green][end][/green] {command.display_name} ({duration:.1f}s)\")\n-            return True\n+            return True, return_code\n \n     def _log_dry_run(self, command: planner.PlannedCommand, preview: str) -> None:\n         if command.log_path:\n@@ -280,8 +334,13 @@ def _handle_launch_failure(\n         progress: Optional[Progress],\n         task_id,\n         preview: str,\n-    ) -> bool:\n-        message = f\"[error] Failed to launch {command.display_name}: {exc}\\n\"\n+    ) -> tuple[bool, int]:\n+        hint = \"\"\n+        if exc.errno == errno.EACCES:\n+            resolved = _resolve_executable(command.command[0], self.env.get(\"PATH\"))\n+            if resolved and not os.access(resolved, os.X_OK):\n+                hint = f\" (missing execute bit: {resolved})\"\n+        message = f\"[error] Failed to launch {command.display_name}: {exc}{hint}\\n\"\n         step_log.write(message)\n         master_log.write(message)\n         master_log.flush()\n@@ -293,7 +352,7 @@ def _handle_launch_failure(\n             )\n         elif self.mirror_stdout:\n             self.console.print(f\"[red]{message.rstrip()}[/red]\")\n-        return False\n+        return False, -1\n \n     def _emit_important(self, line: str, progress: Optional[Progress]) -> None:\n         text = line.rstrip()\n@@ -333,6 +392,181 @@ def _derive_log_root(self) -> Path:\n             return _to_path(self.plan.out_dir, self.base_dir) / \"logs\"\n         return (self.base_dir / \"logs\").resolve()\n \n+    def _prepare_toil_jobstore(\n+        self,\n+        command: planner.PlannedCommand,\n+        entry: Optional[dict[str, Any]],\n+        *,\n+        allow_restart: bool,\n+    ) -> None:\n+        \"\"\"在断点续跑场景下处理 Toil jobStore 冲突。\n+\n+        Cactus 的多数步骤使用 Toil；当 jobStore 目录已存在时：\n+        - 若上次该步骤处于 running/failed，则追加 `--restart` 以继续执行；\n+        - 否则（例如：断点回退导致本次需要重跑），清理该 jobStore 以便从头运行，避免复用旧依赖。\n+        \"\"\"\n+\n+        step = command.step\n+        if step is None or not step.jobstore:\n+            return\n+\n+        jobstore_path = _resolve_jobstore_path(step.jobstore, self.base_dir)\n+        if not jobstore_path.exists():\n+            return\n+\n+        status = entry.get(\"status\") if entry else None\n+        if status in {\"running\", \"failed\"} and not allow_restart:\n+            if self.mirror_stdout:\n+                self.console.print(\n+                    f\"[yellow][resume][/yellow] To avoid reusing stale Toil jobStore state, cleaning and rerunning: {jobstore_path}\"\n+                )\n+            try:\n+                if jobstore_path.is_dir():\n+                    shutil.rmtree(jobstore_path)\n+                else:\n+                    jobstore_path.unlink()\n+            except OSError as exc:\n+                if self.mirror_stdout:\n+                    self.console.print(f\"[yellow][resume][/yellow] Failed to clean jobStore (will still try to run): {exc}\")\n+            return\n+\n+        if status in {\"running\", \"failed\"} and allow_restart:\n+            root_marker = jobstore_path / \"files\" / \"shared\" / \"rootJobStoreID\"\n+            if not root_marker.exists():\n+                if self.mirror_stdout:\n+                    self.console.print(\n+                        f\"[yellow][resume][/yellow] Detected incomplete Toil jobStore (missing rootJobStoreID); cleaning and rerunning: {jobstore_path}\"\n+                    )\n+                try:\n+                    if jobstore_path.is_dir():\n+                        shutil.rmtree(jobstore_path)\n+                    else:\n+                        jobstore_path.unlink()\n+                except OSError as exc:\n+                    if self.mirror_stdout:\n+                        self.console.print(f\"[yellow][resume][/yellow] Failed to clean jobStore (will still try to run): {exc}\")\n+                return\n+            if \"--restart\" not in command.command:\n+                command.command = [*command.command, \"--restart\"]\n+            if self.mirror_stdout:\n+                self.console.print(\n+                    f\"[yellow][resume][/yellow] Detected existing Toil jobStore; adding --restart for this step: {jobstore_path}\"\n+                )\n+            return\n+\n+        if self.mirror_stdout:\n+            self.console.print(f\"[yellow][resume][/yellow] Cleaning Toil jobStore for rerun: {jobstore_path}\")\n+        try:\n+            if jobstore_path.is_dir():\n+                shutil.rmtree(jobstore_path)\n+            else:\n+                jobstore_path.unlink()\n+        except OSError as exc:\n+            if self.mirror_stdout:\n+                self.console.print(f\"[yellow][resume][/yellow] Failed to clean jobStore (will still try to run): {exc}\")\n+\n+\n+class _RunState:\n+    \"\"\"轻量级运行状态记录，用于断点续跑。\"\"\"\n+\n+    def __init__(\n+        self,\n+        path: Path,\n+        commands: list[planner.PlannedCommand],\n+        base_dir: Path,\n+        thread_count: Optional[int],\n+    ) -> None:\n+        self.path = path\n+        self.plan_signature = plan_signature(commands, base_dir, thread_count)\n+        self.state: dict[str, Any] = {\"plan_signature\": self.plan_signature, \"commands\": {}}\n+        self.mismatched = False\n+        loaded = self._load()\n+        loaded_sig = loaded.get(\"plan_signature\") if loaded else None\n+        if loaded and loaded_sig and loaded_sig != self.plan_signature:\n+            self.mismatched = True\n+        if loaded:\n+            self.state[\"commands\"] = index_state_commands(loaded.get(\"commands\", {}))\n+        self._write()\n+\n+    def compute_skips(self, commands: list[planner.PlannedCommand], base_dir: Path) -> set[int]:\n+        # 续跑策略：只跳过“前缀连续已完成步骤”，一旦某一步需要重跑，则其后的步骤都视为待执行。\n+        #\n+        # 原因：计划是顺序执行的，后续步骤通常依赖前面步骤产物；若从中间重跑但仍跳过后续，\n+        # 会导致产物与依赖不一致（例如上游 HAL 改变但下游 hal2fasta 仍被跳过）。\n+        skips: set[int] = set()\n+        for idx, command in enumerate(commands):\n+            cmd_id = self.command_key(command, idx)\n+            entry = self.state[\"commands\"].get(cmd_id)\n+            if entry and entry.get(\"status\") == \"success\" and outputs_exist(command, base_dir):\n+                skips.add(idx)\n+                continue\n+            break\n+        return skips\n+\n+    def command_key(self, command: planner.PlannedCommand, index: int) -> str:\n+        _ = index\n+        return command_stable_key(command)\n+\n+    def mark_running(self, cmd_id: str, command: planner.PlannedCommand, index: int) -> None:\n+        self.state[\"commands\"][cmd_id] = {\n+            \"index\": index,\n+            \"display_name\": command.display_name,\n+            \"preview\": command.shell_preview(),\n+            \"canonical_preview\": command_canonical_preview(command),\n+            \"stable_key\": cmd_id,\n+            \"log_path\": str(command.log_path) if command.log_path else None,\n+            \"status\": \"running\",\n+            \"updated_at\": _now_iso(),\n+        }\n+        self._write()\n+\n+    def mark_result(\n+        self,\n+        cmd_id: str,\n+        command: planner.PlannedCommand,\n+        index: int,\n+        success: bool,\n+        exit_code: int,\n+    ) -> None:\n+        self.state[\"commands\"][cmd_id] = {\n+            \"index\": index,\n+            \"display_name\": command.display_name,\n+            \"preview\": command.shell_preview(),\n+            \"canonical_preview\": command_canonical_preview(command),\n+            \"stable_key\": cmd_id,\n+            \"log_path\": str(command.log_path) if command.log_path else None,\n+            \"status\": \"success\" if success else \"failed\",\n+            \"exit_code\": exit_code,\n+            \"updated_at\": _now_iso(),\n+        }\n+        self._write()\n+\n+    def mark_skipped(self, cmd_id: str, command: planner.PlannedCommand, index: int) -> None:\n+        existing = self.state[\"commands\"].get(cmd_id, {})\n+        status = existing.get(\"status\", \"success\")\n+        self.state[\"commands\"][cmd_id] = {\n+            \"index\": index,\n+            \"display_name\": command.display_name,\n+            \"preview\": command.shell_preview(),\n+            \"canonical_preview\": command_canonical_preview(command),\n+            \"stable_key\": cmd_id,\n+            \"log_path\": str(command.log_path) if command.log_path else None,\n+            \"status\": status,\n+            \"exit_code\": existing.get(\"exit_code\"),\n+            \"updated_at\": _now_iso(),\n+            \"skipped\": True,\n+        }\n+        self._write()\n+\n+    def _load(self) -> dict[str, Any]:\n+        return load_run_state_file(self.path)\n+\n+    def _write(self) -> None:\n+        self.path.parent.mkdir(parents=True, exist_ok=True)\n+        tmp_path = self.path.with_suffix(\".tmp\")\n+        tmp_path.write_text(json.dumps(self.state, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n+        tmp_path.replace(self.path)\n+\n \n def _format_duration(seconds: float) -> str:\n     if seconds < 0:\n@@ -346,6 +580,10 @@ def _format_duration(seconds: float) -> str:\n     return f\"{minutes}m{sec:02d}s\"\n \n \n+def _now_iso() -> str:\n+    return time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n+\n+\n def _format_bytes(value: int) -> str:\n     if value <= 0:\n         return \"0B\"\n@@ -358,6 +596,24 @@ def _format_bytes(value: int) -> str:\n     return f\"{num:.1f}TB\"\n \n \n+def _resolve_executable(binary: str, path_env: Optional[str]) -> Optional[Path]:\n+    \"\"\"Return the first PATH entry containing *binary* (even if non-executable).\"\"\"\n+\n+    if os.path.isabs(binary):\n+        candidate = Path(binary)\n+        return candidate if candidate.exists() else None\n+\n+    if not path_env:\n+        path_env = os.environ.get(\"PATH\", \"\")\n+    for entry in path_env.split(os.pathsep):\n+        if not entry:\n+            continue\n+        candidate = Path(entry) / binary\n+        if candidate.exists():\n+            return candidate\n+    return None\n+\n+\n def _format_cpu(value: Optional[float]) -> str:\n     if value is None or value < 0:\n         return \"--\"\n@@ -471,3 +727,12 @@ def _to_path(path_like: str, base_dir: Path) -> Path:\n     if path.is_absolute():\n         return path\n     return (base_dir / path).resolve()\n+\n+\n+def _resolve_jobstore_path(jobstore: str, base_dir: Path) -> Path:\n+    \"\"\"解析 Toil jobStore 路径（兼容 `file:` 前缀）。\"\"\"\n+\n+    value = jobstore\n+    if value.startswith(\"file:\"):\n+        value = value.split(\":\", 1)[1]\n+    return _to_path(value, base_dir)"
      },
      {
        "sha": "8bb92f825ecea60ebc02a12ba708955d15cbd749",
        "filename": "cax/tree_utils.py",
        "status": "modified",
        "additions": 78,
        "deletions": 5,
        "changes": 83,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Ftree_utils.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Ftree_utils.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Ftree_utils.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -76,7 +76,7 @@ def build_alignment_tree(plan: Plan, base_dir: Optional[Path] = None) -> Optiona\n     a valid Newick tree definition.\n     \"\"\"\n \n-    newick = _read_newick(plan.out_seq_file, base_dir=base_dir)\n+    newick = _read_newick(plan, base_dir=base_dir)\n     if not newick:\n         return None\n     parser = _NewickParser(newick)\n@@ -86,13 +86,55 @@ def build_alignment_tree(plan: Plan, base_dir: Optional[Path] = None) -> Optiona\n         return None\n     round_map = {round_entry.root: round_entry for round_entry in plan.rounds}\n     _attach_rounds(root, round_map)\n+    _attach_orphans_to_root(root, round_map)\n     return AlignmentTree(root)\n \n \n-def _read_newick(out_seq_file: str, base_dir: Optional[Path]) -> str | None:\n-    path = Path(out_seq_file).expanduser()\n-    if not path.is_absolute() and base_dir is not None:\n-        path = (Path(base_dir) / path).expanduser().resolve()\n+def _read_newick(plan: Plan, base_dir: Optional[Path]) -> str | None:\n+    \"\"\"Return the Newick string for *plan*.\n+\n+    Preferred source: ``plan.out_seq_file``. If missing, fall back to the input\n+    file path found in the first cactus-preprocess step.\n+    \"\"\"\n+\n+    # Primary: out_seq_file\n+    path = _resolve_path(plan.out_seq_file, base_dir)\n+    newick = _read_first_nonempty_line(path)\n+    if newick:\n+        return newick\n+\n+    # Fallback: try to infer input file from preprocess step\n+    for step in plan.preprocess:\n+        tokens = step.raw.split()\n+        candidates = _candidate_paths_from_tokens(tokens, base_dir)\n+        for candidate in candidates:\n+            newick = _read_first_nonempty_line(candidate)\n+            if newick:\n+                return newick\n+        break  # only need first preprocess step\n+    return None\n+\n+\n+def _candidate_paths_from_tokens(tokens: list[str], base_dir: Optional[Path]) -> list[Path]:\n+    paths: list[Path] = []\n+    for tok in tokens:\n+        if tok.startswith(\"-\"):\n+            continue\n+        candidate = _resolve_path(tok, base_dir)\n+        if candidate.exists() and candidate.is_file():\n+            paths.append(candidate)\n+    return paths\n+\n+\n+def _resolve_path(path_like: str, base_dir: Optional[Path]) -> Path:\n+    path = Path(path_like).expanduser()\n+    if path.is_absolute():\n+        return path\n+    base = Path(base_dir) if base_dir else Path.cwd()\n+    return (base / path).resolve()\n+\n+\n+def _read_first_nonempty_line(path: Path) -> str | None:\n     if not path.exists():\n         return None\n     try:\n@@ -114,6 +156,37 @@ def _attach_rounds(node: AlignmentNode, round_map: dict[str, Round]) -> None:\n         _attach_rounds(child, round_map)\n \n \n+def _attach_orphans_to_root(root: AlignmentNode, round_map: dict[str, Round]) -> None:\n+    \"\"\"Attach a single unmatched round to an unnamed root so it can be toggled in the UI.\n+\n+    Some cactus-prepare outputs leave the outermost Newick node unnamed, while the last\n+    round (e.g. Anc0) targets that implied root. If exactly one round remains unattached\n+    and the parsed root currently lacks a round, bind it there to keep ancestor/descendant\n+    logic intact.\n+    \"\"\"\n+\n+    attached_roots: set[str] = set()\n+\n+    def _collect(node: AlignmentNode) -> None:\n+        if node.round:\n+            attached_roots.add(node.round.root)\n+        for child in node.children:\n+            _collect(child)\n+\n+    _collect(root)\n+    unmatched = [rnd for rnd in round_map.values() if rnd.root not in attached_roots]\n+    if len(unmatched) == 1 and root.round is None and (not root.name):\n+        root.round = unmatched.pop()\n+\n+    if unmatched:\n+        existing_names = {child.name for child in root.children if child.name}\n+        for rnd in unmatched:\n+            if rnd.root in existing_names:\n+                continue\n+            child = AlignmentNode(name=rnd.root, children=[], round=rnd, parent=root)\n+            root.children.append(child)\n+\n+\n class _NewickParser:\n     \"\"\"Minimal recursive-descent parser for Newick tree strings.\"\"\"\n "
      },
      {
        "sha": "66165d9e80655583426cc902e438e1468626098a",
        "filename": "cax/ui.py",
        "status": "modified",
        "additions": 155,
        "deletions": 19,
        "changes": 174,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fui.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/cax%2Fui.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/cax%2Fui.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -26,11 +26,39 @@\n from rich.align import Align\n from rich.console import Group\n \n-from . import planner, tree_utils\n+from . import planner, resume as resume_utils, tree_utils\n from .models import Plan, Round, RunSettings, Step\n from .planner import PlannedCommand\n \n \n+SUBTREE_MODE_FLAG = \"--subtree-mode\"\n+\n+\n+def _is_subtree_mode_round(round_entry: Round) -> bool:\n+    return round_entry.replace_with_ramax and SUBTREE_MODE_FLAG in round_entry.ramax_opts\n+\n+\n+def _is_effective_ramax_node(node: tree_utils.AlignmentNode) -> bool:\n+    \"\"\"判断节点在执行层面是否等价于 RaMAx。\n+\n+    说明：\n+    - `replace_with_ramax=True` 的 round 当然是 RaMAx。\n+    - 若任一祖先 round 处于 Subtree Mode（`--subtree-mode`），其子树内的 round 虽然会被标记成 Cactus\n+      以避免混合状态，但执行时会被祖先 RaMAx 吸收，因此 UI 需要按“有效模式”展示为 RaMAx。\n+    \"\"\"\n+\n+    if not node.round:\n+        return False\n+    if node.round.replace_with_ramax:\n+        return True\n+    current = getattr(node, \"parent\", None)\n+    while current:\n+        if current.round and _is_subtree_mode_round(current.round):\n+            return True\n+        current = getattr(current, \"parent\", None)\n+    return False\n+\n+\n @dataclass\n class UIResult:\n     plan: Plan\n@@ -526,7 +554,7 @@ def _toggle_subtree(self) -> None:\n         \"\"\"\n         Toggle Subtree Mode (Mode B):\n         - Enable RaMAx for this node.\n-        - Add '--subtree-mode' flag.\n+        - 标记内部“subtree-mode”（仅用于 CAX 控制，不会传给 ramax）。\n         - Disable RaMAx for all descendant nodes (as they are subsumed).\n         \"\"\"\n         if not self._cursor.round:\n@@ -901,13 +929,25 @@ def _rebuild_visual(self) -> None:\n         if highlight_subtree and self._cursor:\n             highlighted_nodes = self._collect_subtree_nodes(self._cursor)\n \n+        # 计算每个节点“执行层面”的有效 RaMAx 状态：当祖先处于 Subtree Mode 时，后代 round 也视为 RaMAx。\n+        effective_ramax: dict[tree_utils.AlignmentNode, bool] = {}\n+\n+        def propagate_effective(node: tree_utils.AlignmentNode, covered: bool) -> None:\n+            node_effective = bool(node.round and (node.round.replace_with_ramax or covered))\n+            effective_ramax[node] = node_effective\n+            subtree_cover = covered or bool(node.round and _is_subtree_mode_round(node.round))\n+            for child in self._ordered_children.get(node, node.children):\n+                propagate_effective(child, subtree_cover)\n+\n+        propagate_effective(self._root, False)\n+\n         def label_for(node: tree_utils.AlignmentNode) -> str:\n             \"\"\"Return the full label text without truncation.\"\"\"\n             name = node.name or \"(unnamed)\"\n             parts = [name]\n             if node.round:\n                 # Keep round state only; no extra leaf marker.\n-                tag = \"[RaMAx]\" if node.round.replace_with_ramax else \"[Cactus]\"\n+                tag = \"[RaMAx]\" if effective_ramax.get(node, False) else \"[Cactus]\"\n                 parts.append(tag)\n             return \" \".join(parts)\n \n@@ -938,7 +978,7 @@ def walk(node: tree_utils.AlignmentNode, prefix: str, is_last: bool, depth: int)\n             indicator_char = \"│\" # Default\n             indicator_style = \"#6272a4\" \n \n-            if node.round and node.round.replace_with_ramax:\n+            if node.round and effective_ramax.get(node, False):\n                 indicator_char = \"❚\" # Golden bar\n                 indicator_style = \"#fcbf49\"\n \n@@ -959,7 +999,7 @@ def walk(node: tree_utils.AlignmentNode, prefix: str, is_last: bool, depth: int)\n                 display_text_object.append(f\"【 {icon}{label_text} 】\", style=\"bold #1e1e2e on #bd93f9\")\n             \n             # --- Scheme A: RaMAx State ---\n-            elif node.round and node.round.replace_with_ramax:\n+            elif node.round and effective_ramax.get(node, False):\n                 display_text_object.append(f\"{icon}{label_text}\", style=\"bold #1e1e2e on #fcbf49\")\n             \n             # --- Scheme A: Subtree Scope Highlight ---\n@@ -1161,9 +1201,20 @@ def _info_block(self, label: str, body: RenderableType, *, accent: str = \"white\"\n     def _subtree_stats(self, node: tree_utils.AlignmentNode) -> dict[str, object]:\n         rounds = list(node.iter_rounds())\n         total_rounds = len(rounds)\n-        ramax_rounds = sum(1 for r in rounds if r.replace_with_ramax)\n         hal2fasta = sum(len(r.hal2fasta_steps) for r in rounds)\n \n+        # 子树模式（Subtree Mode）下，后代 round 会被标记成 Cactus 以避免混合状态，但执行上会被祖先 RaMAx 吸收；\n+        # 这里统计覆盖率时应使用“有效 RaMAx”口径，否则用户看到的覆盖率会与实际执行计划不一致。\n+        ramax_rounds = 0\n+        stack: list[tuple[tree_utils.AlignmentNode, bool]] = [(node, False)]\n+        while stack:\n+            current, covered = stack.pop()\n+            if current.round and (current.round.replace_with_ramax or covered):\n+                ramax_rounds += 1\n+            subtree_cover = covered or bool(current.round and _is_subtree_mode_round(current.round))\n+            for child in current.children:\n+                stack.append((child, subtree_cover))\n+\n         def _depth(n: tree_utils.AlignmentNode) -> int:\n             if not n.children:\n                 return 1\n@@ -1194,7 +1245,7 @@ def _leaves(n: tree_utils.AlignmentNode) -> int:\n     def _render_dashboard(self, node: tree_utils.AlignmentNode) -> Table:\n         # Mode and theme color\n         if node.round:\n-            if node.round.replace_with_ramax:\n+            if _is_effective_ramax_node(node):\n                 mode_icon = \"⚡\"\n                 mode_name = \"RaMAx Accelerated\"\n                 theme_color = \"yellow\"\n@@ -1573,16 +1624,23 @@ class RunSettingsScreen(Screen[RunSettings | None]):\n     }\n     \"\"\"\n \n-    def __init__(self, plan: Plan, current: RunSettings, compact: bool):\n+    def __init__(\n+        self,\n+        plan: Plan,\n+        current: RunSettings,\n+        compact: bool,\n+        resume_available: bool = False,\n+    ):\n         super().__init__()\n         self.plan = plan\n         self.current = current\n         self.compact = compact\n+        self.resume_available = resume_available\n         self._summary: Static | None = None\n         self._input: Input | None = None\n         self._verbose: Checkbox | None = None\n         self._status: Static | None = None\n-        self._view_mode: str = \"flow\"  # flow | table\n+        self._view_mode: str = \"resume\" if (resume_available and current.resume) else \"flow\"  # resume | flow | table\n \n     def compose(self) -> ComposeResult:\n         yield Header()\n@@ -1594,7 +1652,7 @@ def compose(self) -> ComposeResult:\n                 summary.update(self._render_summary(self.current))\n                 yield summary\n                 with Container(id=\"run-form\"):\n-                    yield Static(\"• Tab/Shift+Tab to move between controls\\n• Ctrl+Enter to run immediately\\n• V toggles verbose logging\\n• F6 toggles table/flow view\", id=\"run-instructions\")\n+                    yield Static(\"• Tab/Shift+Tab to move between controls\\n• Ctrl+Enter to run immediately\\n• V toggles verbose logging\\n• F6 toggles overview view\", id=\"run-instructions\")\n                     verbose_box = Checkbox(\n                         \"Verbose logging (stream every command output)\",\n                         value=self.current.verbose,\n@@ -1647,8 +1705,10 @@ def action_save(self) -> None:\n             self._update_status(error)\n             return\n         self._update_status(\"\")\n-        verbose = self._verbose.value if self._verbose else False\n-        self.dismiss(RunSettings(verbose=verbose, thread_count=threads))\n+        settings = self._current_settings_preview()\n+        # 替换线程数为已校验的值，避免在预览中使用旧值\n+        settings.thread_count = threads\n+        self.dismiss(settings)\n \n     def action_cancel(self) -> None:\n         self.dismiss(None)\n@@ -1659,8 +1719,16 @@ def action_toggle_verbose(self) -> None:\n             self._refresh_summary()\n \n     def action_toggle_view(self) -> None:\n-        # 切换左侧总览的呈现方式（表格/流程图）\n-        self._view_mode = \"table\" if self._view_mode == \"flow\" else \"flow\"\n+        # 切换左侧总览的呈现方式：有续跑状态时支持 resume/flow/table 三态，否则保持 flow/table 二态。\n+        if self.resume_available:\n+            modes = (\"resume\", \"flow\", \"table\")\n+            try:\n+                idx = modes.index(self._view_mode)\n+            except ValueError:\n+                idx = 0\n+            self._view_mode = modes[(idx + 1) % len(modes)]\n+        else:\n+            self._view_mode = \"table\" if self._view_mode == \"flow\" else \"flow\"\n         self._refresh_summary()\n \n     def on_input_submitted(self, event: Input.Submitted) -> None:\n@@ -1700,7 +1768,7 @@ def _current_settings_preview(self) -> RunSettings:\n         verbose = self._verbose.value if self._verbose else self.current.verbose\n         ok, threads, _ = self._validate_threads()\n         thread_val = threads if ok else self.current.thread_count\n-        return RunSettings(verbose=verbose, thread_count=thread_val)\n+        return RunSettings(verbose=verbose, thread_count=thread_val, resume=self.current.resume)\n \n     def _refresh_summary(self) -> None:\n         if not self._summary:\n@@ -1709,10 +1777,59 @@ def _refresh_summary(self) -> None:\n         self._summary.update(self._render_summary(settings))\n \n     def _render_summary(self, settings: RunSettings) -> RenderableType:\n+        if self._view_mode == \"resume\":\n+            return self._render_resume_overview(settings)\n         if self._view_mode == \"flow\":\n             return self._render_flow_overview(settings)\n         return plan_overview(self.plan, run_settings=settings, compact=self.compact)\n \n+    def _render_resume_overview(self, settings: RunSettings) -> RenderableType:\n+        app = self.app\n+        base_dir = app.base_dir if isinstance(app, PlanUIApp) else Path.cwd()\n+\n+        preview = resume_utils.preview_resume(\n+            self.plan,\n+            base_dir=base_dir,\n+            thread_count=settings.thread_count,\n+        )\n+        rows = resume_utils.command_rows(\n+            self.plan,\n+            base_dir=base_dir,\n+            thread_count=settings.thread_count,\n+        )\n+\n+        next_row = next((row for row in rows if row.status != resume_utils.STATUS_COMPLETED), None)\n+        header = Text()\n+        header.append(\"Resume: \", style=\"bold cyan\")\n+        if not settings.resume:\n+            header.append(\"disabled (full run)\", style=\"dim\")\n+        elif next_row is None:\n+            header.append(\"all steps are skippable (outputs present)\", style=\"bold green\")\n+        else:\n+            header.append(f\"starts at step {next_row.index}: \", style=\"dim\")\n+            header.append(next_row.name, style=\"bold white\")\n+\n+        if preview is None:\n+            message = Panel(\n+                \"Unable to read run_state.json (missing or invalid). The plan will run in full; to resume, ensure the state file exists and is readable.\",\n+                border_style=\"yellow\",\n+            )\n+            return Group(header, Text(\"\"), message, resume_utils.render_command_table(rows, limit=200))\n+\n+        summary_table, state_panel = resume_utils.render_summary(preview)\n+        warning: Panel | None = None\n+        if not preview.plan_matches:\n+            warning = Panel(\n+                \"Note: the plan signature in the state file does not match the current plan (thread count / edits can cause this).\\n\"\n+                \"Resume will skip only the contiguous completed prefix using command matching + output checks; once a step needs rerun, all subsequent steps will rerun.\",\n+                border_style=\"yellow\",\n+            )\n+        parts: list[RenderableType] = [header, Text(\"\"), summary_table, state_panel]\n+        if warning is not None:\n+            parts.insert(2, warning)\n+        parts.append(resume_utils.render_command_table(rows, limit=200))\n+        return Group(*parts)\n+\n     def _render_flow_overview(self, settings: RunSettings) -> Panel:\n         # Header\n         header = Text()\n@@ -1722,7 +1839,7 @@ def _render_flow_overview(self, settings: RunSettings) -> Panel:\n         header.append(\"on\" if settings.verbose else \"off\", style=\"bold green\" if settings.verbose else \"bold #aaaaaa\")\n         \n         canvas_text = self._draw_dependency_tree()\n-        \n+\n         content = Group(header, Text(\"\"), canvas_text)\n         return Panel(content, title=\"[Execution Dependency Tree]\", border_style=\"magenta\", padding=(0, 1))\n \n@@ -2215,6 +2332,8 @@ def __init__(self, plan: Plan, base_dir: Optional[Path] = None, run_settings: Op\n         self.plan = plan\n         self.base_dir = Path(base_dir) if base_dir else Path.cwd()\n         self.alignment_tree = tree_utils.build_alignment_tree(plan, base_dir=self.base_dir)\n+        self._run_state_path = self._resolve_run_state_path()\n+        self.resume_available = self._run_state_path.exists()\n         self.canvas: AsciiPhylo | None = None\n         self.run_settings = run_settings or RunSettings()\n         self.hud: DashboardHUD | None = None\n@@ -2244,8 +2363,20 @@ def on_mount(self) -> None:\n             preview = plan_overview(self.plan, run_settings=self.run_settings, compact=self._is_compact())\n             self.detail_panel.update(preview)\n         \n-        # Delay the welcome overlay slightly so the UI renders first.\n-        self.set_timer(0.3, self._show_welcome_guide)\n+        if self.run_settings.resume and self.resume_available:\n+            # 断点续跑专属入口：直接进入运行设置/续跑摘要界面。\n+            self.set_timer(0.05, self.action_run_plan)\n+        else:\n+            # Delay the welcome overlay slightly so the UI renders first.\n+            self.set_timer(0.3, self._show_welcome_guide)\n+\n+    def _resolve_run_state_path(self) -> Path:\n+        if self.plan.out_dir:\n+            out_dir = Path(self.plan.out_dir).expanduser()\n+            if not out_dir.is_absolute():\n+                out_dir = (self.base_dir / out_dir).resolve()\n+            return (out_dir / \"logs\" / \"run_state.json\").resolve()\n+        return (self.base_dir / \"logs\" / \"run_state.json\").resolve()\n \n     def _show_welcome_guide(self) -> None:\n         welcome_text = (\n@@ -2308,7 +2439,12 @@ def _start_round_edit(self, round_index: int) -> None:\n         self._show_round(round_index)\n \n     def action_run_plan(self) -> None:\n-        screen = RunSettingsScreen(self.plan, self.run_settings, compact=self._is_compact())\n+        screen = RunSettingsScreen(\n+            self.plan,\n+            self.run_settings,\n+            compact=self._is_compact(),\n+            resume_available=self.resume_available,\n+        )\n         self.push_screen(screen, self._finalize_run_settings)\n \n     def export_commands(self, settings: RunSettings | None = None, *, notify_detail: bool = True) -> Path | None:"
      },
      {
        "sha": "2f6fa35b737f6d849a0a019d161a4feda3d2b871",
        "filename": "pyproject.toml",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/pyproject.toml",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/pyproject.toml",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/pyproject.toml?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -4,7 +4,7 @@ build-backend = \"hatchling.build\"\n \n [project]\n name = \"cactus-ramax\"\n-version = \"0.4.0-dev\"\n+version = \"0.4.0\"\n description = \"Interactive tooling for mixing cactus and RaMAx workflows\"\n authors = [{name = \"Cactus-RaMAx Team\"}]\n readme = \"README.md\""
      },
      {
        "sha": "279e820f8c3fae034fa00547aeb1306d03d95fe6",
        "filename": "tests/test_planner_ramax_options.py",
        "status": "added",
        "additions": 34,
        "deletions": 0,
        "changes": 34,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_planner_ramax_options.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_planner_ramax_options.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/tests%2Ftest_planner_ramax_options.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -0,0 +1,34 @@\n+from datetime import datetime\n+from pathlib import Path\n+\n+from cax import planner\n+from cax.models import Plan, PrepareHeader, Round\n+\n+\n+def test_subtree_flag_not_passed_to_ramax(tmp_path: Path):\n+    header = PrepareHeader(\n+        generated_by=\"cactus-prepare --outSeqFile seq.fa\",\n+        date=datetime.now(),\n+        cactus_commit=None,\n+    )\n+    round_entry = Round(\n+        name=\"r1\",\n+        root=\"Anc0\",\n+        target_hal=\"out.hal\",\n+        replace_with_ramax=True,\n+        ramax_opts=[\"--subtree-mode\", \"--threads\", \"4\"],\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[],\n+        rounds=[round_entry],\n+        hal_merges=[],\n+        out_seq_file=\"seq.fa\",\n+        out_dir=str(tmp_path),\n+    )\n+\n+    commands = planner.build_execution_plan(plan, base_dir=tmp_path)\n+    ramax_cmd = next(cmd for cmd in commands if cmd.is_ramax)\n+\n+    assert \"--subtree-mode\" not in ramax_cmd.command\n+    assert \"--threads\" in ramax_cmd.command"
      },
      {
        "sha": "224e27840373bd3a48c3fa456b92bef0b81db203",
        "filename": "tests/test_planner_subtree_absorb.py",
        "status": "added",
        "additions": 43,
        "deletions": 0,
        "changes": 43,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_planner_subtree_absorb.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_planner_subtree_absorb.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/tests%2Ftest_planner_subtree_absorb.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -0,0 +1,43 @@\n+from datetime import datetime\n+from pathlib import Path\n+\n+from cax import planner\n+from cax.models import Plan, PrepareHeader, Round, Step\n+\n+\n+def _round(root: str) -> Round:\n+    blast = Step(raw=f\"blast {root}\", kind=\"blast\", out_files=[f\"{root}.paf\"], root=root)\n+    align = Step(raw=f\"align {root}\", kind=\"align\", out_files=[f\"{root}.hal\"], root=root)\n+    return Round(name=root, root=root, target_hal=f\"{root}.hal\", blast_step=blast, align_step=align)\n+\n+\n+def _plan(tmp_path: Path) -> Plan:\n+    tree_path = tmp_path / \"tree.nwk\"\n+    tree_path.write_text(\"((a,b)Anc1)Anc0;\", encoding=\"utf-8\")\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile tree.nwk\", date=datetime.now())\n+    root_round = Round(\n+        name=\"Anc0\",\n+        root=\"Anc0\",\n+        target_hal=\"Anc0.hal\",\n+        replace_with_ramax=True,\n+        ramax_opts=[\"--subtree-mode\"],\n+    )\n+    child_round = _round(\"Anc1\")\n+    return Plan(\n+        header=header,\n+        preprocess=[],\n+        rounds=[root_round, child_round],\n+        hal_merges=[],\n+        out_seq_file=str(tree_path),\n+        out_dir=str(tmp_path),\n+    )\n+\n+\n+def test_subtree_mode_skips_descendant_rounds(tmp_path: Path):\n+    plan = _plan(tmp_path)\n+\n+    commands = planner.build_execution_plan(plan, base_dir=tmp_path)\n+\n+    # Only the ancestor RaMAx command should remain; descendant rounds are absorbed.\n+    assert any(cmd.is_ramax and cmd.round_name == \"Anc0\" for cmd in commands)\n+    assert not any(cmd.round_name == \"Anc1\" for cmd in commands)"
      },
      {
        "sha": "fb807dcce075bf5033bda4767eb4fcb8e3e042d4",
        "filename": "tests/test_resume_matching.py",
        "status": "added",
        "additions": 186,
        "deletions": 0,
        "changes": 186,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_resume_matching.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_resume_matching.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/tests%2Ftest_resume_matching.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -0,0 +1,186 @@\n+import os\n+import stat\n+from datetime import datetime\n+from pathlib import Path\n+\n+from cax.models import Plan, PrepareHeader, Round, RunSettings, Step\n+from cax.runner import PlanRunner\n+from cax.resume import preview_resume\n+\n+\n+def _write_executable(path: Path, content: str) -> None:\n+    path.write_text(content, encoding=\"utf-8\")\n+    path.chmod(path.stat().st_mode | stat.S_IEXEC)\n+\n+\n+def test_resume_skips_even_when_threads_change_for_cactus_commands(tmp_path: Path):\n+    bin_dir = tmp_path / \"bin\"\n+    bin_dir.mkdir()\n+    _write_executable(\n+        bin_dir / \"cactus-preprocess\",\n+        \"\"\"#!/usr/bin/env python3\n+import sys\n+from pathlib import Path\n+\n+out = None\n+for arg in sys.argv[1:]:\n+    if arg.endswith(\".txt\"):\n+        out = arg\n+        break\n+out = out or \"count.txt\"\n+p = Path(out)\n+n = int(p.read_text()) if p.exists() else 0\n+p.write_text(str(n + 1))\n+\"\"\",\n+    )\n+    env = {\"PATH\": f\"{bin_dir}{os.pathsep}{os.environ.get('PATH', '')}\"}\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    step = Step(raw=\"cactus-preprocess count.txt\", kind=\"preprocess\", out_files=[\"count.txt\"])\n+    plan = Plan(\n+        header=header,\n+        preprocess=[step],\n+        rounds=[],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(\n+        plan,\n+        base_dir=tmp_path,\n+        env=env,\n+        run_settings=RunSettings(verbose=False, resume=True, thread_count=4),\n+    )\n+    runner.run()\n+    assert (tmp_path / \"count.txt\").read_text() == \"1\"\n+\n+    preview = preview_resume(plan, base_dir=tmp_path, thread_count=8)\n+    assert preview is not None\n+    assert preview.plan_matches is False  # thread_count 变更会导致签名不同\n+    assert \"cactus-preprocess\" in preview.completed  # 但续跑匹配仍应能跳过\n+\n+    runner = PlanRunner(\n+        plan,\n+        base_dir=tmp_path,\n+        env=env,\n+        run_settings=RunSettings(verbose=False, resume=True, thread_count=8),\n+    )\n+    runner.run()\n+    assert (tmp_path / \"count.txt\").read_text() == \"1\"  # 已完成步骤仍可被跳过\n+\n+\n+def test_resume_keeps_skipping_completed_steps_when_future_step_changes(tmp_path: Path):\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    step1 = Step(\n+        raw=(\n+            \"python -c \\\"from pathlib import Path; p=Path('count.txt'); \"\n+            \"n=int(p.read_text()) if p.exists() else 0; p.write_text(str(n+1))\\\"\"\n+        ),\n+        kind=\"preprocess\",\n+        out_files=[\"count.txt\"],\n+    )\n+    step2 = Step(\n+        raw=\"python -c \\\"from pathlib import Path; Path('marker.txt').write_text('v1')\\\"\",\n+        kind=\"preprocess\",\n+        out_files=[\"marker.txt\"],\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[step1, step2],\n+        rounds=[],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+    assert (tmp_path / \"count.txt\").read_text() == \"1\"\n+    assert (tmp_path / \"marker.txt\").read_text() == \"v1\"\n+\n+    # 微调后续步骤命令（模拟用户编辑待执行/后续步骤），应不影响已完成步骤的跳过。\n+    step2.raw = \"python -c \\\"from pathlib import Path; Path('marker.txt').write_text('v2')\\\"\"\n+    runner = PlanRunner(plan, base_dir=tmp_path, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+\n+    assert (tmp_path / \"count.txt\").read_text() == \"1\"  # 第一步仍被跳过\n+    assert (tmp_path / \"marker.txt\").read_text() == \"v2\"  # 第二步按新命令重跑\n+\n+\n+def test_resume_reruns_ramax_when_output_missing(tmp_path: Path):\n+    bin_dir = tmp_path / \"bin\"\n+    bin_dir.mkdir()\n+    _write_executable(\n+        bin_dir / \"ramax\",\n+        \"\"\"#!/usr/bin/env python3\n+import sys\n+from pathlib import Path\n+\n+out = None\n+for i, arg in enumerate(sys.argv[1:]):\n+    if arg == \"-o\" and i + 2 <= len(sys.argv[1:]):\n+        out = sys.argv[1:][i + 1]\n+        break\n+    if arg.startswith(\"-o=\"):\n+        out = arg.split(\"=\", 1)[1]\n+        break\n+\n+out = out or \"out.hal\"\n+Path(out).write_text(\"ok\")\n+\n+counter = Path(\"ramax-count.txt\")\n+n = int(counter.read_text()) if counter.exists() else 0\n+counter.write_text(str(n + 1))\n+\"\"\",\n+    )\n+    env = {\"PATH\": f\"{bin_dir}{os.pathsep}{os.environ.get('PATH', '')}\"}\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    round1 = Round(\n+        name=\"Round 1\",\n+        root=\"root1\",\n+        target_hal=\"out.hal\",\n+        replace_with_ramax=True,\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[],\n+        rounds=[round1],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(\n+        plan,\n+        base_dir=tmp_path,\n+        env=env,\n+        run_settings=RunSettings(verbose=False, resume=True, thread_count=4),\n+    )\n+    runner.run()\n+    assert (tmp_path / \"out.hal\").exists()\n+    assert (tmp_path / \"ramax-count.txt\").read_text() == \"1\"\n+\n+    # 线程数变化不应导致已完成的 RaMAx 被重复执行\n+    runner = PlanRunner(\n+        plan,\n+        base_dir=tmp_path,\n+        env=env,\n+        run_settings=RunSettings(verbose=False, resume=True, thread_count=8),\n+    )\n+    runner.run()\n+    assert (tmp_path / \"ramax-count.txt\").read_text() == \"1\"\n+\n+    # 删除产物，应触发重跑\n+    (tmp_path / \"out.hal\").unlink()\n+    runner = PlanRunner(\n+        plan,\n+        base_dir=tmp_path,\n+        env=env,\n+        run_settings=RunSettings(verbose=False, resume=True, thread_count=8),\n+    )\n+    runner.run()\n+    assert (tmp_path / \"out.hal\").exists()\n+    assert (tmp_path / \"ramax-count.txt\").read_text() == \"2\"\n+"
      },
      {
        "sha": "5d8e67ed34724738048d01e397206d70fd4598a5",
        "filename": "tests/test_runner_resume.py",
        "status": "added",
        "additions": 491,
        "deletions": 0,
        "changes": 491,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_runner_resume.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_runner_resume.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/tests%2Ftest_runner_resume.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -0,0 +1,491 @@\n+import os\n+import stat\n+from datetime import datetime\n+from pathlib import Path\n+\n+import pytest\n+\n+from cax.models import Plan, PrepareHeader, Round, RunSettings, Step\n+from cax.runner import PlanRunner\n+from cax.resume import preview_resume\n+\n+\n+def _build_plan(tmp_path: Path) -> Plan:\n+    header = PrepareHeader(\n+        generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\",\n+        date=datetime.now(),\n+    )\n+    step1 = Step(\n+        raw=(\n+            \"python -c \\\"from pathlib import Path; p=Path('count.txt'); \"\n+            \"n=int(p.read_text()) if p.exists() else 0; p.write_text(str(n+1))\\\"\"\n+        ),\n+        kind=\"blast\",\n+        out_files=[\"count.txt\"],\n+        root=\"root1\",\n+    )\n+    step2 = Step(\n+        raw=\"python -c \\\"from pathlib import Path; Path('marker.txt').write_text('ok')\\\"\",\n+        kind=\"align\",\n+        out_files=[\"marker.txt\"],\n+        root=\"root1\",\n+    )\n+    round1 = Round(\n+        name=\"Round 1\",\n+        root=\"root1\",\n+        target_hal=\"target.hal\",\n+        blast_step=step1,\n+        align_step=step2,\n+    )\n+    return Plan(\n+        header=header,\n+        preprocess=[],\n+        rounds=[round1],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+\n+def _write_executable(path: Path, content: str) -> None:\n+    path.write_text(content, encoding=\"utf-8\")\n+    path.chmod(path.stat().st_mode | stat.S_IEXEC)\n+\n+\n+def test_resume_skips_completed_steps(tmp_path):\n+    plan = _build_plan(tmp_path)\n+    runner = PlanRunner(plan, base_dir=tmp_path, run_settings=RunSettings(verbose=False, resume=True))\n+\n+    runner.run()\n+\n+    count_path = tmp_path / \"count.txt\"\n+    marker_path = tmp_path / \"marker.txt\"\n+\n+    assert count_path.exists()\n+    assert marker_path.exists()\n+    assert count_path.read_text() == \"1\"\n+\n+    # 删除第二步产物以验证续跑会重做缺失步骤\n+    marker_path.unlink()\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+\n+    assert count_path.read_text() == \"1\"  # 第一步被跳过\n+    assert marker_path.exists()  # 第二步因产物缺失被重跑\n+    assert (tmp_path / \"logs\" / \"run_state.json\").exists()\n+\n+\n+def test_preview_resume_reports_completed_and_pending(tmp_path):\n+    plan = _build_plan(tmp_path)\n+    runner = PlanRunner(plan, base_dir=tmp_path, run_settings=RunSettings(verbose=False, resume=True))\n+\n+    runner.run()\n+\n+    # 删除第二步产物以制造“缺失产物需重跑”场景\n+    marker_path = tmp_path / \"marker.txt\"\n+    marker_path.unlink()\n+\n+    preview = preview_resume(plan, base_dir=tmp_path)\n+\n+    assert preview is not None\n+    assert preview.plan_matches is True\n+    assert \"blast-root1\" in preview.completed\n+    assert \"align-root1\" in preview.pending\n+    assert \"align-root1\" in preview.missing_outputs\n+\n+\n+def test_preview_resume_detects_signature_mismatch(tmp_path):\n+    plan = _build_plan(tmp_path)\n+    runner = PlanRunner(plan, base_dir=tmp_path, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+\n+    preview = preview_resume(plan, base_dir=tmp_path, thread_count=8)\n+\n+    assert preview is not None\n+    assert preview.plan_matches is False\n+\n+\n+def test_resume_adds_restart_for_existing_toil_jobstore(tmp_path: Path):\n+    bin_dir = tmp_path / \"bin\"\n+    bin_dir.mkdir()\n+    _write_executable(\n+        bin_dir / \"cactus-blast\",\n+        \"\"\"#!/usr/bin/env python3\n+import sys\n+from pathlib import Path\n+\n+jobstore = Path(sys.argv[1])\n+jobstore.mkdir(parents=True, exist_ok=True)\n+(jobstore / \"files\" / \"shared\").mkdir(parents=True, exist_ok=True)\n+(jobstore / \"files\" / \"shared\" / \"rootJobStoreID\").write_text(\"ok\")\n+\n+args = \" \".join(sys.argv[1:])\n+Path(\"seen-args.txt\").write_text(args)\n+\n+if \"--restart\" not in sys.argv:\n+    sys.exit(1)\n+\n+out = next((a for a in sys.argv[1:] if a.endswith(\".paf\")), None)\n+if out:\n+    Path(out).write_text(\"ok\")\n+sys.exit(0)\n+\"\"\",\n+    )\n+    env = {\"PATH\": f\"{bin_dir}{os.pathsep}{os.environ.get('PATH', '')}\"}\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    step = Step(\n+        raw=\"cactus-blast jobstore/0 seq.txt out.paf --root r\",\n+        kind=\"preprocess\",\n+        jobstore=\"jobstore/0\",\n+        out_files=[\"out.paf\"],\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[step],\n+        rounds=[],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    with pytest.raises(RuntimeError):\n+        runner.run()\n+\n+    assert (tmp_path / \"jobstore\" / \"0\").exists()\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+\n+    assert (tmp_path / \"out.paf\").exists()\n+    assert \"--restart\" in (tmp_path / \"seen-args.txt\").read_text()\n+\n+\n+def test_resume_cleans_toil_jobstore_when_forced_to_rerun(tmp_path: Path):\n+    bin_dir = tmp_path / \"bin\"\n+    bin_dir.mkdir()\n+    _write_executable(\n+        bin_dir / \"cactus-blast\",\n+        \"\"\"#!/usr/bin/env python3\n+import sys\n+from pathlib import Path\n+\n+jobstore = Path(sys.argv[1])\n+if jobstore.exists():\n+    # Runner should have cleaned it when rerunning a previously-successful step.\n+    sys.exit(2)\n+if \"--restart\" in sys.argv:\n+    sys.exit(3)\n+\n+jobstore.mkdir(parents=True, exist_ok=True)\n+out = next((a for a in sys.argv[1:] if a.endswith(\".paf\")), None)\n+if out:\n+    Path(out).write_text(\"ok\")\n+\n+counter = Path(\"blast-count.txt\")\n+n = int(counter.read_text()) if counter.exists() else 0\n+counter.write_text(str(n + 1))\n+sys.exit(0)\n+\"\"\",\n+    )\n+    env = {\"PATH\": f\"{bin_dir}{os.pathsep}{os.environ.get('PATH', '')}\"}\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    step1 = Step(\n+        raw=\"python -c \\\"from pathlib import Path; Path('a.txt').write_text('ok')\\\"\",\n+        kind=\"preprocess\",\n+        out_files=[\"a.txt\"],\n+        label=\"make-a\",\n+    )\n+    step2 = Step(\n+        raw=\"cactus-blast jobstore/0 seq.txt out.paf --root r\",\n+        kind=\"preprocess\",\n+        jobstore=\"jobstore/0\",\n+        out_files=[\"out.paf\"],\n+        label=\"blast\",\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[step1, step2],\n+        rounds=[],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+    assert (tmp_path / \"jobstore\" / \"0\").exists()\n+    assert (tmp_path / \"blast-count.txt\").read_text() == \"1\"\n+\n+    # 触发断点回退：让第 1 步需要重跑，从而第 2 步也必须重跑（并清理 jobStore）。\n+    (tmp_path / \"a.txt\").unlink()\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+\n+    assert (tmp_path / \"blast-count.txt\").read_text() == \"2\"\n+\n+\n+def test_resume_cleans_corrupt_jobstore_instead_of_restart(tmp_path: Path):\n+    \"\"\"jobStore 存在但缺少 rootJobStoreID 时，--restart 会报错，应当清理后重跑。\"\"\"\n+\n+    bin_dir = tmp_path / \"bin\"\n+    bin_dir.mkdir()\n+    _write_executable(\n+        bin_dir / \"cactus-blast\",\n+        \"\"\"#!/usr/bin/env python3\n+import sys\n+from pathlib import Path\n+\n+jobstore = Path(sys.argv[1])\n+\n+# 若 runner 未在启动前清理，直接失败。\n+if jobstore.exists():\n+    sys.exit(2)\n+if \"--restart\" in sys.argv:\n+    sys.exit(3)\n+\n+marker = Path(\"first-run.txt\")\n+if not marker.exists():\n+    # 第一次：制造一个“看似存在但不完整”的 jobStore（缺少 rootJobStoreID），并失败\n+    (jobstore / \"files\" / \"shared\").mkdir(parents=True, exist_ok=True)\n+    (jobstore / \"files\" / \"shared\" / \"config.pickle\").write_text(\"x\")\n+    marker.write_text(\"1\")\n+    sys.exit(1)\n+\n+out = next((a for a in sys.argv[1:] if a.endswith(\".paf\")), None)\n+if out:\n+    Path(out).write_text(\"ok\")\n+sys.exit(0)\n+\"\"\",\n+    )\n+    env = {\"PATH\": f\"{bin_dir}{os.pathsep}{os.environ.get('PATH', '')}\"}\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    step = Step(\n+        raw=\"cactus-blast jobstore/0 seq.txt out.paf --root r\",\n+        kind=\"preprocess\",\n+        jobstore=\"jobstore/0\",\n+        out_files=[\"out.paf\"],\n+        label=\"blast\",\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[step],\n+        rounds=[],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    with pytest.raises(RuntimeError):\n+        runner.run()\n+    assert (tmp_path / \"jobstore\" / \"0\").exists()\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+    assert (tmp_path / \"out.paf\").exists()\n+\n+\n+def test_resume_only_skips_prefix_steps(tmp_path: Path):\n+    \"\"\"验证续跑只跳过前缀：一旦前置步骤需重跑，后续即使成功也要重跑。\"\"\"\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    step1 = Step(\n+        raw=\"python -c \\\"from pathlib import Path; Path('a.txt').write_text('ok')\\\"\",\n+        kind=\"preprocess\",\n+        out_files=[\"a.txt\"],\n+        label=\"make-a\",\n+    )\n+    step2 = Step(\n+        raw=(\n+            \"python -c \\\"from pathlib import Path; p=Path('b.txt'); \"\n+            \"n=int(p.read_text()) if p.exists() else 0; p.write_text(str(n+1))\\\"\"\n+        ),\n+        kind=\"preprocess\",\n+        out_files=[\"b.txt\"],\n+        label=\"bump-b\",\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[step1, step2],\n+        rounds=[],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+    assert (tmp_path / \"a.txt\").exists()\n+    assert (tmp_path / \"b.txt\").read_text() == \"1\"\n+\n+    # 删除第一步产物，触发断点回退：后续步骤即便已成功也不应被跳过。\n+    (tmp_path / \"a.txt\").unlink()\n+\n+    preview = preview_resume(plan, base_dir=tmp_path)\n+    assert preview is not None\n+    assert \"make-a\" in preview.pending\n+    assert \"bump-b\" in preview.pending\n+    assert \"bump-b\" not in preview.completed\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+    assert (tmp_path / \"a.txt\").exists()\n+    assert (tmp_path / \"b.txt\").read_text() == \"2\"\n+\n+\n+def test_resume_cleans_failed_toil_jobstore_when_not_first_step(tmp_path: Path):\n+    \"\"\"当失败的 Toil 步骤不是本次重跑的第一个步骤时，应清理 jobStore 而不是 --restart。\"\"\"\n+\n+    bin_dir = tmp_path / \"bin\"\n+    bin_dir.mkdir()\n+    _write_executable(\n+        bin_dir / \"cactus-blast\",\n+        \"\"\"#!/usr/bin/env python3\n+import sys\n+from pathlib import Path\n+\n+jobstore = Path(sys.argv[1])\n+Path(\"seen-args.txt\").write_text(\" \".join(sys.argv[1:]))\n+\n+marker = Path(\"first-run.txt\")\n+if not marker.exists():\n+    (jobstore / \"files\" / \"shared\").mkdir(parents=True, exist_ok=True)\n+    (jobstore / \"files\" / \"shared\" / \"rootJobStoreID\").write_text(\"ok\")\n+    marker.write_text(\"1\")\n+    sys.exit(1)\n+\n+if jobstore.exists():\n+    sys.exit(2)\n+if \"--restart\" in sys.argv:\n+    sys.exit(3)\n+\n+(jobstore / \"files\" / \"shared\").mkdir(parents=True, exist_ok=True)\n+(jobstore / \"files\" / \"shared\" / \"rootJobStoreID\").write_text(\"ok\")\n+\n+out = next((a for a in sys.argv[1:] if a.endswith(\".paf\")), None)\n+if out:\n+    Path(out).write_text(\"ok\")\n+sys.exit(0)\n+\"\"\",\n+    )\n+    env = {\"PATH\": f\"{bin_dir}{os.pathsep}{os.environ.get('PATH', '')}\"}\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    step1 = Step(\n+        raw=\"python -c \\\"from pathlib import Path; Path('a.txt').write_text('ok')\\\"\",\n+        kind=\"preprocess\",\n+        out_files=[\"a.txt\"],\n+        label=\"make-a\",\n+    )\n+    step2 = Step(\n+        raw=\"cactus-blast jobstore/0 seq.txt out.paf --root r\",\n+        kind=\"blast\",\n+        jobstore=\"jobstore/0\",\n+        out_files=[\"out.paf\"],\n+        label=\"blast\",\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[step1, step2],\n+        rounds=[],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    with pytest.raises(RuntimeError):\n+        runner.run()\n+    assert (tmp_path / \"jobstore\" / \"0\").exists()\n+\n+    # 触发断点回退：让第 1 步需要重跑，从而第 2 步不再是“本次重跑的第一步”\n+    (tmp_path / \"a.txt\").unlink()\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+\n+    assert (tmp_path / \"out.paf\").exists()\n+    assert \"--restart\" not in (tmp_path / \"seen-args.txt\").read_text()\n+\n+\n+def test_resume_reruns_blast_when_paf_inconsistent_with_fasta(tmp_path: Path):\n+    \"\"\"PAF 引用的 contig 与当前 FASTA 不一致时，不应跳过 blast 步骤。\"\"\"\n+\n+    bin_dir = tmp_path / \"bin\"\n+    bin_dir.mkdir()\n+    _write_executable(\n+        bin_dir / \"cactus-blast\",\n+        \"\"\"#!/usr/bin/env python3\n+import sys\n+from pathlib import Path\n+\n+counter = Path(\"blast-count.txt\")\n+n = int(counter.read_text()) if counter.exists() else 0\n+counter.write_text(str(n + 1))\n+\n+out = sys.argv[3] if len(sys.argv) > 3 else \"out.paf\"\n+\n+# 故意写一个“与 FASTA 不一致”的 PAF：A 的 contig 写成 A.chr1，但 FASTA 里只有 ArefChr0\n+Path(out).write_text(\n+    \"id=B|BrefChr0\\\\t4\\\\t0\\\\t4\\\\t+\\\\tid=A|A.chr1\\\\t4\\\\t0\\\\t4\\\\t4\\\\t4\\\\t60\\\\n\",\n+    encoding=\"utf-8\",\n+)\n+sys.exit(0)\n+\"\"\",\n+    )\n+    env = {\"PATH\": f\"{bin_dir}{os.pathsep}{os.environ.get('PATH', '')}\"}\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa --outDir out\", date=datetime.now())\n+    step0 = Step(\n+        raw=(\n+            \"python -c \\\"from pathlib import Path; \"\n+            \"Path('A.fa').write_text('>ArefChr0\\\\nACGT\\\\n'); \"\n+            \"Path('B.fa').write_text('>BrefChr0\\\\nACGT\\\\n'); \"\n+            \"Path('seq.txt').write_text('(A:0.1,B:0.1)R;\\\\nA\\\\tA.fa\\\\nB\\\\tB.fa\\\\n')\\\"\"\n+        ),\n+        kind=\"preprocess\",\n+        out_files=[\"A.fa\", \"B.fa\", \"seq.txt\"],\n+        label=\"prep\",\n+    )\n+    step1 = Step(\n+        raw=\"cactus-blast jobstore/0 seq.txt out.paf --root R\",\n+        kind=\"blast\",\n+        jobstore=\"jobstore/0\",\n+        out_files=[\"out.paf\"],\n+        label=\"blast\",\n+    )\n+    step2 = Step(\n+        raw=(\n+            \"python -c \\\"from pathlib import Path; p=Path('after-count.txt'); \"\n+            \"n=int(p.read_text()) if p.exists() else 0; p.write_text(str(n+1))\\\"\"\n+        ),\n+        kind=\"preprocess\",\n+        out_files=[\"after-count.txt\"],\n+        label=\"after\",\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[step0, step1, step2],\n+        rounds=[],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"seq.fa\"),\n+        out_dir=str(tmp_path),\n+    )\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+    assert (tmp_path / \"blast-count.txt\").read_text() == \"1\"\n+    assert (tmp_path / \"after-count.txt\").read_text() == \"1\"\n+\n+    runner = PlanRunner(plan, base_dir=tmp_path, env=env, run_settings=RunSettings(verbose=False, resume=True))\n+    runner.run()\n+\n+    # step0 会被跳过，但 step1 的 PAF 校验失败 -> step1/step2 必须重跑\n+    assert (tmp_path / \"blast-count.txt\").read_text() == \"2\"\n+    assert (tmp_path / \"after-count.txt\").read_text() == \"2\""
      },
      {
        "sha": "de37f28fdb22460104fa09fe53eed28ebff4aec6",
        "filename": "tests/test_tree_utils_attach_orphan_root.py",
        "status": "added",
        "additions": 53,
        "deletions": 0,
        "changes": 53,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_tree_utils_attach_orphan_root.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_tree_utils_attach_orphan_root.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/tests%2Ftest_tree_utils_attach_orphan_root.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -0,0 +1,53 @@\n+from datetime import datetime\n+from pathlib import Path\n+\n+from cax import parser, tree_utils\n+from cax.models import Plan, PrepareHeader, Round, Step\n+\n+\n+def _round(root: str) -> Round:\n+    blast = Step(raw=f\"cactus-blast jobstore/1 seq.fa {root}.paf --root {root}\", kind=\"blast\", out_files=[f\"{root}.paf\"], root=root)\n+    align = Step(raw=f\"cactus-align jobstore/2 seq.fa {root}.paf {root}.hal --root {root}\", kind=\"align\", out_files=[f\"{root}.hal\"], root=root)\n+    return Round(name=root, root=root, target_hal=f\"{root}.hal\", blast_step=blast, align_step=align)\n+\n+\n+def _plan(tmp_path: Path) -> Plan:\n+    tree_path = tmp_path / \"seq.fa\"\n+    tree_path.write_text(\"(a,(b,c)cb) ;\", encoding=\"utf-8\")\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa\", date=datetime.now())\n+    return Plan(\n+        header=header,\n+        preprocess=[],\n+        rounds=[_round(\"cb\"), _round(\"Anc0\")],\n+        hal_merges=[],\n+        out_seq_file=str(tree_path),\n+    )\n+\n+\n+def test_orphan_round_attached_to_unnamed_root(tmp_path: Path):\n+    plan = _plan(tmp_path)\n+    tree = tree_utils.build_alignment_tree(plan, base_dir=tmp_path)\n+    assert tree is not None\n+    # unnamed root should carry the unmatched round\n+    assert tree.root.round is not None\n+    assert tree.root.round.root == \"Anc0\"\n+    # named child still attached correctly\n+    child = tree.find(\"cb\")\n+    assert child and child.round and child.round.root == \"cb\"\n+\n+\n+def test_multiple_orphans_added_as_children(tmp_path: Path):\n+    tree_path = tmp_path / \"seq.fa\"\n+    tree_path.write_text(\"(a,b);\", encoding=\"utf-8\")\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile seq.fa\", date=datetime.now())\n+    plan = Plan(\n+        header=header,\n+        preprocess=[],\n+        rounds=[_round(\"Anc0\"), _round(\"Anc1\")],\n+        hal_merges=[],\n+        out_seq_file=str(tree_path),\n+    )\n+    tree = tree_utils.build_alignment_tree(plan, base_dir=tmp_path)\n+    assert tree is not None\n+    names = {child.name for child in tree.root.children}\n+    assert {\"Anc0\", \"Anc1\"}.issubset(names)"
      },
      {
        "sha": "3112266396efad1ac044aa6bded480b2898929f8",
        "filename": "tests/test_tree_utils_fallback_newick.py",
        "status": "added",
        "additions": 37,
        "deletions": 0,
        "changes": 37,
        "blob_url": "https://github.com/malabz/Cax/blob/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_tree_utils_fallback_newick.py",
        "raw_url": "https://github.com/malabz/Cax/raw/984c1351d8e705217fde3c46d58fd89e3006d364/tests%2Ftest_tree_utils_fallback_newick.py",
        "contents_url": "https://api.github.com/repos/malabz/Cax/contents/tests%2Ftest_tree_utils_fallback_newick.py?ref=984c1351d8e705217fde3c46d58fd89e3006d364",
        "patch": "@@ -0,0 +1,37 @@\n+from datetime import datetime\n+from pathlib import Path\n+\n+from cax import tree_utils\n+from cax.models import Plan, PrepareHeader, Round, Step\n+\n+\n+def _round(root: str) -> Round:\n+    blast = Step(raw=f\"cactus-blast jobstore/1 seq.fa {root}.paf --root {root}\", kind=\"blast\", out_files=[f\"{root}.paf\"], root=root)\n+    align = Step(raw=f\"cactus-align jobstore/2 seq.fa {root}.paf {root}.hal --root {root}\", kind=\"align\", out_files=[f\"{root}.hal\"], root=root)\n+    return Round(name=root, root=root, target_hal=f\"{root}.hal\", blast_step=blast, align_step=align)\n+\n+\n+def test_build_tree_uses_preprocess_input_when_outseq_missing(tmp_path: Path):\n+    # Write only the input file (with Newick) and point out_seq_file to a non-existent path.\n+    input_path = tmp_path / \"input.txt\"\n+    input_path.write_text(\"(a,b)c;\", encoding=\"utf-8\")\n+\n+    header = PrepareHeader(generated_by=\"cactus-prepare --outSeqFile missing.txt\", date=datetime.now())\n+    preprocess = Step(\n+        raw=f\"cactus-preprocess jobstore/0 {input_path} missing.txt --logFile preprocess.log\",\n+        kind=\"preprocess\",\n+        out_files=[\"missing.txt\"],\n+    )\n+    plan = Plan(\n+        header=header,\n+        preprocess=[preprocess],\n+        rounds=[_round(\"c\")],\n+        hal_merges=[],\n+        out_seq_file=str(tmp_path / \"missing.txt\"),\n+    )\n+\n+    tree = tree_utils.build_alignment_tree(plan, base_dir=tmp_path)\n+\n+    assert tree is not None\n+    assert tree.root.name == \"c\"\n+    assert tree.root.round and tree.root.round.root == \"c\""
      }
    ]
  }
}