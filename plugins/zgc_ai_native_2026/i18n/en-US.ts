export const enUS: Record<string, string> = {
  'plugin.zgc_ai_native_2026.single.error_title': 'Evaluation failed',
  'plugin.zgc_ai_native_2026.single.loading': 'Evaluating with plugin...',
  'plugin.zgc_ai_native_2026.single.no_eval.title': 'No evaluation yet',
  'plugin.zgc_ai_native_2026.single.no_eval.desc': 'Select an author to start evaluation.',
  'plugin.zgc_ai_native_2026.single.title_default': 'RUBRIC VIEW (Single Repo, AI-Native 2026)',
  'plugin.zgc_ai_native_2026.single.banner.active': 'PLUGIN VIEW ACTIVE',
  'plugin.zgc_ai_native_2026.single.tag.avg': 'avg',
  'plugin.zgc_ai_native_2026.single.section.focus_title': 'What this view optimizes for',
  'plugin.zgc_ai_native_2026.single.focus.1': 'Built-in Quality (tests / lint / refactor / validation)',
  'plugin.zgc_ai_native_2026.single.focus.2': 'Reproducibility (lockfiles / docker / one-command run)',
  'plugin.zgc_ai_native_2026.single.focus.3': 'Cloud-Native readiness (CI/CD / IaC / deploy configs)',
  'plugin.zgc_ai_native_2026.single.focus.4': 'Intelligent dev workflows (tooling / scripts / agent usage)',
  'plugin.zgc_ai_native_2026.single.focus.5': 'Professionalism (docs/ADR / PR hygiene / trade-offs)',
  'plugin.zgc_ai_native_2026.single.section.mapping': 'Dimension → Level (mapped to engineer_level.md L1–L5)',
  'plugin.zgc_ai_native_2026.single.section.summary': 'Rubric-guided Summary (AI-Native 2026)',

  'plugin.zgc_ai_native_2026.compare.title': 'RUBRIC COMPARE VIEW (Multi-Repo, AI-Native 2026)',
  'plugin.zgc_ai_native_2026.compare.banner.active':
    'Compare is rubric-themed (L1–L5). If you see this wrapper, plugin compare view is active.',
  'plugin.zgc_ai_native_2026.compare.tag.active': 'MULTI-REPO COMPARE VIEW ACTIVE',
  'plugin.zgc_ai_native_2026.compare.tag.avg': 'avg',
};


